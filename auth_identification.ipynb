{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "auth_identification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-qqI1Xd0KvD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "3f75c0e1-f8f3-4cce-b7f2-50c5e3d9d628"
      },
      "source": [
        "#https://drive.google.com/open?id=1jgg7I6tLqB6ahus-g1GKCmEpyv7dceOC\n",
        "!pip install PyDrive\n",
        "import os                                  # to access google drive as bigger files are downloaded from there\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyDrive\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/2d/c8e052ba51099faee0bfe71d84f35bb1576e6910483cad46b840a122ca6c/PyDrive-1.3.1-py2-none-any.whl\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python2.7/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python2.7/dist-packages (from PyDrive) (1.6.7)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.2)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.11.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n",
            "Installing collected packages: PyDrive\n",
            "Successfully installed PyDrive-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn5IZo0m0jaV"
      },
      "source": [
        "auth.authenticate_user()          # sign in for google drive\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1ET5nPL0vN8"
      },
      "source": [
        "download = drive.CreateFile({'id': '1jgg7I6tLqB6ahus-g1GKCmEpyv7dceOC'})\n",
        "download.GetContentFile('glove_embedding.tar')\n",
        "#from google.colab import files\n",
        "#uploadedFile=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2Gl9M_91Hby",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c8b2a2ff-97a7-4c89-90ec-3f02226c8f31"
      },
      "source": [
        "!tar -xvf glove_embedding.tar             # unzipping the glove embedding\n",
        "!rm -r /content/C50\n",
        "!rm -r /content/auth_id\n",
        "!rm -r /content/bbc\n",
        "!git clone https://github.com/shriya999/auth_id.git          # clones supporting files from github repo\n",
        "!git clone https://github.com/shriya999/C50.git               # clone dataset from github repo \n",
        "!git clone https://github.com/shriya999/bbc.git \n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LIAR-PLUS'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 77 (delta 2), reused 0 (delta 0), pack-reused 68\u001b[K\n",
            "Unpacking objects: 100% (77/77), done.\n",
            "LIAR-PLUS  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N66ahZvLsOrC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "ca78b3d7-cb1f-44c3-9564-fc6d4a7b6e2c"
      },
      "source": [
        "#sentence level case\n",
        "%cd /content/auth_id/utils\n",
        "!pip install Unidecode\n",
        "!python2 save_dictionary.py\n",
        "!python2 create_article_testset_C50.py\n",
        "!python2 create_article_trainset_C50.py\n",
        "!python2 preload_train_minibatch.py\n",
        "!python2 preload_test_minibatch.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/auth_id/utils\n",
            "Collecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/39/53096f9217b057cb049fe872b7fc7ce799a1a89b76cf917d9639e7a558b5/Unidecode-1.0.23-py2.py3-none-any.whl (237kB)\n",
            "\u001b[K    100% |████████████████████████████████| 245kB 5.0MB/s \n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.0.23\n",
            "abc\n",
            "Success!\n",
            "Success!\n",
            "Success!\n",
            "Success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTvYdyA8pyUm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "4a609159-a9b8-49ba-8c15-5dd374beec80"
      },
      "source": [
        "#article level cases for C50 dataset\n",
        "%cd /content/auth_id/utils\n",
        "!pip install Unidecode\n",
        "!python2 save_dictionary.py\n",
        "!python2 create_sent_set_C50_train.py\n",
        "!python2 create_sentence_set.py           # with glove for train data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/auth_id/utils\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python2.7/dist-packages (1.0.23)\n",
            "abc\n",
            "Success!\n",
            "Success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPHE4Rq0Nlt4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "5e2104c8-0049-4cc9-ed98-2e44ecfd67fe"
      },
      "source": [
        "#article level cases for bbc dataset\n",
        "%cd /content/auth_id/utils\n",
        "!pip install Unidecode\n",
        "!python2 save_dictionary.py\n",
        "!python2 create_sent_set_no_glove.py\n",
        "!python2 create_sentence_set_bbc.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/auth_id/utils\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python2.7/dist-packages (1.0.23)\n",
            "abc\n",
            "Success!\n",
            "Success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_9x_dOjTDjP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "c976f7c2-84fa-4846-b74d-8af96db119b4"
      },
      "source": [
        "%cd /content/auth_id\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/auth_id\n",
            "AttributionModel.py\t proj_gru_cell.py\t  RNN_sent_model.py\n",
            "data_analysis.py\t proj_rnn_cell.py\t  RNN_sent_model_test.py\n",
            "data_sentence_index.pkl  __pycache__\t\t  tokenToIndex\n",
            "data_sentence.pkl\t README.txt\t\t  trial.py\n",
            "forTest.py\t\t results\t\t  trial_tile.py\n",
            "glove_read_in_trial.py\t RNN_average_model.py\t  utils\n",
            "model.py\t\t RNN_model.py\n",
            "numpy_playground.py\t RNN_sent_model_embed.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giFU3WWNVxVc"
      },
      "source": [
        "# Create & upload a file.\n",
        "# uploaded = drive.CreateFile({'title': 'article_35epoch_11Nov.png'})\n",
        "# uploaded.SetContentFile('/content/auth_id/results/fig/confusion_matrix_gutenberg_sentence.png')\n",
        "# uploaded.Upload()\n",
        "# print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19TX_aCTvgw3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6746
        },
        "outputId": "8d96d721-5ac2-4389-9e88-eac48ac12dba"
      },
      "source": [
        "#RNN_sent_model_embed.py  for gru              ARTICLE LEVEL CASE\n",
        "\n",
        "\n",
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "\n",
        "import argparse\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import utils.file2dict as fdt\n",
        "import utils.read_minibatch as rmb\n",
        "import utils.data_util as data_util\n",
        "import utils.confusion_matrix as cm\n",
        "import utils.data_util as du\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from AttributionModel import AttributionModel\n",
        "from proj_rnn_cell import RNNCell\n",
        "from proj_gru_cell import GRUCell\n",
        "\n",
        "logger = logging.getLogger(\"RNN_Author_Attribution\")\n",
        "logger.setLevel(logging.DEBUG)\n",
        "logging.basicConfig(format='%(message)s', level=logging.DEBUG)\n",
        "\n",
        "tf.reset_default_graph()  #used so that variables gets reinitialized every time\n",
        "\n",
        "class Config:\n",
        "    cell_type=\"gru\" \n",
        "\n",
        "    window_size = 0\n",
        "\n",
        "    word_num = 30\n",
        "    max_length = 30 # longest length of a sentence we will process\n",
        "    n_classes = 50 # in total, we have 50 classes\n",
        "    dropout = 0.8\n",
        "\n",
        "    embed_size = 50\n",
        "\n",
        "    hidden_size = 300\n",
        "    batch_size = 16\n",
        "\n",
        "    n_epochs = 30\n",
        "    regularization = 0.00001\n",
        "\n",
        "    max_grad_norm = 10.0 # max gradients norm for clipping\n",
        "    lr = 0.004 # learning rate\n",
        "\n",
        "    def __init__(self, args):\n",
        "\n",
        "        #self.cell = args.cell\n",
        "\n",
        "        self.cell = GRUCell(Config.embed_size, Config.hidden_size)\n",
        "        if \"output_path\" in args:\n",
        "            # Where to save things.\n",
        "            self.output_path = args.output_path\n",
        "        else:\n",
        "            self.output_path = \"results/{}/{:%Y%m%d_%H%M%S}/\".format(\"RNN\", datetime.now())\n",
        "\n",
        "        self.model_output = self.output_path + \"model.weights\"\n",
        "        self.eval_output = self.output_path + \"results.txt\"\n",
        "\n",
        "        #self.conll_output = self.output_path + \"{}_predictions.conll\".format(self.cell)\n",
        "        self.log_output = self.output_path + \"log\"\n",
        "\n",
        "class RNNModel(AttributionModel):\n",
        "    def add_placeholders(self):\n",
        "        self.input_placeholder = tf.placeholder(tf.int32, [None, Config.max_length, Config.word_num])\n",
        "        self.batch_mask_placeholder = tf.placeholder(tf.float32, [None, Config.max_length, Config.word_num])\n",
        "        self.labels_placeholder = tf.placeholder(tf.int32, [None, Config.n_classes])\n",
        "        self.mask_placeholder = tf.placeholder(tf.float32, [None, Config.max_length])\n",
        "        self.dropout_placeholder = tf.placeholder(tf.float32)\n",
        "\n",
        "    def create_feed_dict(self, inputs_batch, batch_feat_mask, mask_batch, labels_batch=None, dropout=1): \n",
        "        feed_dict = {}\n",
        "        feed_dict[self.batch_mask_placeholder] = batch_feat_mask        #default value of dropout given as 1 so that not applied for test data\n",
        "        if labels_batch is not None:\n",
        "            feed_dict[self.labels_placeholder] = labels_batch\n",
        "        if inputs_batch is not None:\n",
        "            feed_dict[self.input_placeholder] = inputs_batch\n",
        "        if dropout is not None:\n",
        "            feed_dict[self.dropout_placeholder] = dropout\n",
        "        if mask_batch is not None:\n",
        "            feed_dict[self.mask_placeholder] = mask_batch\n",
        "\n",
        "        return feed_dict\n",
        "\n",
        "    def add_embedding(self):\n",
        "        embeddingTensor = tf.Variable(self.pretrained_embeddings, tf.float32)\n",
        "        embeddingsTemp = tf.nn.embedding_lookup(embeddingTensor, self.input_placeholder)\n",
        "        mask_batch = tf.reshape(self.batch_mask_placeholder, [-1, config.max_length, config.word_num, 1])\n",
        "        mask_batch = tf.tile(mask_batch, [1, 1, 1, config.embed_size])\n",
        "        embeddings = tf.multiply(embeddingsTemp, mask_batch)\n",
        "        #embeddings = tf.reshape(embeddings, [-1, config.max_length, config.word_num, config.embed_size])\n",
        "        embeddings = tf.reduce_sum(embeddings, axis = 2)\n",
        "        return embeddings\n",
        "\n",
        "    def add_prediction_op(self):\n",
        "        x = self.add_embedding()\n",
        "        #x = self.input_placeholder\n",
        "        if Config.cell_type==\"lstm\":\n",
        "            print \"lstm\"\n",
        "            cell_state = tf.zeros([tf.shape(x)[0], Config.hidden_size])\n",
        "            hidden_state = tf.zeros([tf.shape(x)[0], Config.hidden_size])\n",
        "            init_state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)\n",
        "            cell = tf.nn.rnn_cell.BasicLSTMCell(Config.hidden_size, state_is_tuple=True)\n",
        "            inputs_series=tf.split(x,Config.max_length,1)\n",
        "            inputs_series=[tf.reshape(one_input,[-1,Config.embed_size]) for one_input in inputs_series ]\n",
        "            outputs, current_state = tf.nn.static_rnn(cell, inputs_series, init_state)\n",
        "\n",
        "            self.U = tf.get_variable('U',\n",
        "                                  [Config.hidden_size, Config.n_classes],\n",
        "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
        "            self.b2 = tf.get_variable('b2',\n",
        "                                  [Config.n_classes, ],\n",
        "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
        "            h = tf.zeros([tf.shape(x)[0], Config.hidden_size])\n",
        "\n",
        "            preds=[tf.matmul(o, self.U) + self.b2 for o in outputs]\n",
        "            preds=tf.stack(preds)\n",
        "            preds=tf.reshape(tf.transpose(preds, [1, 0, 2]),[-1,Config.max_length,Config.n_classes])\n",
        "            return preds\n",
        "\n",
        "\n",
        "        else:\n",
        "            dropout_rate = self.dropout_placeholder\n",
        "\n",
        "            self.raw_preds = [] # Predicted output at each timestep should go here!\n",
        "\n",
        "            if Config.cell_type==\"rnn\":\n",
        "                cell = RNNCell(Config.embed_size, Config.hidden_size)\n",
        "            elif Config.cell_type==\"gru\":\n",
        "                cell = GRUCell(Config.embed_size, Config.hidden_size)\n",
        "            else:\n",
        "                assert False, \"Cell type undefined\"\n",
        "          \n",
        "            self.U = tf.get_variable('U',\n",
        "                                  [Config.hidden_size, Config.n_classes],\n",
        "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
        "            self.b2 = tf.get_variable('b2',\n",
        "                                  [Config.n_classes, ],\n",
        "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
        "            h = tf.zeros([tf.shape(x)[0], Config.hidden_size])\n",
        "\n",
        "            with tf.variable_scope(\"RNN\"):\n",
        "\n",
        "                for time_step in range(config.max_length):\n",
        "                    if time_step >= 1:\n",
        "                        tf.get_variable_scope().reuse_variables()\n",
        "                    o, h = cell(x[:,time_step,:], h)\n",
        "\n",
        "                    o_drop = tf.nn.dropout(o, dropout_rate)\n",
        "                    self.raw_preds.append(tf.matmul(o_drop, self.U) + self.b2)\n",
        "\n",
        "            preds=tf.stack(self.raw_preds)\n",
        "            preds=tf.reshape(tf.transpose(preds, [1, 0, 2]),[-1,Config.max_length,Config.n_classes])\n",
        "            return preds\n",
        "          \n",
        "    def add_loss_op(self, preds):\n",
        "        \n",
        "        self.pred_mask=tf.reshape(self.mask_placeholder,[-1,Config.max_length,1])\n",
        "        self.pred_mask=tf.tile(self.pred_mask,[1,1,Config.n_classes])\n",
        "\n",
        "        self.pred_masked=tf.multiply(preds,self.pred_mask)\n",
        "        self.pred_masked=tf.reduce_sum(self.pred_masked,axis=1)\n",
        "\n",
        "        loss = tf.nn.softmax_cross_entropy_with_logits(logits=self.pred_masked, labels=self.labels_placeholder)\n",
        "\n",
        "        loss = tf.reduce_mean(loss) + config.regularization * ( tf.nn.l2_loss(self.U) )\n",
        "\n",
        "        with tf.variable_scope(\"RNN/cell\", reuse= True):\n",
        "            # add regularization\n",
        "\n",
        "            if Config.cell_type=='gru':\n",
        "                loss += config.regularization * (tf.nn.l2_loss(tf.get_variable(\"W_r\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"U_r\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"W_z\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"U_z\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"W_o\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"U_o\")))\n",
        "        return loss\n",
        "          \n",
        "    def add_loss_op(self, preds):\n",
        "        \n",
        "        self.pred_mask=tf.reshape(self.mask_placeholder,[-1,Config.max_length,1])\n",
        "        self.pred_mask=tf.tile(self.pred_mask,[1,1,Config.n_classes])\n",
        "\n",
        "        self.pred_masked=tf.multiply(preds,self.pred_mask)\n",
        "        self.pred_masked=tf.reduce_sum(self.pred_masked,axis=1)\n",
        "\n",
        "        loss = tf.nn.softmax_cross_entropy_with_logits(logits=self.pred_masked, labels=self.labels_placeholder)\n",
        "\n",
        "        loss = tf.reduce_mean(loss) + config.regularization * ( tf.nn.l2_loss(self.U) )\n",
        "\n",
        "        with tf.variable_scope(\"RNN/cell\", reuse= True):\n",
        "            # add regularization\n",
        "\n",
        "            if Config.cell_type=='gru':\n",
        "                loss += config.regularization * (tf.nn.l2_loss(tf.get_variable(\"W_r\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"U_r\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"W_z\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"U_z\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"W_o\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"U_o\")))\n",
        "        return loss\n",
        "\n",
        "    def add_training_op(self, loss):\n",
        "        train_op = tf.train.AdamOptimizer(Config.lr).minimize(loss)\n",
        "        return train_op\n",
        "\n",
        "    def train_on_batch(self, sess, inputs_batch, batch_feat_mask, labels_batch, mask_batch):             #for train data\n",
        "\n",
        "        feed = self.create_feed_dict(inputs_batch, batch_feat_mask, labels_batch=labels_batch, mask_batch=mask_batch,\n",
        "                                     dropout=Config.dropout)\n",
        "        _, loss, pred, pred_mask = sess.run([self.train_op, self.loss, self.pred, self.pred_mask], feed_dict=feed)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def predict_on_batch(self, sess, inputs_batch, batch_feat_mask, mask_batch):         #for test data\n",
        "       \n",
        "        feed = self.create_feed_dict(inputs_batch, batch_feat_mask, mask_batch)\n",
        "        predictions = sess.run(tf.nn.softmax(self.pred), feed_dict=feed)\n",
        "        mask2=np.stack([mask_batch for i in range(Config.n_classes)] ,2)\n",
        "        pred2=np.sum(np.multiply(predictions,mask2),1)\n",
        "        return pred2\n",
        "\n",
        "    def record_history_init(self,f):\n",
        "        f.write(\"###\\n\")\n",
        "        f.write(\"training_model: \"+sys.argv[0]+\"\\n\")\n",
        "        f.write(\"starting_time: \"+str(datetime.now())+\"\\n\")\n",
        "        f.write(\"\\n\")\n",
        "        f.write(\"parameters:\\n\")\n",
        "        f.write(\"\\tcell_type: \"+Config.cell_type+\"\\n\")\n",
        "        f.write(\"\\tembed_size: {}\\n\".format(Config.embed_size))\n",
        "        f.write(\"\\thidden_size: {}\\n\".format(Config.hidden_size))\n",
        "        f.write(\"\\tlearning_rate: {0:.4f}\\n\".format(Config.lr))\n",
        "        f.write(\"\\tregularization: {0:.5f}\\n\".format(Config.regularization))\n",
        "        f.write(\"\\tdropout: {0:.5f}\\n\".format(Config.dropout))\n",
        "        f.write(\"\\tn_epochs: {0:.5f}\\n\".format(Config.n_epochs))\n",
        "        f.write(\"\\tbatch_size: {}\\n\".format(Config.batch_size))\n",
        "        f.write(\"\\n\")\n",
        "        f.write(\"training history:\\n\")\n",
        "        f.write(\"epoch \\t\\t loss \\t\\t train_accu \\t\\t test_accu\\n\")\n",
        "\n",
        "    def record_history_accu(self,f,n_epoch,average_train_loss,train_accu,test_accu):\n",
        "        f.write(\"{0:d} \\t\\t {1:.5f} \\t\\t {2:.5f} \\t\\t {3:.5f}\\n\".format(n_epoch,average_train_loss,train_accu,test_accu))\n",
        "\n",
        "    def record_history_finish(self,f):\n",
        "        f.write(\"END\\n\")\n",
        "        f.write(\"\\n\")\n",
        "        f.close()\n",
        "\n",
        "    def test_model(self, session, batch_list):\n",
        "        print \"Now, testing on the test set...\"\n",
        "        total = 0\n",
        "        accuCount = 0\n",
        "        pred_list = []\n",
        "        real_label_list = []\n",
        "\n",
        "        for batch in batch_list:\n",
        "            batch_feat = np.array(batch[1], dtype = np.int32)[:, :, 0, :]\n",
        "            batch_feat_mask = np.array(batch[1], dtype = np.float32)[:, :, 1, :]\n",
        "            batch_mask = np.array(batch[2], dtype = np.float32)\n",
        "\n",
        "            pred = self.predict_on_batch(session, batch_feat, batch_feat_mask, batch_mask)\n",
        "            accuCount += np.sum(np.argmax(pred,1) == batch[0])\n",
        "            pred_list.extend(np.argmax(pred,1).tolist())\n",
        "            total += len(batch[0])\n",
        "        accu = accuCount * 1.0 / total\n",
        "        logger.info( (\"Test accuracy %f\" %(accu)) )\n",
        "        return accu\n",
        "\n",
        "    def test_trainset_model(self, session, batch_list):\n",
        "        print \"Now, testing on the training set, notice this is only for debugging...\"\n",
        "        total = 0\n",
        "        accuCount = 0\n",
        "        for batch in batch_list:\n",
        "            batch_feat = np.array(batch[1], dtype = np.int32)[:, :, 0, :]\n",
        "            batch_feat_mask = np.array(batch[1], dtype = np.float32)[:, :, 1, :]\n",
        "            batch_mask = np.array(batch[2], dtype = np.float32)\n",
        "\n",
        "            pred = self.predict_on_batch(session, batch_feat, batch_feat_mask, batch_mask)\n",
        "            accuCount += np.sum(np.argmax(pred,1) == batch[0])\n",
        "            total += len(batch[0])\n",
        "        accu = accuCount * 1.0 / total\n",
        "        logger.info( (\"Test accuracy on training set is: %f\" %(accu)) )\n",
        "        return accu\n",
        "\n",
        "    def process_model_output(self):\n",
        "\n",
        "        pkl_file = open('/content/auth_id/data_sentence_index.pkl', 'rb') #changed filename from data_sentence_index_test to data_sentence to load train data\n",
        "        batch_list = pickle.load(pkl_file)\n",
        "        pkl_file.close()\n",
        "\n",
        "        test_size = int(len(batch_list) / 10)\n",
        "        training_batch = batch_list[0 : len(batch_list) - test_size]\n",
        "        print test_size, len(batch_list)\n",
        "        testing_batch = batch_list[len(batch_list) - test_size : len(batch_list)]\n",
        "\n",
        "        init = tf.global_variables_initializer()\n",
        "        saver = tf.train.Saver()\n",
        "        with tf.Session() as session:\n",
        "            session.run(init)\n",
        "            #load_path = \"results/RNN/20170318_221625/model.weights_10\"\n",
        "            saver.restore(session, \"./model_weights\")\n",
        "\n",
        "            print \"Now, collecting the model outputs...\"\n",
        "            total = 0\n",
        "            accuCount = 0\n",
        "            pred_list = []\n",
        "            real_label_list = []\n",
        "            for batch in testing_batch:\n",
        "                batch_feat = np.array(batch[1], dtype = np.int32)[:, :, 0, :]\n",
        "                batch_feat_mask = np.array(batch[1], dtype = np.float32)[:, :, 1, :]\n",
        "                batch_mask = np.array(batch[2], dtype = np.float32)\n",
        "\n",
        "                pred = self.predict_on_batch(session, batch_feat, batch_feat_mask, batch_mask)\n",
        "                accuCount += np.sum(np.argmax(pred,1) == batch[0])\n",
        "                pred_list.extend(np.argmax(pred,1).tolist())\n",
        "                real_label_list.extend(batch[0])\n",
        "                total += len(batch[0])\n",
        "            accu = accuCount * 1.0 / total\n",
        "            print( (\"Test accuracy %f\" %(accu)) )\n",
        "\n",
        "            t_cm = cm.generate_cm(real_label_list,pred_list, Config.n_classes)\n",
        "            x = t_cm.as_matrix().astype(np.uint8)\n",
        "            print x\n",
        "            du.visualize_cm(x, \"gutenberg_sentence\")\n",
        "            return accu        \n",
        "\n",
        "    def train_model(self):\n",
        "        # modify txt name from here\n",
        "        level='' # 'word' or ''\n",
        "        dataset='c50'\n",
        "        parameter='hs'\n",
        "        date='0319'\n",
        "        training_history_txt_filename='/content/auth_id/results/lstm'+level+'_'+parameter+'_'+dataset+'_'+date  +'.txt'\n",
        "\n",
        "        if not os.path.exists(config.log_output):\n",
        "            os.makedirs(os.path.dirname(config.log_output))\n",
        "        handler = logging.FileHandler(config.log_output)\n",
        "        handler.setLevel(logging.DEBUG)\n",
        "        handler.setFormatter(logging.Formatter('%(message)s'))\n",
        "        logging.getLogger().addHandler(handler)\n",
        "\n",
        "        pkl_file = open('/content/auth_id/data_sentence_index.pkl', 'rb')\n",
        "        batch_list = pickle.load(pkl_file)\n",
        "        pkl_file.close()\n",
        "\n",
        "        # write training_history\n",
        "        print training_history_txt_filename\n",
        "        training_history_file = open(training_history_txt_filename,'a+')\n",
        "        print training_history_file\n",
        "        self.record_history_init(training_history_file)\n",
        "\n",
        "        test_size = int(len(batch_list) / 10)\n",
        "        training_batch = batch_list[0 : len(batch_list) - test_size]\n",
        "        print test_size, len(batch_list)\n",
        "        testing_train_batch = batch_list[test_size : 2 * test_size]\n",
        "        testing_batch = batch_list[len(batch_list) - test_size : len(batch_list)]\n",
        "\n",
        "        init = tf.global_variables_initializer()\n",
        "        saver = tf.train.Saver()\n",
        "        with tf.Session() as session:\n",
        "            session.run(init)\n",
        "          \n",
        "            #the following is a test for what in tensor\n",
        "            batch = training_batch[0]\n",
        "            batch_label = rmb.convertOnehotLabel(batch[0],  Config.n_classes)\n",
        "            batch_feat = np.array(batch[1], dtype = np.int32)[:, :, 0, :]\n",
        "            batch_feat_mask = np.array(batch[1], dtype = np.float32)[:, :, 1, :]\n",
        "            batch_mask = np.array(batch[2], dtype = np.float32)\n",
        "            feed = self.create_feed_dict(batch_feat, batch_feat_mask, labels_batch=batch_label, mask_batch=batch_mask,\n",
        "                                     dropout=Config.dropout)\n",
        "            _, loss= session.run([self.train_op, self.loss, ], feed_dict=feed)\n",
        "            ##############\n",
        "\n",
        "\n",
        "            for iterTime in range(Config.n_epochs):\n",
        "                loss_list = []\n",
        "                smallIter = 0\n",
        "\n",
        "                for batch in training_batch:\n",
        "                    batch_label = rmb.convertOnehotLabel(batch[0],  Config.n_classes)\n",
        "                    batch_feat = np.array(batch[1], dtype = np.int32)[:, :, 0, :]\n",
        "                    batch_feat_mask = np.array(batch[1], dtype = np.float32)[:, :, 1, :]\n",
        "                    batch_mask = np.array(batch[2], dtype = np.float32)\n",
        "                    #print batch_mask\n",
        "                    loss = self.train_on_batch(session, batch_feat,batch_feat_mask, batch_label, batch_mask)\n",
        "                    loss_list.append(loss)\n",
        "                    smallIter += 1\n",
        "\n",
        "                    if(smallIter % 20 == 0):\n",
        "\n",
        "                        #self.test_trainset_model(session, testing_train_batch)\n",
        "                        #self.test_model(session, testing_batch)\n",
        "                        logger.info((\"Intermediate epoch %d Total Iteration %d: loss : %f\" %(iterTime, smallIter, np.mean(np.mean(np.array(loss)))) ))\n",
        "\n",
        "                # record training history on this epoch\n",
        "                train_accu=self.test_trainset_model(session, testing_train_batch)\n",
        "                test_accu=self.test_model(session, testing_batch)\n",
        "                average_train_loss=np.mean(np.array(loss_list))\n",
        "                self.record_history_accu(training_history_file,iterTime,average_train_loss,train_accu,test_accu)\n",
        "\n",
        "                if(iterTime % 10 == 0):\n",
        "                    logger.info((\"epoch %d : loss : %f\" %(iterTime, np.mean(np.mean(np.array(loss)))) ))\n",
        "                    saver.save(session, \"./model_weights\") #changed path name to model_weights\n",
        "\n",
        "                    #if(smallIter % 200 == 0):\n",
        "                    print (\"Intermediate epoch %d : loss : %f\" %(iterTime, np.mean(np.mean(np.array(loss)))) )\n",
        "\n",
        "            print (\"epoch %d : loss : %f\" %(iterTime, np.mean(np.mean(np.array(loss)))) )\n",
        "\n",
        "            self.record_history_finish(training_history_file)   #all logging on output screen in thru this function. Process model output only generates the confusion matrix\n",
        "\n",
        "\n",
        "\n",
        "    def __init__(self, config, pretrained_embeddings, report=None):\n",
        "\n",
        "        super(RNNModel, self).__init__(config)\n",
        "        self.pretrained_embeddings = pretrained_embeddings\n",
        "        self.raw_preds=None\n",
        "        self.input_placeholder = None\n",
        "        self.labels_placeholder = None\n",
        "        self.batch_mask_placeholder = None\n",
        "        self.mask_placeholder = None\n",
        "        self.dropout_placeholder = None\n",
        "\n",
        "        self.build()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = \"gru\"\n",
        "    config = Config(args)\n",
        "    glove_path = \"/content/glove.6B.50d.txt\"\n",
        "    glove_vector = data_util.load_embeddings(glove_path, config.embed_size)\n",
        "    model = RNNModel(config, glove_vector.astype(np.float32))\n",
        "\n",
        "    model.train_model()\n",
        "    model.process_model_output()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/auth_id/results/lstm_hs_c50_0319.txt\n",
            "<open file '/content/auth_id/results/lstm_hs_c50_0319.txt', mode 'a+' at 0x7fd191f7f930>\n",
            "15 157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Intermediate epoch 0 Total Iteration 20: loss : 3.610343\n",
            "INFO:Intermediate epoch 0 Total Iteration 40: loss : 3.353291\n",
            "INFO:Intermediate epoch 0 Total Iteration 60: loss : 3.169256\n",
            "INFO:Intermediate epoch 0 Total Iteration 80: loss : 2.473940\n",
            "INFO:Intermediate epoch 0 Total Iteration 100: loss : 2.925659\n",
            "INFO:Intermediate epoch 0 Total Iteration 120: loss : 2.646039\n",
            "INFO:Intermediate epoch 0 Total Iteration 140: loss : 2.389947\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 0.370833\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.263158\n",
            "INFO:epoch 0 : loss : 2.421933\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Intermediate epoch 0 : loss : 2.421933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Intermediate epoch 1 Total Iteration 20: loss : 2.179726\n",
            "INFO:Intermediate epoch 1 Total Iteration 40: loss : 1.873555\n",
            "INFO:Intermediate epoch 1 Total Iteration 60: loss : 1.376561\n",
            "INFO:Intermediate epoch 1 Total Iteration 80: loss : 1.532637\n",
            "INFO:Intermediate epoch 1 Total Iteration 100: loss : 1.906717\n",
            "INFO:Intermediate epoch 1 Total Iteration 120: loss : 1.431137\n",
            "INFO:Intermediate epoch 1 Total Iteration 140: loss : 1.236843\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 0.595833\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.548246\n",
            "INFO:Intermediate epoch 2 Total Iteration 20: loss : 1.159055\n",
            "INFO:Intermediate epoch 2 Total Iteration 40: loss : 1.248189\n",
            "INFO:Intermediate epoch 2 Total Iteration 60: loss : 0.785357\n",
            "INFO:Intermediate epoch 2 Total Iteration 80: loss : 0.909714\n",
            "INFO:Intermediate epoch 2 Total Iteration 100: loss : 1.173240\n",
            "INFO:Intermediate epoch 2 Total Iteration 120: loss : 0.603812\n",
            "INFO:Intermediate epoch 2 Total Iteration 140: loss : 0.881961\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 0.720833\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.548246\n",
            "INFO:Intermediate epoch 3 Total Iteration 20: loss : 0.944661\n",
            "INFO:Intermediate epoch 3 Total Iteration 40: loss : 0.629497\n",
            "INFO:Intermediate epoch 3 Total Iteration 60: loss : 0.783240\n",
            "INFO:Intermediate epoch 3 Total Iteration 80: loss : 0.478266\n",
            "INFO:Intermediate epoch 3 Total Iteration 100: loss : 1.013031\n",
            "INFO:Intermediate epoch 3 Total Iteration 120: loss : 0.450472\n",
            "INFO:Intermediate epoch 3 Total Iteration 140: loss : 0.647886\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 0.783333\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.578947\n",
            "INFO:Intermediate epoch 4 Total Iteration 20: loss : 0.597067\n",
            "INFO:Intermediate epoch 4 Total Iteration 40: loss : 0.297747\n",
            "INFO:Intermediate epoch 4 Total Iteration 60: loss : 0.298895\n",
            "INFO:Intermediate epoch 4 Total Iteration 80: loss : 0.233846\n",
            "INFO:Intermediate epoch 4 Total Iteration 100: loss : 0.349793\n",
            "INFO:Intermediate epoch 4 Total Iteration 120: loss : 0.081553\n",
            "INFO:Intermediate epoch 4 Total Iteration 140: loss : 0.383033\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 0.841667\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.570175\n",
            "INFO:Intermediate epoch 5 Total Iteration 20: loss : 0.645046\n",
            "INFO:Intermediate epoch 5 Total Iteration 40: loss : 0.143574\n",
            "INFO:Intermediate epoch 5 Total Iteration 60: loss : 0.124790\n",
            "INFO:Intermediate epoch 5 Total Iteration 80: loss : 0.130089\n",
            "INFO:Intermediate epoch 5 Total Iteration 100: loss : 0.247785\n",
            "INFO:Intermediate epoch 5 Total Iteration 120: loss : 0.058771\n",
            "INFO:Intermediate epoch 5 Total Iteration 140: loss : 0.255780\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 0.900000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.675439\n",
            "INFO:Intermediate epoch 6 Total Iteration 20: loss : 0.351277\n",
            "INFO:Intermediate epoch 6 Total Iteration 40: loss : 0.129348\n",
            "INFO:Intermediate epoch 6 Total Iteration 60: loss : 0.055131\n",
            "INFO:Intermediate epoch 6 Total Iteration 80: loss : 0.292213\n",
            "INFO:Intermediate epoch 6 Total Iteration 100: loss : 0.085032\n",
            "INFO:Intermediate epoch 6 Total Iteration 120: loss : 0.074938\n",
            "INFO:Intermediate epoch 6 Total Iteration 140: loss : 0.127338\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 0.941667\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.649123\n",
            "INFO:Intermediate epoch 7 Total Iteration 20: loss : 0.097491\n",
            "INFO:Intermediate epoch 7 Total Iteration 40: loss : 0.056320\n",
            "INFO:Intermediate epoch 7 Total Iteration 60: loss : 0.910366\n",
            "INFO:Intermediate epoch 7 Total Iteration 80: loss : 0.056322\n",
            "INFO:Intermediate epoch 7 Total Iteration 100: loss : 0.261098\n",
            "INFO:Intermediate epoch 7 Total Iteration 120: loss : 0.142968\n",
            "INFO:Intermediate epoch 7 Total Iteration 140: loss : 0.079078\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 0.987500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.662281\n",
            "INFO:Intermediate epoch 8 Total Iteration 20: loss : 0.046239\n",
            "INFO:Intermediate epoch 8 Total Iteration 40: loss : 0.187212\n",
            "INFO:Intermediate epoch 8 Total Iteration 60: loss : 0.111438\n",
            "INFO:Intermediate epoch 8 Total Iteration 80: loss : 0.060600\n",
            "INFO:Intermediate epoch 8 Total Iteration 100: loss : 0.033592\n",
            "INFO:Intermediate epoch 8 Total Iteration 120: loss : 0.034224\n",
            "INFO:Intermediate epoch 8 Total Iteration 140: loss : 0.042528\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 0.995833\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.697368\n",
            "INFO:Intermediate epoch 9 Total Iteration 20: loss : 0.046948\n",
            "INFO:Intermediate epoch 9 Total Iteration 40: loss : 0.037392\n",
            "INFO:Intermediate epoch 9 Total Iteration 60: loss : 0.031410\n",
            "INFO:Intermediate epoch 9 Total Iteration 80: loss : 0.034845\n",
            "INFO:Intermediate epoch 9 Total Iteration 100: loss : 0.146324\n",
            "INFO:Intermediate epoch 9 Total Iteration 120: loss : 0.037506\n",
            "INFO:Intermediate epoch 9 Total Iteration 140: loss : 0.045143\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 0.995833\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.657895\n",
            "INFO:Intermediate epoch 10 Total Iteration 20: loss : 0.037457\n",
            "INFO:Intermediate epoch 10 Total Iteration 40: loss : 0.035618\n",
            "INFO:Intermediate epoch 10 Total Iteration 60: loss : 0.031741\n",
            "INFO:Intermediate epoch 10 Total Iteration 80: loss : 0.032485\n",
            "INFO:Intermediate epoch 10 Total Iteration 100: loss : 0.034009\n",
            "INFO:Intermediate epoch 10 Total Iteration 120: loss : 0.032508\n",
            "INFO:Intermediate epoch 10 Total Iteration 140: loss : 0.035059\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.675439\n",
            "INFO:epoch 10 : loss : 0.032013\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Intermediate epoch 10 : loss : 0.032013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Intermediate epoch 11 Total Iteration 20: loss : 0.035148\n",
            "INFO:Intermediate epoch 11 Total Iteration 40: loss : 0.032333\n",
            "INFO:Intermediate epoch 11 Total Iteration 60: loss : 0.030576\n",
            "INFO:Intermediate epoch 11 Total Iteration 80: loss : 0.031143\n",
            "INFO:Intermediate epoch 11 Total Iteration 100: loss : 0.033848\n",
            "INFO:Intermediate epoch 11 Total Iteration 120: loss : 0.031129\n",
            "INFO:Intermediate epoch 11 Total Iteration 140: loss : 0.031163\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.692982\n",
            "INFO:Intermediate epoch 12 Total Iteration 20: loss : 0.032431\n",
            "INFO:Intermediate epoch 12 Total Iteration 40: loss : 0.031194\n",
            "INFO:Intermediate epoch 12 Total Iteration 60: loss : 0.029577\n",
            "INFO:Intermediate epoch 12 Total Iteration 80: loss : 0.030100\n",
            "INFO:Intermediate epoch 12 Total Iteration 100: loss : 0.029319\n",
            "INFO:Intermediate epoch 12 Total Iteration 120: loss : 0.029594\n",
            "INFO:Intermediate epoch 12 Total Iteration 140: loss : 0.029457\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.710526\n",
            "INFO:Intermediate epoch 13 Total Iteration 20: loss : 0.031208\n",
            "INFO:Intermediate epoch 13 Total Iteration 40: loss : 0.029778\n",
            "INFO:Intermediate epoch 13 Total Iteration 60: loss : 0.028568\n",
            "INFO:Intermediate epoch 13 Total Iteration 80: loss : 0.028842\n",
            "INFO:Intermediate epoch 13 Total Iteration 100: loss : 0.028410\n",
            "INFO:Intermediate epoch 13 Total Iteration 120: loss : 0.028519\n",
            "INFO:Intermediate epoch 13 Total Iteration 140: loss : 0.029108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.710526\n",
            "INFO:Intermediate epoch 14 Total Iteration 20: loss : 0.028781\n",
            "INFO:Intermediate epoch 14 Total Iteration 40: loss : 0.028943\n",
            "INFO:Intermediate epoch 14 Total Iteration 60: loss : 0.027474\n",
            "INFO:Intermediate epoch 14 Total Iteration 80: loss : 0.027440\n",
            "INFO:Intermediate epoch 14 Total Iteration 100: loss : 0.027266\n",
            "INFO:Intermediate epoch 14 Total Iteration 120: loss : 0.027247\n",
            "INFO:Intermediate epoch 14 Total Iteration 140: loss : 0.027422\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.719298\n",
            "INFO:Intermediate epoch 15 Total Iteration 20: loss : 0.028033\n",
            "INFO:Intermediate epoch 15 Total Iteration 40: loss : 0.027523\n",
            "INFO:Intermediate epoch 15 Total Iteration 60: loss : 0.026378\n",
            "INFO:Intermediate epoch 15 Total Iteration 80: loss : 0.026350\n",
            "INFO:Intermediate epoch 15 Total Iteration 100: loss : 0.026101\n",
            "INFO:Intermediate epoch 15 Total Iteration 120: loss : 0.026154\n",
            "INFO:Intermediate epoch 15 Total Iteration 140: loss : 0.026276\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.719298\n",
            "INFO:Intermediate epoch 16 Total Iteration 20: loss : 0.026684\n",
            "INFO:Intermediate epoch 16 Total Iteration 40: loss : 0.026029\n",
            "INFO:Intermediate epoch 16 Total Iteration 60: loss : 0.025299\n",
            "INFO:Intermediate epoch 16 Total Iteration 80: loss : 0.025203\n",
            "INFO:Intermediate epoch 16 Total Iteration 100: loss : 0.024992\n",
            "INFO:Intermediate epoch 16 Total Iteration 120: loss : 0.025031\n",
            "INFO:Intermediate epoch 16 Total Iteration 140: loss : 0.024986\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.723684\n",
            "INFO:Intermediate epoch 17 Total Iteration 20: loss : 0.025434\n",
            "INFO:Intermediate epoch 17 Total Iteration 40: loss : 0.025092\n",
            "INFO:Intermediate epoch 17 Total Iteration 60: loss : 0.024229\n",
            "INFO:Intermediate epoch 17 Total Iteration 80: loss : 0.024143\n",
            "INFO:Intermediate epoch 17 Total Iteration 100: loss : 0.023900\n",
            "INFO:Intermediate epoch 17 Total Iteration 120: loss : 0.023890\n",
            "INFO:Intermediate epoch 17 Total Iteration 140: loss : 0.023892\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.710526\n",
            "INFO:Intermediate epoch 18 Total Iteration 20: loss : 0.024999\n",
            "INFO:Intermediate epoch 18 Total Iteration 40: loss : 0.024060\n",
            "INFO:Intermediate epoch 18 Total Iteration 60: loss : 0.023143\n",
            "INFO:Intermediate epoch 18 Total Iteration 80: loss : 0.023082\n",
            "INFO:Intermediate epoch 18 Total Iteration 100: loss : 0.022830\n",
            "INFO:Intermediate epoch 18 Total Iteration 120: loss : 0.022839\n",
            "INFO:Intermediate epoch 18 Total Iteration 140: loss : 0.022790\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.710526\n",
            "INFO:Intermediate epoch 19 Total Iteration 20: loss : 0.023041\n",
            "INFO:Intermediate epoch 19 Total Iteration 40: loss : 0.022660\n",
            "INFO:Intermediate epoch 19 Total Iteration 60: loss : 0.022089\n",
            "INFO:Intermediate epoch 19 Total Iteration 80: loss : 0.021987\n",
            "INFO:Intermediate epoch 19 Total Iteration 100: loss : 0.021776\n",
            "INFO:Intermediate epoch 19 Total Iteration 120: loss : 0.021738\n",
            "INFO:Intermediate epoch 19 Total Iteration 140: loss : 0.021745\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.710526\n",
            "INFO:Intermediate epoch 20 Total Iteration 20: loss : 0.022797\n",
            "INFO:Intermediate epoch 20 Total Iteration 40: loss : 0.021725\n",
            "INFO:Intermediate epoch 20 Total Iteration 60: loss : 0.021056\n",
            "INFO:Intermediate epoch 20 Total Iteration 80: loss : 0.020951\n",
            "INFO:Intermediate epoch 20 Total Iteration 100: loss : 0.020724\n",
            "INFO:Intermediate epoch 20 Total Iteration 120: loss : 0.020710\n",
            "INFO:Intermediate epoch 20 Total Iteration 140: loss : 0.020688\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.710526\n",
            "INFO:epoch 20 : loss : 0.020373\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Intermediate epoch 20 : loss : 0.020373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Intermediate epoch 21 Total Iteration 20: loss : 0.020995\n",
            "INFO:Intermediate epoch 21 Total Iteration 40: loss : 0.020541\n",
            "INFO:Intermediate epoch 21 Total Iteration 60: loss : 0.020014\n",
            "INFO:Intermediate epoch 21 Total Iteration 80: loss : 0.019919\n",
            "INFO:Intermediate epoch 21 Total Iteration 100: loss : 0.019697\n",
            "INFO:Intermediate epoch 21 Total Iteration 120: loss : 0.019636\n",
            "INFO:Intermediate epoch 21 Total Iteration 140: loss : 0.019605\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.714912\n",
            "INFO:Intermediate epoch 22 Total Iteration 20: loss : 0.020392\n",
            "INFO:Intermediate epoch 22 Total Iteration 40: loss : 0.019655\n",
            "INFO:Intermediate epoch 22 Total Iteration 60: loss : 0.019009\n",
            "INFO:Intermediate epoch 22 Total Iteration 80: loss : 0.018917\n",
            "INFO:Intermediate epoch 22 Total Iteration 100: loss : 0.018695\n",
            "INFO:Intermediate epoch 22 Total Iteration 120: loss : 0.018640\n",
            "INFO:Intermediate epoch 22 Total Iteration 140: loss : 0.018733\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.714912\n",
            "INFO:Intermediate epoch 23 Total Iteration 20: loss : 0.019041\n",
            "INFO:Intermediate epoch 23 Total Iteration 40: loss : 0.018776\n",
            "INFO:Intermediate epoch 23 Total Iteration 60: loss : 0.018029\n",
            "INFO:Intermediate epoch 23 Total Iteration 80: loss : 0.017970\n",
            "INFO:Intermediate epoch 23 Total Iteration 100: loss : 0.017719\n",
            "INFO:Intermediate epoch 23 Total Iteration 120: loss : 0.017679\n",
            "INFO:Intermediate epoch 23 Total Iteration 140: loss : 0.017705\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.706140\n",
            "INFO:Intermediate epoch 24 Total Iteration 20: loss : 0.017838\n",
            "INFO:Intermediate epoch 24 Total Iteration 40: loss : 0.017773\n",
            "INFO:Intermediate epoch 24 Total Iteration 60: loss : 0.017087\n",
            "INFO:Intermediate epoch 24 Total Iteration 80: loss : 0.016984\n",
            "INFO:Intermediate epoch 24 Total Iteration 100: loss : 0.016777\n",
            "INFO:Intermediate epoch 24 Total Iteration 120: loss : 0.016740\n",
            "INFO:Intermediate epoch 24 Total Iteration 140: loss : 0.016819\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.701754\n",
            "INFO:Intermediate epoch 25 Total Iteration 20: loss : 0.016963\n",
            "INFO:Intermediate epoch 25 Total Iteration 40: loss : 0.016835\n",
            "INFO:Intermediate epoch 25 Total Iteration 60: loss : 0.016157\n",
            "INFO:Intermediate epoch 25 Total Iteration 80: loss : 0.016136\n",
            "INFO:Intermediate epoch 25 Total Iteration 100: loss : 0.015869\n",
            "INFO:Intermediate epoch 25 Total Iteration 120: loss : 0.015828\n",
            "INFO:Intermediate epoch 25 Total Iteration 140: loss : 0.015879\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.706140\n",
            "INFO:Intermediate epoch 26 Total Iteration 20: loss : 0.016414\n",
            "INFO:Intermediate epoch 26 Total Iteration 40: loss : 0.015929\n",
            "INFO:Intermediate epoch 26 Total Iteration 60: loss : 0.015297\n",
            "INFO:Intermediate epoch 26 Total Iteration 80: loss : 0.015220\n",
            "INFO:Intermediate epoch 26 Total Iteration 100: loss : 0.014991\n",
            "INFO:Intermediate epoch 26 Total Iteration 120: loss : 0.014948\n",
            "INFO:Intermediate epoch 26 Total Iteration 140: loss : 0.015059\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.710526\n",
            "INFO:Intermediate epoch 27 Total Iteration 20: loss : 0.015354\n",
            "INFO:Intermediate epoch 27 Total Iteration 40: loss : 0.015080\n",
            "INFO:Intermediate epoch 27 Total Iteration 60: loss : 0.014448\n",
            "INFO:Intermediate epoch 27 Total Iteration 80: loss : 0.014378\n",
            "INFO:Intermediate epoch 27 Total Iteration 100: loss : 0.014161\n",
            "INFO:Intermediate epoch 27 Total Iteration 120: loss : 0.014103\n",
            "INFO:Intermediate epoch 27 Total Iteration 140: loss : 0.014098\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.710526\n",
            "INFO:Intermediate epoch 28 Total Iteration 20: loss : 0.014281\n",
            "INFO:Intermediate epoch 28 Total Iteration 40: loss : 0.014114\n",
            "INFO:Intermediate epoch 28 Total Iteration 60: loss : 0.013658\n",
            "INFO:Intermediate epoch 28 Total Iteration 80: loss : 0.013619\n",
            "INFO:Intermediate epoch 28 Total Iteration 100: loss : 0.013370\n",
            "INFO:Intermediate epoch 28 Total Iteration 120: loss : 0.013324\n",
            "INFO:Intermediate epoch 28 Total Iteration 140: loss : 0.013367\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.706140\n",
            "INFO:Intermediate epoch 29 Total Iteration 20: loss : 0.013610\n",
            "INFO:Intermediate epoch 29 Total Iteration 40: loss : 0.013373\n",
            "INFO:Intermediate epoch 29 Total Iteration 60: loss : 0.012859\n",
            "INFO:Intermediate epoch 29 Total Iteration 80: loss : 0.012806\n",
            "INFO:Intermediate epoch 29 Total Iteration 100: loss : 0.012626\n",
            "INFO:Intermediate epoch 29 Total Iteration 120: loss : 0.012584\n",
            "INFO:Intermediate epoch 29 Total Iteration 140: loss : 0.012634\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 1.000000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.697368\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 29 : loss : 0.012394\n",
            "15 157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Restoring parameters from ./model_weights\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, collecting the model outputs...\n",
            "Test accuracy 0.710526\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 1 0 0]\n",
            " [0 0 5 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 3 0 0]\n",
            " [0 0 0 ... 0 3 0]\n",
            " [0 0 0 ... 0 0 4]]\n",
            "./results/fig/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAFOCAYAAABql81SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngj4AWISgDwAW+R8JQ2oQFpZinQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd18d35f690>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1l4INy2EHx3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2669
        },
        "outputId": "f73bc1d7-42b0-4917-b3b0-9bb5c886505c"
      },
      "source": [
        "%cd /content/auth_id/results/\n",
        "!cat lstm_hs_c50_0319.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/auth_id/results\n",
            "\n",
            "###\n",
            "training_model: /usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\n",
            "starting_time: 2019-01-02 13:39:33.659288\n",
            "\n",
            "parameters:\n",
            "\tcell_type: gru\n",
            "\tembed_size: 50\n",
            "\thidden_size: 200\n",
            "\tlearning_rate: 0.0040\n",
            "\tregularization: 0.00001\n",
            "\tdropout: 0.80000\n",
            "\tn_epochs: 30.00000\n",
            "\tbatch_size: 16\n",
            "\n",
            "training history:\n",
            "epoch \t\t loss \t\t train_accu \t\t test_accu\n",
            "0 \t\t 3.07070 \t\t 0.32500 \t\t 0.28070\n",
            "1 \t\t 1.65292 \t\t 0.59583 \t\t 0.50000\n",
            "2 \t\t 0.99593 \t\t 0.72917 \t\t 0.53509\n",
            "3 \t\t 0.62725 \t\t 0.77500 \t\t 0.56140\n",
            "4 \t\t 0.34424 \t\t 0.85833 \t\t 0.62281\n",
            "5 \t\t 0.25991 \t\t 0.92917 \t\t 0.67105\n",
            "6 \t\t 0.13242 \t\t 0.97083 \t\t 0.69737\n",
            "7 \t\t 0.06979 \t\t 0.97083 \t\t 0.67544\n",
            "8 \t\t 0.05787 \t\t 0.99583 \t\t 0.67982\n",
            "9 \t\t 0.04929 \t\t 0.96250 \t\t 0.67544\n",
            "10 \t\t 0.04644 \t\t 0.98333 \t\t 0.66228\n",
            "11 \t\t 0.05906 \t\t 1.00000 \t\t 0.71491\n",
            "12 \t\t 0.05909 \t\t 0.99583 \t\t 0.66667\n",
            "13 \t\t 0.05987 \t\t 0.98750 \t\t 0.68860\n",
            "14 \t\t 0.03317 \t\t 1.00000 \t\t 0.71930\n",
            "15 \t\t 0.02503 \t\t 1.00000 \t\t 0.71491\n",
            "16 \t\t 0.02373 \t\t 1.00000 \t\t 0.70614\n",
            "17 \t\t 0.02300 \t\t 1.00000 \t\t 0.70175\n",
            "18 \t\t 0.02231 \t\t 1.00000 \t\t 0.70175\n",
            "19 \t\t 0.02168 \t\t 1.00000 \t\t 0.69737\n",
            "20 \t\t 0.02105 \t\t 1.00000 \t\t 0.70175\n",
            "21 \t\t 0.02044 \t\t 1.00000 \t\t 0.70175\n",
            "22 \t\t 0.01980 \t\t 1.00000 \t\t 0.70614\n",
            "23 \t\t 0.01919 \t\t 1.00000 \t\t 0.70614\n",
            "24 \t\t 0.01856 \t\t 1.00000 \t\t 0.70614\n",
            "25 \t\t 0.01794 \t\t 1.00000 \t\t 0.70175\n",
            "26 \t\t 0.01732 \t\t 1.00000 \t\t 0.70175\n",
            "27 \t\t 0.01669 \t\t 1.00000 \t\t 0.70614\n",
            "28 \t\t 0.01606 \t\t 1.00000 \t\t 0.71930\n",
            "29 \t\t 0.01545 \t\t 1.00000 \t\t 0.71491\n",
            "END\n",
            "\n",
            "###\n",
            "training_model: /usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\n",
            "starting_time: 2019-01-02 13:56:07.919277\n",
            "\n",
            "parameters:\n",
            "\tcell_type: gru\n",
            "\tembed_size: 50\n",
            "\thidden_size: 250\n",
            "\tlearning_rate: 0.0040\n",
            "\tregularization: 0.00001\n",
            "\tdropout: 0.80000\n",
            "\tn_epochs: 30.00000\n",
            "\tbatch_size: 16\n",
            "\n",
            "training history:\n",
            "epoch \t\t loss \t\t train_accu \t\t test_accu\n",
            "0 \t\t 3.01146 \t\t 0.31250 \t\t 0.30263\n",
            "1 \t\t 1.65499 \t\t 0.62083 \t\t 0.51316\n",
            "2 \t\t 0.98047 \t\t 0.74583 \t\t 0.58333\n",
            "3 \t\t 0.57494 \t\t 0.84167 \t\t 0.56579\n",
            "4 \t\t 0.33846 \t\t 0.89583 \t\t 0.63596\n",
            "5 \t\t 0.19805 \t\t 0.94583 \t\t 0.65351\n",
            "6 \t\t 0.12702 \t\t 0.95833 \t\t 0.64912\n",
            "7 \t\t 0.09498 \t\t 0.96250 \t\t 0.69737\n",
            "8 \t\t 0.05375 \t\t 0.98333 \t\t 0.70175\n",
            "9 \t\t 0.05396 \t\t 0.96250 \t\t 0.66228\n",
            "10 \t\t 0.05602 \t\t 0.99167 \t\t 0.71491\n",
            "11 \t\t 0.04118 \t\t 1.00000 \t\t 0.69298\n",
            "12 \t\t 0.03025 \t\t 1.00000 \t\t 0.70614\n",
            "13 \t\t 0.02686 \t\t 1.00000 \t\t 0.71491\n",
            "14 \t\t 0.02579 \t\t 1.00000 \t\t 0.71930\n",
            "15 \t\t 0.02489 \t\t 1.00000 \t\t 0.71491\n",
            "16 \t\t 0.02404 \t\t 1.00000 \t\t 0.71491\n",
            "17 \t\t 0.02323 \t\t 1.00000 \t\t 0.71053\n",
            "18 \t\t 0.02241 \t\t 1.00000 \t\t 0.71491\n",
            "19 \t\t 0.02159 \t\t 1.00000 \t\t 0.71491\n",
            "20 \t\t 0.02078 \t\t 1.00000 \t\t 0.71053\n",
            "21 \t\t 0.01998 \t\t 1.00000 \t\t 0.71053\n",
            "22 \t\t 0.01916 \t\t 1.00000 \t\t 0.71491\n",
            "23 \t\t 0.01837 \t\t 1.00000 \t\t 0.71491\n",
            "24 \t\t 0.01756 \t\t 1.00000 \t\t 0.71491\n",
            "25 \t\t 0.01679 \t\t 1.00000 \t\t 0.71930\n",
            "26 \t\t 0.01603 \t\t 1.00000 \t\t 0.71491\n",
            "27 \t\t 0.01528 \t\t 1.00000 \t\t 0.71491\n",
            "28 \t\t 0.01456 \t\t 1.00000 \t\t 0.71491\n",
            "29 \t\t 0.01385 \t\t 1.00000 \t\t 0.72368\n",
            "END\n",
            "\n",
            "###\n",
            "training_model: /usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\n",
            "starting_time: 2019-01-02 14:41:09.919369\n",
            "\n",
            "parameters:\n",
            "\tcell_type: gru\n",
            "\tembed_size: 50\n",
            "\thidden_size: 300\n",
            "\tlearning_rate: 0.0040\n",
            "\tregularization: 0.00001\n",
            "\tdropout: 0.80000\n",
            "\tn_epochs: 30.00000\n",
            "\tbatch_size: 16\n",
            "\n",
            "training history:\n",
            "epoch \t\t loss \t\t train_accu \t\t test_accu\n",
            "0 \t\t 2.99281 \t\t 0.37083 \t\t 0.26316\n",
            "1 \t\t 1.61544 \t\t 0.59583 \t\t 0.54825\n",
            "2 \t\t 0.94744 \t\t 0.72083 \t\t 0.54825\n",
            "3 \t\t 0.56656 \t\t 0.78333 \t\t 0.57895\n",
            "4 \t\t 0.32071 \t\t 0.84167 \t\t 0.57018\n",
            "5 \t\t 0.21114 \t\t 0.90000 \t\t 0.67544\n",
            "6 \t\t 0.12420 \t\t 0.94167 \t\t 0.64912\n",
            "7 \t\t 0.11098 \t\t 0.98750 \t\t 0.66228\n",
            "8 \t\t 0.06408 \t\t 0.99583 \t\t 0.69737\n",
            "9 \t\t 0.05507 \t\t 0.99583 \t\t 0.65789\n",
            "10 \t\t 0.04309 \t\t 1.00000 \t\t 0.67544\n",
            "11 \t\t 0.03455 \t\t 1.00000 \t\t 0.69298\n",
            "12 \t\t 0.03098 \t\t 1.00000 \t\t 0.71053\n",
            "13 \t\t 0.02914 \t\t 1.00000 \t\t 0.71053\n",
            "14 \t\t 0.02761 \t\t 1.00000 \t\t 0.71930\n",
            "15 \t\t 0.02644 \t\t 1.00000 \t\t 0.71930\n",
            "16 \t\t 0.02534 \t\t 1.00000 \t\t 0.72368\n",
            "17 \t\t 0.02423 \t\t 1.00000 \t\t 0.71053\n",
            "18 \t\t 0.02316 \t\t 1.00000 \t\t 0.71053\n",
            "19 \t\t 0.02207 \t\t 1.00000 \t\t 0.71053\n",
            "20 \t\t 0.02103 \t\t 1.00000 \t\t 0.71053\n",
            "21 \t\t 0.01999 \t\t 1.00000 \t\t 0.71491\n",
            "22 \t\t 0.01898 \t\t 1.00000 \t\t 0.71491\n",
            "23 \t\t 0.01800 \t\t 1.00000 \t\t 0.70614\n",
            "24 \t\t 0.01705 \t\t 1.00000 \t\t 0.70175\n",
            "25 \t\t 0.01613 \t\t 1.00000 \t\t 0.70614\n",
            "26 \t\t 0.01526 \t\t 1.00000 \t\t 0.71053\n",
            "27 \t\t 0.01442 \t\t 1.00000 \t\t 0.71053\n",
            "28 \t\t 0.01361 \t\t 1.00000 \t\t 0.70614\n",
            "29 \t\t 0.01284 \t\t 1.00000 \t\t 0.69737\n",
            "END\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y33X_RKfgIID",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1788
        },
        "outputId": "a1ce14ec-ee4b-47a4-d620-8568e24f7f89"
      },
      "source": [
        "%cd /content/auth_id/\n",
        "\n",
        "#data analysis.py\n",
        "\n",
        "import utils.parse_history as ph\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import os\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from cycler import cycler\n",
        "\n",
        "def get_data_epoch_loss(one_th):\n",
        "    return [one_th.epoch, one_th.loss]\n",
        "\n",
        "def get_data_epoch_train(one_th):\n",
        "    return [one_th.epoch, one_th.train_accu]\n",
        "\n",
        "def get_data_epoch_test(one_th):\n",
        "    return [one_th.epoch, one_th.test_accu]\n",
        "\n",
        "def get_final_train_accu(one_th):\n",
        "    return np.amax(one_th.train_accu)\n",
        "\n",
        "def get_final_test_accu(one_th):\n",
        "    return np.amax(one_th.test_accu)\n",
        "\n",
        "\n",
        "def analysis():\n",
        "    dataset='gutenberg'\n",
        "    parameter='hs'\n",
        "    date='0318'\n",
        "    para_name='hidden_size'\n",
        "    training_history_txt_filename='/content/auth_id/results/lstm_hs_c50_0319.txt'\n",
        "    output_path='/content/auth_id/results/'\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "    f=open(training_history_txt_filename,'r')\n",
        "    training_history_list=ph.parse_file(f)\n",
        "    f.close()\n",
        "\n",
        "    num_models=len(training_history_list)\n",
        "\n",
        "    # get the learning_rate and test accuracies\n",
        "    epoch=training_history_list[0].epoch\n",
        "\n",
        "    paras=[]\n",
        "    losses=[]\n",
        "    train_accus=[]\n",
        "    test_accus=[]\n",
        "    for i in range(num_models):\n",
        "        one_th=training_history_list[i]\n",
        "        \"\"\"\n",
        "        choose parameter here\n",
        "        \"\"\"\n",
        "        paras.append(one_th.hidden_size)\n",
        "        losses.append(one_th.loss)\n",
        "        train_accus.append(one_th.train_accu)\n",
        "        test_accus.append(one_th.test_accu)\n",
        "\n",
        "\n",
        "#     fig1=plt.figure(1)\n",
        "#     plt.xlabel('epoch')\n",
        "#     plt.ylabel('loss')\n",
        "#     handles1=[]\n",
        "\n",
        "    fig2=plt.figure(2)\n",
        "    plt.xlabel('epoch',fontsize=15, fontweight='bold')\n",
        "    plt.ylabel('train accuracy',fontsize=15, fontweight='bold')\n",
        "    handles2=[]\n",
        "\n",
        "    fig3=plt.figure(3)\n",
        "    plt.xlabel('epoch',fontsize=15, fontweight='bold')\n",
        "    plt.ylabel('test accuracy',fontsize=15, fontweight='bold')\n",
        "    handles3=[]\n",
        "    \n",
        "    for i in range(num_models):\n",
        "#         plt.figure(1)\n",
        "#         line1, =plt.plot(epoch,losses[i],label=para_name+'='+str(paras[i]))\n",
        "#         handles1.append(line1)\n",
        "\n",
        "        linestyle_cycler = cycler('linestyle',['-','--',':','-.'])\n",
        "        plt.rc('axes', prop_cycle=linestyle_cycler)\n",
        "\n",
        "        plt.figure(2)\n",
        "        line2, =plt.plot(epoch,train_accus[i],label=para_name+'='+str(paras[i]))\n",
        "        handles2.append(line2)\n",
        "\n",
        "        plt.figure(3)\n",
        "        line3, =plt.plot(epoch,test_accus[i],label=para_name+'='+str(paras[i]))\n",
        "        handles3.append(line3)\n",
        "\n",
        "#     plt.figure(1)\n",
        "#     plt.legend(handles=handles1,loc='upper right')\n",
        "    plt.figure(2)\n",
        "    plt.legend(handles=handles2,loc='lower right')\n",
        "    plt.figure(3)\n",
        "    plt.legend(handles=handles3,loc='lower right')\n",
        "\n",
        "\n",
        "#     fig1.savefig(output_path+'/epoch_loss.png')\n",
        "    fig2.savefig(output_path+'/epoch_train_accu.png')\n",
        "    fig3.savefig(output_path+'/epoch_test_accu.png')\n",
        "\n",
        "    fig4=plt.figure(4)\n",
        "    plt.figure(4)\n",
        "\n",
        "    final_train_accus=[]\n",
        "    final_test_accus=[]\n",
        "    for i in range(num_models):\n",
        "        one_th=training_history_list[i]\n",
        "        final_train_accus.append(get_final_train_accu(one_th))\n",
        "        final_test_accus.append(get_final_test_accu(one_th))\n",
        "\n",
        "    line_train, =plt.plot(paras,final_train_accus,label='train')\n",
        "    line_test, =plt.plot(paras,final_test_accus,label='test')\n",
        "    plt.xlabel(para_name,fontsize=15, fontweight='bold')\n",
        "    plt.ylabel('accuracy',fontsize=15, fontweight='bold')\n",
        "    plt.grid(True)\n",
        "    plt.legend(handles=[line_train,line_test])\n",
        "    fig4.savefig(output_path+'/parameter.png')\n",
        "\n",
        "def main():\n",
        "    analysis()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/auth_id\n",
            "['/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', '2019-01-02 13:39:33.659288', 'gru', 50, 200, 0.004, 1e-05, 16]\n",
            "['/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', '2019-01-02 13:56:07.919277', 'gru', 50, 250, 0.004, 1e-05, 16]\n",
            "['/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', '2019-01-02 14:41:09.919369', 'gru', 50, 300, 0.004, 1e-05, 16]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:9: UserWarning: \n",
            "This call to matplotlib.use() has no effect because the backend has already\n",
            "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
            "or matplotlib.backends is imported for the first time.\n",
            "\n",
            "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
            "    \"__main__\", fname, loader, pkg_name)\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
            "    exec code in run_globals\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 657, in launch_instance\n",
            "    app.initialize(argv)\n",
            "  File \"<decorator-gen-121>\", line 2, in initialize\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 87, in catch_config_error\n",
            "    return method(app, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 462, in initialize\n",
            "    self.init_gui_pylab()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 403, in init_gui_pylab\n",
            "    InteractiveShellApp.init_gui_pylab(self)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/shellapp.py\", line 213, in init_gui_pylab\n",
            "    r = enable(key)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2950, in enable_matplotlib\n",
            "    pt.activate_matplotlib(backend)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/pylabtools.py\", line 309, in activate_matplotlib\n",
            "    matplotlib.pyplot.switch_backend(backend)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py\", line 232, in switch_backend\n",
            "    matplotlib.use(newbackend, warn=False, force=True)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py\", line 1305, in use\n",
            "    reload(sys.modules['matplotlib.backends'])\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
            "    line for line in traceback.format_stack()\n",
            "\n",
            "\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAFcCAYAAADcRVdwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nG6diLiIiYuNUzEVERGzcfwGQKyC3w3lhcAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd192458110>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAFcCAYAAADcRVdwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3XVcVecfwPHPJQVBQgG7AIuwa3bH\nDGzsQKduYm9O52bX7Jitc7Zi6+zuVlSwwVYEBaTz/v5gnN8YF70oIfp9v157zXvOc8758sC933ue\n84RKrVarEUIIIUSWpZPZAQghhBDi00gyF0IIIbI4SeZCCCFEFifJXAghhMjiJJkLIYQQWZwkcyGE\nECKL08vsAD6Wv3+Ixu0WFsYEBoZncDSfP6kXzaReNJN60UzqRTOpF83So16srEw1bv/i7sz19HQz\nO4TPktSLZlIvmkm9aCb1opnUi2YZWS9fXDIXQgghvjaSzIUQQogsTpK5EEIIkcVJMhdCCCGyOEnm\nQgghRBYnyVwIIYTI4iSZCyGEEFmcJHMhhBAii5NkLoQQQmRxksyFEEKILE6SuRAiUwUEBLBmzSre\nvQvO7FCESBNqtZqLFy8QERGRYdeUZC6EyFALFsylVatviY2NBRI++IYNG0jfvr0yOTIhPs2TJ4+Z\nOXMaVaqUpVmzBuzcuTPDri3JXAiRZtRqNUFBgcrry5cvUq1aBZYs+UPZdu/eHc6fP8uTJ48ByJUr\nF0OH/sTgwT8qZXx9fVCr1RkXuBCfIDo6mtatm1GhghPTpk3i1auXtGnTHjs7uwyLIcsugSqESBsx\nMTHcv38PL6+b3Lp1k5Mnj3P37m309PTo1asP+fIVoHDhIvz00xCqV6/J/PmLAfDw2MiUKROYPHk6\njRs3BaBDh1bcvOmJt7cPKpUKc3MLXr16RVhYmHK9336bwLRpszAyMgJApVLx88+jlf0BAQHUr1+T\nGjVqsWrVugysCZHeHjy4z+XLF5W/NT+/V9jbF6d8+YoMHDgks8NLJjDwLbNmTefkyWMUKWKLg4Mj\njo7OlChRksePfcmVyxpHRycMDAxQqVR880112rfvSPPmLTE1zYGVlWmKy3WnNUnmQnxFgoICUalU\nmJmZA+Dq2ppTp04QExOTrGxsbCwLF85Psm3r1s14el7D0dEZY2NjICEZJ7K0zEnlyt8QERGBsbEx\ntrZ2PHjwNEmZXLlyvTfGqKhIqlWrTvXqNZRtcXFx6OrKMptZxZs3b5SEnTdvXlxc2gCwYMEc1q9f\no5TLkcOMBw/u4+f3Uknmu3fvYPnyJTg4OOLg4ISjoxPFi5ckW7ZsGRZ/VFQUK1cuY9as3wkODkJf\nX5/bt73Zu3d3knK5cuWiVau2ODg4MXLkrzg6OmdonP+mUmfRtqyUvu1k5DehrETqRbOMrJe4uDi8\nvG7i7FwmQ64XEvKOEyeOc+vWDby8buLldYtnz54yceJUOnbsgomJKT16dObp08d4ed2iYMFCqNVq\nnjx5zPr163F2roSX103WrVvNtWtX8PPzIzo6Ksk1dHR0KFrUFmtrawwMDKlQoRJOTqXR10+4TzAw\nMKRmzdoAvH79mhs3rmmMtUqVbzAxMU2yTa1Wo1KpiIuLo2nTelSvXovRo8cm+WKQWvHx8URFRSmt\nAp6e1/D3f52snIlJDqpUqQrAs2dPuXPHGwBrawtsbApibW3zSXF8SOLPDhAWFsa5c6fJkycfDg6O\nAPj4PMDH5yHlylXA0jInAGfOnCI+Pp4aNWolKfNfKpWKevUaAglf7i5fvqgxhn+f++jRw8THxyUr\nU6hQEezti2FlZcqkSdM4fvwoXl63ePnyhVKmVq06eHgkPDs+ffok9+/fw9HRiZIlHciePTt+fq8I\nDAykZMlSAMydO5MpUyYQHx+vnENXV5dixYpz5Mhp9PT08PPz4+bN6xrjrlKlGiYmJsTGxnL8+BGN\nZYoVK0HBgoUAuHjxAu/eBQGgVsOFC2fZsGEd/v6vMTMzZ8iQH7G0tGTJkoV4ed0EQE9PD2NjY969\ne5fkvLq6utjbF8PBwQkHByeaNWtE4cIlNMbwsaysTDVul2T+lZB60exj6uXp0yfkz18g1R/mM2dO\nY9q0SSxZspJWrdqm6tjUioiIwNm5OMHBQco2a2sbHBwcyZMnL9u2ebB9+9+UL18RgOPHj7B+/Rp2\n7NiGm9t3LF++RGO9BAUFcejQfk6dOoG//2vCw8O5desmISHvkpUFsLHJzc2b9wA4cGAfXbt20Fju\nxInzlCxZiri4OLp27YC9fXHlzszQ0JD27V2oXr0m8+Yt0roOQkNDuX3bCy+vW3h53eLWrRvcvu3N\ngAGDGD78ZwB69uzC33/vSnass3MZDh8+CcDq1X8yfPigJPtz5cpFqVJOLF26EkvLnMTHxxMXF4e+\nvr7W8f07TgATExMA+vbtyfnz57h+/TYqlQpfXx8qVy5Dp05dmTMnoe/B779PZsaMqUyePANdXR28\nvG6xceM69PR0efToFQCjR//M0qULk11PX1+f58/fAHDp0gW+/baBxri2b/+batUSWkeKFMlLWFho\nsjIDBw5l9OixWFmZ0qxZS/7+exd58uRVmqMdHBxxcipN0aK2qaqT8PBw7tzxVn5vXl63iIqK4tCh\nEwDs3r0TN7euGo89e/YKdnb2hIaGULRoPo1lJk/+nd69+wHQtGl9jV9oChYsxMGDx7G0zMnkyeOZ\nN28WderUo0OHTjRq1BQjIyPCwsKSxenldYvw8P8/Vrp16wHW1tap+vnfJ6VkLs3sQqRCREQEDRvW\nolQpR7Zs2cWFC+coU6bcB5vWIiIiWL484VnzzJnTaNGiVZo2G9+5c5vNmzdQteo3NGjQGCMjI1xd\nO5Ejhxk2NrmJj4+nRw83AI4ePcT582eTJHpfX1927NhG+fIVGDducorXMTc3p107V9q1c1W2qdVq\nrly5xIED+zh//iw3b3oSHh6u7Js/fw5t27bH3r4Yv/46XuN5rawSPuyePHnM4cMHOXz4oLLPwMAA\nO7tiNGjQSNk2duxoypevSLNmLQB48eI5Xl43KVGilHLHVbVqOfz8XinH6OnpYW9fjBw5cijb2rVz\npVy5ChrisVL+XbZs+X/FHcPly9fw8rrJ5csXlMcVXl63aNKkLsWLl/znS4jjP3dnjlhYWCp18fz5\nM/z9X1O2bHkAdu3aTp8+Pfj999l0757Qm19HRxdzcwuCg4MwN7fA3NycgQOHYmdnr8SUmHxGjRqu\nbNPR0UlSJiYmGoBvv22h/IyxsbEYGBgoZfLnL5Di76RQocLKv0eMGEVMTGyyMuXL/7/uxo+fzIwZ\nc8mZM6fG86WGsbEx5cpV0Pi7AShZslSKcSde38DAMMUyFStWVv797bctCA0NVVpfSpZ0oF69+pQt\n+/+WiT59+uPm9h02NrmTnCd79uyUL19R+VIMCa0/jx754uV1C2NjvSR/S+lJkrkQqeDhsZE3b95Q\ntmx5rly5RJs2zalS5Rv++mt9smbif9u8eQNv3rzB1DQH9+7dZc+enbRs2TpV1/7zz+UcPnyAqVNn\nUqBAQd68eUO7di159eolAQH+AFy7doVVq1bQqVM3JkyYilqtpkqVsv/0rm2HqWkOateux7lzV5WW\nhatXLzN69Ahy5szJ8uWrk3zYa0OlUlGhQiUqVKgEJHSoO3bsMJs2beDAgb1MmPAbkyaNpWbN2nTo\n0IkmTZopz9v/q0iRojx8+AwvL69/Hg0k/Hf7trfywfrq1UsWLpyHnp4+ZcqU5eHD+wQGJvSgHzr0\nR37++Vcg4XmspaUl/fu74+DgSFRUFLNnT0/ygezr68P582eYN2+xkgQ6d25HyZIOSpmgoEDOnz9D\n7979aN/eBX//EKZOncD169eIj49HV1cXf//XZMuWjdu3vbh50zPJzzR//mI6dOhEcHAQVaqURUdH\nlxo1agIQEhKCubkFL148V8qbmZmRP39+fvjhO6V1ISgoiG7deuHq2hmA8uUrEhsbq3xhcHBwolix\n4hgaGirnmTBhKrVq1aVateqYmZkTFxdHpUqlkySyPHny4u4++IO/4379BnywTIECBT9Y5mPFxsai\np5eQrjw9rzF9+hS+/bYFHTt2AZK+NxK/PH3/fR+sra2ZPHk6AFeuXOKPP+bh6tqJ0qXL8vbtG2bP\nns7KlcuIiYmhfPmKjBs3mUqVKie7fmoScuKjp6JFbaUDnBCfo/j4eBYvXoC+vj69e/fF3NyC+vUb\nsW/fHlq3bsaGDds03pUkHmdgYMC6dR60atWUWbN+p3lzF3R0Uh4dGhcXx/379yhRoiQAd+/e5tCh\nA4wePY4xY35h+fLFSse1Bg0a0aFDJ0BF797dqF494bmpSqVi1Kjf0NHRwdAwofXg39d88+YNbm7d\niI2NZdGiFeTLl/+T60lfX5+GDZvQsGETgoIC2bFjG5s2ref48aMcP34UExNTWrRwoUOHTlSuXDVZ\nHZiaJjyvTnxmDShj0gHMzMypUqUq9+7d48qVSxQuXAQLC0t8fB5ib19cKRcY+AZLy5xKAjx69DCH\nDh2gUqUqSplbt25w6NABoqIilW2HDh1I0vv+5csXHDp0gKZNmyvbrly5zIkTx5Thc46Ozrx7947m\nzV346adReHndZM2aVZw5cwojo4QvLjExsURHRyvX+LfE1gSACxfOK89mVSoVRYvaUrNmHSpWrKSU\nGTHil/f/Ekho0WjatJny+vVrP3LmzEn27NmVbZ6e14iKiqZixUrp2gcgNfz9/TEyyqZ8OW7f3oX7\n9+9x7VrCnbOhYTYOHtxPsWL/fxb97/dGomPHjiRpXfD392fPnp188011Fi6cz+zZ0wkODsLQ0JB5\n8xb98/5JaEVL7FORlcgz86+E1ItmqamXgwf30aVLBzp06KQMz4qNjWXYsIFs2LAWe/tibN68I1lC\n3L9/L926udKxYxfmzl3IDz98h4fHRlauXKs0E/+XWq2mc+d2XLp0kcOHTxIY+BZfX18aNGiEkZER\nixYtYOvWzbi4tMbFpS2FChVS4omMjMTAwOCDd9hxcXF07NiG48eP8vPPoxk69KePqhdtPXhwHw+P\nDWzevJHnz58BCUmsXTtX2rZtT9GidqlOKIl3bFFRUcTExGBkZKQ8vkhMyInJS1PdREZGEhsbi7Gx\nsfKlIjQ0FF1dXeUDPSYmhqioKAwNDcmb1xJ//xAiIiKIi4sje/bsqFQq4uPjCQ8PR09PT3nkEh0d\nTXR0NNmyZUNPT08po4mhoaHyvD08PFzp/KWvr5/kblsbcXFx+Pm9SnGcfkxMNPr6CT//4ME/cOLE\nMbZs2YWtrZ1yTGp/D/ny5UKtNkzVcWq1mvv37xEUFKTcDa9bt5ohQwYorRkA/fr14unTp2zZsgsj\nIyPi4+MJCXlHtmxGSt1o+v2Hhoaio6OjtAJFRkayceNa5s2bzbNnTzE3N8fa2oaAgABu304YSvn4\n8SMqVy5Dnz79mTBhCgDPnz/DwMDwo5rL0+N9JB3gvnJSL5qlpl5cXJpy9uxpjh07q/QqhoQPpbFj\nR7No0Xzy5y/A1q27KVKkqLK/ZcsmnDt3Runk9eDBfapVq4CDgxNHjpxK8QNw/fo1bN26mZiYWM6f\nP0OuXLnw9LyLvr5+mgzVSuxEVb9+Q9au3ZzkDjk9/17i4+M5c+YUmzdvYPfunUpnIQsLC6UXcGLT\ncfHiJVLd7J+ePrf3UUjIO+WRhLd3QiesO3duZ+g0ookSOwUmdH5L+D3a2xdTvqTcvXuH06dP0KJF\na6ysrIiPj8feviB58uTh9OlLQEJLwYwZU+nRw03pcf8x3r0LxtvbSxke5+V1kzt3bhMZGYm+vj5u\nbn0ZMmQ4FhaWxMTEKDF6ed1i5MjhtGjhonSQGzZsEGvXrmL//qNKXwdtZWQyz9Bm9smTJ+Pp6flP\n098onJ2dAfDz82P48P935Hj69CnDhg2jefPmKZ1KiAwVEBDAvXt3qV27bpJEDgl3MWPHTsTS0pId\nO7ZhaWmp7Lt27Qrnzp2hTp16ytAbOzt7WrVqw7ZtWzh4cD+NGjUBEu7k1qxZRffuvXj92o+zZ09z\n6lRC7906derRu3dfJeF+aiI/evQQM2dOo2DBQvzxx9L3NvenNR0dHWrUqEWNGrWYMmUGe/fu5sCB\nfdy6dYPTp09y+vRJpay+vj729sWV5JCY5NOik1VWolarefr0yT+9pf+foB4/fpSknL6+PsWLl8TO\nzg49vdT3rH/92o8rVy5RrFgJbG0TZi87f/4sL148p0mTbzEyMkatVuPv74+5ubnyRSsmJpJr1zw5\nefIYJ08eU86nq6tLqVIJHQIDAgI4fPgA5uYWtGnTHh0dHdzdB2Nq+v/kVLp0Wdas2ZSqenny5HGy\n3uRPniStFwMDA0qUKEXZsuX5/nv3JF+2/z0CwcHBkV279ic5tly58gQE+CtDSt+9C+bXX0fStWsP\npZ/I5yDD7swvXrzIihUrWLJkCQ8fPmTUqFFs2pT8lxYbG0vXrl1Zvnx5kmc7/yV35qnzpdZLdHQ0\n27dvwd/fn169+qTYsSolqamXiIgI3r59897nypGRkUoza2hoKEOHDmDHjm14eOykVq06Srk7d25T\nq1YVSpcuw4EDx1GpVEyZMp7Zs2cwcOAQli1bTEREBKVKOTJ27ERq166bqp/rfZ4+fUL9+jUICwvj\n778PUbp02WRlMuvvJTQ0BG9vbyVheXvfxNvbK9mdZuLwJ3v74h91525gYEDx4iVwcHCkSBFbrb/M\npKZeIiMjuXfvDrdu3eTxY1/i41P/UZtQH154e3slGX0AYGlpiYODc7I74bRoyfj3OPfff5/MuXNn\n2LZtDyqViidPHlOhghMuLq1ZunQVAFu3rmP16rX88ccSnj17hqfnNX77bRRGRsbEx8cRGRmZ5Pz5\n8xfAwcERW1v7jxrOFxLy7p8771vJhkXmypUrSQuPo6MzdnYfdx1NNm/ewIABffnllzEMGjQMSHiv\nJw4t/Lcv8s783Llz1K9fHwBbW1uCg4M1VsD27dtp1KjRexO5+Pq8fftGuSvx8rqFu/sQihUrjq6u\nLiNGDCU8PJzXr/0YPz7lYVWfysjI6IMdxBIT+dWrl3F1bcO7d8GUKuWoTJySqESJkjRv7sKuXds5\nevQQtWrVpVu3nkRERDJo0DCePXtGrVp1aN++Y5oOYYuKisLNrSuBgYHMnDlPYyLPTCYmplSqVDlJ\nj+K4uDh8fX2UO6/E//93CNvHMjY2pmRJhyR3/qVKOWj8cE7J69evlb/NW7du4O19i/v37xEXl3yi\nldRK7ASX2CqUmLhz586Tbp3W/n3en34alWSfvr4+7u5DcHYurWzz8fHh/Pmz+Pn5UaXKN1Sp8o0y\nvjxXLisePnyQpH68vG5x4MA+YN9Hx6ijo4OtrR316tVXxrQ7Ojqn+4Q+bdt2oECBghQtmtByoVar\nadasIWZmZmzbtifTZirMsDvzX3/9lVq1aikJvVOnTkyaNIkiRYokKde+fXtWrlz5wTdSbGwcenoy\nveOXJi4uDh0dHVQqFS9evOC7777D09OTZ8+eJSn3559/0qNHDwA8PDz4+eefefz4MdevX8fR0VHD\nmT/e9OnT0dPTo3///lpP1Xj48GGaNm1KTEwMffr0YenSpcnKXLp0iUqVKlGgQAFMTEz45ptvWL58\neZrG/l/9+/dn8eLF9OjRg5UrV342PZg/hr+/Pw8fPkwyU5i2QkNDuXnzJp6ennh6euLt7Z2kx7xK\npcLW1pbSpUtTunRpypQpQ+nSpcmbNy/37t3j+vXryrGenp68evUqyflNTExwdnZWji9RosRH3Rka\nGhpSokSJz/7m5u3bt2TLli1VLWN+fn74+HzcgjrZsmWjRIkSqW6JSw8hISG0bdsWU1NTtmzZAsCt\nW7d49OgRjRo1SrMWgQ/JtKFpmn6B165do2jRolp9Iw4M1Nwr9EttTv5UGVkvu3fvYNq0Sfz663jl\nebA2zpw5RY8enTl8+CSFChUmJkaXffv2YW1tQ/36DZM0mxUpUlT5eWrXbsyECdC5c3v69u3P9u1/\na52kPlQv794FM378BLJnz067dl0xNEw+h7kmhQsXR1dXj9jYWJYtW0b+/EXo3z/pWN2LF68CCX1E\nVCodKlX6htev36Vbgt28eQOLFy/GwcGJsWOnEhCQfEavRFnjfZQNW1uHDxdLQdmy/x/6FhUVxb17\nd/81tj2hFWjr1q1s3bpVKaejo5Psy0P+/AVo1KhJkqbdwoWLpFk/hPDweMLDP+/fhZVVQi//sDDt\n49TRMcbO7uO/eIeFxaXqeulp7dotxMXFKe+ZKVN+Z/36NRw7dgwHh9R1mvuQTG9mt7a2JiAgQHn9\n+vXrZF39jx8/TtWqVf97qMhCTp48Tr9+bsTExNCjRyfmzPlDGWLyPmq1ml9/HUlwcBAvX76kUKHC\nGBsbc+eOL+bmFike5+/vT3BwEA0aNKZhw8YcPLif7du30Lp1uzT5edas+YvQ0BAGDRqaqiFCa9b8\nRWRkBH37/sDOndsYM2YUgYFvGTnyV549e8q0aZPw8NiolHd0dOL332elWyL39vbixx8HY2qagxUr\nVn8WdzSfE0NDQ5ycnHFycla2qdVqXr58kaRjlb//KwoX/v/qWaVKObz371N8Pf7dvO7m9h3W1jbU\nrFmTN2/C3nNU2smwZF6tWjXmz5+Pq6srXl5eWFtbJ7sDv3nzJk2bNs2okEQau3nTkx49OqNSqRg/\nfjKzZv2Ou3s/goIC6dv3h/cee/Dgfm7dukGrVm2STBbyoQ/KESOGcvjwAaZNm8Xdu3cwMTFVJub4\nVDExMSxbtghj4+x069ZT6+Oio6OV44YN+4nevfvSvr0LW7Zs5smTxwQGvuXEiWOUKuXImDETWL58\nMQcP7ufs2dPKXNhp6d27YHr16kJERAR//bUy1fNkf61UKhV58+Yjb958NGyY0MKUNVosRGZzciqN\nk1PpDB0lkmHJvFy5cjg4OODq6opKpWLMmDFs27YNU1NTGjRImOjf39//qxty8qV49MgXV9c2hIWF\nsnTpn7Rs2ZpaterSvr0Lv/46ksDAt4wYMVrjnadarWbmzKkADBnyU7L979OqVcLSirVq1eG330bR\ns2dvZcavT7Vz5zZevHhO7959lSkitT3u5csXfPdd/3/m1rZg9+6DvHsXzNCh7kRERLBx4zZq1KiF\nrq4uOXLk4ODB/cycOS3Nk7larWbQoB/w8XmIu/sQmjT5Nk3PL4T4PMikMV+J9KwXf39/mjVrgK+v\nT5LViAAeP35Eu3YtefTIlx493Jg6dWayb6tHjx7C1bUNzZu7sGLF6o+OIygoULmTDw8PJzg4iDx5\n8r73mJTqRa1WU79+Tby8bnL+/DUKFy6i4ejk1Go19erVwNv7FhcuXKdgwUL4+DzA1jZhAYyAgABM\nTU2TNdl36NCKY8eOsGvXfqpU+Uara2lj4cL5jB37C9Wq1cDDY6cyv/WHyPtIM6kXzaReNMvIoWkZ\n1wYgvkihoaF07twWX18fBg0aliSRQ8LKS7t3H8TBwYlVq1bQv79bsmbwTZvWAzBkyI9aXVOtVrNu\n3epkY1cTE/mbN2+oXr0i/fq5fVRP2UTDho1g2LARWidygFOnTnDr1g2aNWtJoUKFGT58MPXq1eDu\n3TtAwhhYTc/ehw1LWJJz5sxpHx3vfx09epgJE37DxiY3S5b8qXUiF0JkPZLMxUeLjo7Gza0r169f\nw9W1M6NG/aaxnI2NDTt2/E2lSlXYvn0r3bq5JlnI4o8/lrF1624cHZ20uu6OHVsZMmQAv/ySvEk+\nNjaWUaOG8+7du38muvD4qJ9NpVLRtGkzfvxxZKqOW7RoPoDSc71OnXo4OZX+4AiNSpUqU6NGbU6c\nOMalSxc+KuZ/2717J926uaKnp8eyZX+l6XrKQojPjyRz8VHi4+MZPPgHjh07Qv36DZk5c957e2Kb\nmZmzefMO6tdvyNGjh2nf3oWgoIRlK/X09KhRo5bW127UqCn9+7szePDwZPv09PTQ0dGlYMGCGBoa\nMmbML8lmiPqQly9fJFkHW1t37tzmyJFDFC1qi6NjQq/oZs1asHPnPq1WIxs+fAQAs2b9nupr/9ua\nNavo06c7+voGbNiwNUmHQiHEl0mSufgoEyaMYcuWTZQvX4Fly/7SamIEY2Nj/vprA61bt+PSpQs0\naFBL6RyXGsbGxowbNynF9ZOnT5/D4cOnGDx4OK9f+/H771NSdf7p06dQvrwjN25cT9VxixcvAMDH\n5yHTp///mtr2aK1atRpVq1bjyJFDXL9+NVXXTjRv3myGDRuIhYUF27fvoXr1mh91HiFE1iLJXKTa\n4sUL+OOPudjZ2bN2rUeqZqfS19dn4cJluLl9x+PHj1iy5A9Onz6l1bFbtmz6ZwrI9zMxMUFHR4cf\nfhhEwYKFWL58Md7eXlpd4/Xr13h4bCRv3nw4OGjX7A8Js1lt2bKJwoWL0K1bT/r06a/1sf82bNjH\n3Z2r1WrGjfuViRPHkC9ffnbtOkCZMuU+KgYhRNYjPWJEqmzb5sFvv43CxiY3mzZt/6ihhDo6Ori4\ntGHFioQpTkeOHE7RorbJViP7t7CwMEaPHkFcXDyXL9/AzMw8yTKHT58+Vc5RokQpsmfPzp49O/H3\n9yd//gJER0dpFduffy4jKiqKfv0GaDXHclxcHHPnzuTOndtER0fTv787PXv21q4iNKhRoxYVK1Zm\n//693LzpiZNT6Q8eExsby/Dhg1i/fg12dvZs3ryD/PkLfHQMQoisR5K50Nrx40dxd+9HjhxmbNy4\nLcVmbm0k3nl+911/li5dhItLU9au3UzlylWSlVWr1QQE+DN06AiuXr3MwIHfa1zmMFHiwhS5c+cF\n1LRq1RZra5skK0FpEh4ezp9/LsPCwkLrseq+vj7MmjWduLhYLCwstJrt7n1UKhXDho3A1bU1s2ZN\n588/1763fGRkJP36ubF3725Kly7Lhg1byZUr1yfFIITIeiSZC614el6jZ88uqFQqVq/e8N676A+5\ncuUSx44doUaNWkycOI0yZcrh7t6P9u1bsnjxSnLnzp1k3WZvby+NyxzWrFlHWUWqQIGE8dz/X5np\nJg8fPgBgzpwZzJkzAzMzM0rfIlVYAAAgAElEQVSVcsTZuYwyHWe1ahWUc27evIG3b98ydOiPH5zu\nNC4uDl1dXezs7OnUqSurVi2nZ8/UL8GqSZ069ShXrjx//70Lb28vSpXSPP94aGgI3bt34tSpE1Sv\nXpO//lqPqWmOT76+ECLrkWQuUnT69EkGDuzPkiUr6d69E+HhYSxf/hfffFP9k86beFee+Hy4bdsO\nmJmZ4ebWje7dOyYpq1KpMDbOTqNGTahYsfJ7lzn8d69ttVrNs2dPlS8Fx48f5cKFc5w7d4Zz584o\n5YyMjOjdux+DBg3l4cP7GBkZ0bPndynGHhcXx9SpE7lx4zobNmxFrVZz4sRRDA0N6dUr5eNSQ6VS\nMXToT3Tp0oHZs6ezbNmqZGXevHlDx46tuX79Gk2aNGPJkpVar+gmhPjySDIXKdq2zYNnz57Sp08P\nAgL8mTp1Js2bu3zyed3dh2BvXzzJl4IGDRrj4bGLxYsXYGNjo6xPvGPHNhYtmk+7dq60aNFK62uo\nVCoKFChIgQIFcXR0YseObZiYmBIREc6cOQsJCwvFy+sWx44dYv782axfv5rhw0dy8aInNjY27z2v\nt/ctfHwe4uf3iqtXr+Dr60Pnzt3SdCx3gwaNcXIqza5d2/nxx5EUK1Zc2ff8+TPat3fh/v17dOzY\nhZkz58mEMEJ85WQ616/Ex9TLnTu36dy5HU+fPmHw4GH07Nnng9OjpjW1Ws2pUyeoWbP2R58jNjaW\nBg1qkTt3bo4cOUTlylXZtWs/KpUKExM9Jk2axty5swgNDcHW1o7ffptA48ZNk9z5P3nymIIFCwEQ\nGPj2nznVzWjWrCEXL57n1KmLFC9e4lN/3CT27t1Djx6daNOmPYsWJaxz/uDBfdq1a8nz58/o39+d\nsWMnpstKa/I+0kzqRTOpF81kOlfxWfDw2MjTp0/o2LELjx8/pkmTejx//uyjz+fr68PDh/e1KhsX\nFwck3Al/SiKHhIlk9u07woYNW2natDkXLpxjy5ZNQEIze82atSlfviItWrjw6JEv3bt3xMWlqTLW\ne8aMqVStWo6rVy8DYGFhSY4cZly+fJGLF89Tv37DNE/kAI0bN6VUKUe2b9/Cw4f38fS8RvPmDXn+\n/BmjR49Nt0QuhMh6JJkLjfz8XrF8+RJsbHIzbdosHB2dKVCgYKrGlP/XxIljqVatIrdu3XxvuZiY\nGJo3b8SsWb9/0tzq/5b4PHnChClky5aNsWNH8+5dMJAwBeuJE0fp1q0XJ09eoHHjppw7d4aGDWvT\nr58bhQsXwdbWDiOjpJ3bFi1KmCSmf3/3NInxv3R0dBg27Cfi4+MZMsSdVq2a8fbtW2bMmMvAgUMl\nkQshFJLMhUb9+vUiIiKcli1bkS1bNgYMGMTWrbs/uL54Sm7f9mb37h2ULl3mgz3hnz59zPPnz3j4\n8EGaJ6w//piLSqWiXLkKREVF8+jRI3bt2oGDgxM1atTC3r4Yq1dv5OefR+Pg4MS2bR4MGTKAunUb\nkC9fPuU8jx8/4u+/d+HkVDpdZ1n79tsWFC9egvPnzxIVFcmyZatStba6EOLrIMlcJBMUFMilS5fQ\n0dGhd++EmcxUKhUGBgYA3Lp1k2HDBhIbG6v1OefMmQ7A0KEjPpigixa148SJc0ye/GlzlGs+ty32\n9sUYM2YCVlZWzJ07l/j4eL7/3l2Ja/fuHUydOpGyZcvxxx9LyZXLioUL51GpUmlWrFhCTEwMS5cu\nJD4+nv79B6TrHbKOjg4TJkzFwcGJtWs3p6oToBDi6yEd4L4SqamX6dOnMH36FH77bQIDBgxKtr9n\nzy78/fcuPDx2UqtWnQ+e7/79e1SvXhEHByeOHDmVYvKLiooiJibmgyuMfYrY2FhUKhW6uroEBwdh\nb1+Q3LnzcOXKLWV++ejoaH76aQju7oOxtbUnIiKCZcsWMWfOTEJDQyha1JZXr15hbm7OpUs3tJqX\nPquR95FmUi+aSb1oJh3gRKZ59y6YpUsXYWlpSY8ebhrLzJu3kLVrN2mVyCFh0ha1Ws2wYSnflcfH\nx9OiRSNq1/6GO3duf3T8H6Knp6dM0zpt2mQAunfvhYfHRnbu3AaAgYEBc+b8ga2tPZDQSW7gwKFc\nuHCdXr368PjxI8LDw+jTp/8XmciFEFmPDE4VSaxYsZTg4CCaN3chJiZaYxlT0xw0bNgESBg6duPG\ndUqXLquxrFqtxtg4O6VLl6VJk2+T7Y+Njf1n2VId6tSpx8uXLzNkXvHjx4+yadM62rZtS9u2rtSu\nXRULCwuaNGmmPE74LysrK6ZOnUnv3v04ceIYXbp0T/c4hRBCG9LM/pXQpl5CQ0MoX96RsLAwoqOj\nOXLkNE5Ozu89ZvLk8cybN4vVqzcoCV6TxKSdKDo6mhEjhvLs2VM2b96BSqX64NzpacnPz4+mTesx\nbtxYmjVry9Gjh7CzK6aMJf/ayftIM6kXzaReNMvIZna5MxeKP/9cQWBgIL169cHOzp6SJUt98Jim\nTZtx9uxpnJ3LJNsXGRmJoaEhKpUq2QxlBgYGvHr1Ej+/VwQGvsXSMmeGDrWysbHhwoXr5Mljgb9/\nCHXrNsiwawshRFqTO/OvxIfqJSwsjIoVnYiOjuHKlZuYmZkDCc+ydXTe37UipTvqYcMGceeONytX\nriFXLis2bFjL27dvGThwCJAwv7iZmVmmTkUqfy+aSb1oJvWimdSLZtIBTmS41av/JCAggN69+2Jm\nZk50dDS//vozNWtWVso8eHCfPXt24evrQ3x8vLI9MZH7+vrg4tKUZ8+e8uzZUzZuXMvbt2/IlcuK\nmJgYZs+ezoIFswkNDQUgZ86cMqe4EEKkAfkkFURERLBgwRyyZzchKiqSSpVKY2hoyN27d6hfv6FS\nbs+enUyePB4AExNTSpVywNHRCQcHJzp27MLRo4c4e/Y0Bw7s5d69u8TExNC0aXN0dXXR1dVl8eIV\n5M9fIF2HngkhxNdIkrlg7dpV+Pu/ZtCgYdy9e5tHj3wBcHXtzJQpM5Ry9eo1REdHF2/vhDXDr1y5\nxMWL57GwsKBLl+64ufXFyMiY48eP8Pffu1GpVGzfvoURI37BwMCAihUrpxSCEEKITyDJ/CsXGRnJ\n/PlzMDbOTkCAP/v378XIyJjp02fTvn3StcWdnJyT9G6PiIjg7t3b+Pu/Vprao6Ki2LEjYbx2mzbt\naNeuY4pDvYQQQqQNSeZfuQ0b1vLq1Ut++GEQOXPmwsHBiWXLVmFnZ//BY42MjChTplySbT16uFG3\nbn38/PyoWLGSLAYihBAZQJL5VywqKopp0yaRLVs2+vd35/FjXwoUKEDu3Lk/+pwqlYpChQpTqFDh\ntAtUCCHEe0lv9q9UaGgILVs24e3bN5Qs6YC1tTWrVq2gT58evHjxIrPDE0IIkQpyZ/4VunnzBr17\nd8fX9yEqlYpJk6YBCU3kxYuX0KqJXQghxOdDkvlXRK1Ws3LlMsaMGUV0dMK8692796JChUoAVKxY\nWXqcCyFEFiTN7F+Ra9euMHLkcLJnN8HGJjcGBgYMHjw8s8MSQgjxiSSZf0XKlavA9OlzGD58BH5+\nr+jYsSt58+YDYOrUiTRuXAcfnweZHKUQQojUkmb2r8Ddu3fIkSNhfHiXLt2pUaMSenp6yhzpAAEB\nAXh7e2FtbZNZYQohhPhIcmf+hYuLi6Nt2xaUKlUKtVrNrl3befDgPh06dKJAgYJKuRkz5nD//lNM\nTDRP4i+EEOLzJcn8C3fx4nn8/F5Rt25d1Go1s2dPR1dXl4EDhyYra2homAkRCiGE+FSSzL9wO3Zs\nBaB9+/b8/fdu7ty5Tdu2HShSpKhS5urVy5w6dYLIyMjMClMIIcQnkGfmX7C4uDh2795Jrly5qFWr\nFmXLlkdHR4fBg4clKbdo0QJ27tzGxYueFC5cJJOiFUII8bEkmX/Bzp49TUCAP927u7Fv3z68vW/R\npk17bG2TTgrTuXM3bG3tZApWIYTIoiSZf8FOnDgGQIsWLowfPwaVSsWQIT8mK1e7dl1q166b0eEJ\nIYRII/LM/Av2yy9jOHz4JJGR4Vy9epUWLVpRrFjxzA5LCCFEGpNk/gVTqVQ4O5dhzZrVALi7D05W\nZurUCbRr15IXL55ndHhCCCHSiDSzf6H27NlFoUKFsbKy5tCh/ZQtWxZn5zLJyj148IBz585gYWGZ\nCVEKIYRIC5LMv0DR0dEMHToAQ8Ns9OnTj7i4ONzc3DSWXb78L0JC3mFkZJTBUQohhEgr0sz+BTp1\n6jhBQUE0b+7Chg1rMTQ0pFOnTimWNzXNkYHRCSGESGuSzL9AO3duB8DevhgPHz7g229bYGFhkazc\njRvX8fS8RmxsbEaHKIQQIg1JMv/CREVFsXfvHvLmzcfVq5cB6NSpq8ayM2ZMo0GDWrx+7ZeRIQoh\nhEhj8sz8C3PixFHevQumXbsObNiwloIFC1O9ek2NZdu160DRorbKMqhCCCGyJknmX5iXL19iYmKK\niYkp4eHhdOzYGR0dzQ0wzZu70Ly5SwZHKIQQIq1JM/sXpnv3Xnh5PeDUqROoVCpcXTtndkhCCCHS\nmSTzL9CTJ4+5evUyderUI1++/BrLTJ06gV69uhIQEJDB0QkhhEhrGdrMPnnyZDw9PVGpVIwaNQpn\nZ2dl38uXLxk6dCgxMTGUKlWK8ePHZ2RoX4Q5c2ZgZmbOw4cPgIQFVFJy6dJFLl++iJmZWUaFJ4QQ\nIp1kWDK/ePEijx8/ZtOmTTx8+JBRo0axadMmZf/UqVPp1asXDRo0YNy4cbx48YK8efNmVHhZXnh4\nOHPmzMTKyoqQkHdYWlrSsGGTFMtv2bKL169fo6+vn4FRCiGESA8Z1sx+7tw56tevD4CtrS3BwcGE\nhoYCEB8fz5UrV6hbN2HlrjFjxkgiT6UjRw4RHh6Gg4MTb9++pV07VwwNDVMsr1KpsLGxycAIhRBC\npJcMuzMPCAjAwcFBeW1paYm/vz8mJia8ffuW7NmzM2XKFLy8vKhQoQLDhg177/ksLIzR09PVuM/K\nyjRNY88K9u/fBcC7d4EADBjQP1k9JL6+ceMGxsbG2NraolKpMjbQz9DX+PeiDakXzaReNJN60Syj\n6iXThqap1eok//bz86Nbt27ky5eP7777juPHj1O7du0Ujw8MDNe43crKFH//kLQO97MWFhbGnj17\nKFSoMGfOnKFcufLY2BRKUg//rpchQ4Zx9OhhvL19yJUrV2aF/Vn4Gv9etCH1opnUi2ZSL5qlR72k\n9OUgw5rZra2tk/Scfv36NVZWVgBYWFiQN29eChYsiK6uLlWrVuX+/fsZFVqWd/jwASIiIsiXLz9q\ntZpOnVLu+AYJ48v79On31SdyIYT4UmRYMq9WrRoHDhwAwMvLC2tra0xMTADQ09OjQIECPHr0SNlf\npEiRjAotyzM1zUHVqtXw9fXB2NiYVq3avLd8587dmDTp9wyKTgghRHrLsGb2cuXK4eDggKurKyqV\nijFjxrBt2zZMTU1p0KABo0aN4ueff0atVlOsWDGlM5z4sLp162NgYEDr1s3o0KGTrIImhBBfmQx9\nZj58+PAkr0uUKKH8u1ChQmzYsCEjw/mirFu3Gkh5UZVE06ZN4uXLF4wfP5kcOWSMuRBCfAlkbvYs\n7ocfviMmJpp9+/6maFFbqlT55r3lDx8+yMOHD5g5c14GRSiEECK9STLPwoKDg9i5cxs5c+YkKiqK\nTp26fnCo2f79R3n69Am6upqH9QkhhMh6ZG72LGz//r1ER0ejVoOuri4dOnT64DG6uroULiydC4UQ\n4ksiyTwTvH37hilTxuPj8+CTzrNz5zYAXr16Sf36DbGxyf3e8vfv3+P169efdE0hhBCfH0nmmWDB\ngrnMnj2DevVqsnXr5o86R1BQIMePHyVnzoSx4h8aWw4wYsRQnJzsCQl591HXFEII8XmSZJ4J7t27\ng7GxMQD9+/dmyJABhIdrntHuvxJnztu7dw+xsbGEhYViZWVN/foNP3hs/fqN6Nq1pwxdE0KIL4wk\n80ywdu1mLlzw5MiRkzg5lWbdutXMnTvjg8dt3ryBvn17AlCpUhUaN25KZGQk7dt31Gr1s++/d2fG\njDmfHL8QQojPiyTzTGJjY0PRonbs3XuYn38ezcCBCQvLqNXqJPPWJwoODuLnn4djZGRMbGwsdnb2\n3LzpCUDLlq0yNHYhhBCfF0nmGSg+Pp4pU8Zz9eplZZuhoSFDh/5E9uzZAdi4cR39+vVK9lzbzMyc\njRu30bJla8LCQnn0yJfnz59jYGCIs3MZAN69C8bH56HGa48bN45ffx2pdXO+EEKIrEOSeQa6cuUS\ns2fP4M8/l2vcr1ar2bJlM9u3b6VevRp4el4jPj6e+Ph4ACpVqkzduvVxc+tOo0a1ARg5cjQ6Ogm/\nRg+PjVSpUpYtWzYlO/e6devYvHk9RkZG6fPDCSGEyDSSzDNQ4lAyF5fWGverVCo2btyKu/sQHj3y\npWnT+nTr5kr37p0IDg4CwN/fn9OnTxAWFkb27CZ07+6mHF+kSFFq1apDjRq1gYQvB6NHj+D48aNc\nv36dnTv3y/rlQgjxBdIqmU+fPh0fH5/0juWLFh8fz65dOzA3N1eSrSb6+vr8+us4Nm7cRo4cOTh4\ncD/Hjx8lKCgYgL//3kV8fDzR0dG0atVGWXkOoG7dBnh47MTGxgaAGzeus3TpIjZsWIOxsTElSpRM\n159RCCFE5tBqOtcVK1awcuVKSpcuTatWrfj222+TJBHxYRcvnufVq5d06tQVAwODD5avW7c+x4+f\no3//3sTHx1OgQAHg/3f3AB07dnnvOZydy7B//1GyZZOmdSGE+JJplcy7dOnCsWPHuH79Op6enkyZ\nMoX69evTunVrvvnm/Qt7iAQ7dmwFoGVLzU3s/xYdHY2vrw/Fi5fAw2Mn4eFh6Ojo4Ofnx5kzp1Cp\nVNjbF6NChUrvPY9KpaJcuQppEr8QQojPl1bN7KNHj+bIkSPs3r2bwYMHU6JECfbu3Yubmxt16tRh\n0aJFhISEpHesWZqZmRn29sWoXr3mB8uOH/8r9evX4NSpE+jq6iqTvJw6dRxIeBbeqVM3ef4thBAC\nSGUHOHt7e/r27cuIESNo1qwZarWaly9fMnfuXJo0acKNGzfSK84sb+TI3zh9+pJWk7vUrFmb0qXL\nUrZs+STba9euR758+dHV1aVdO9f0ClUIIUQWo1Uzu1qt5vLlyxw4cIBDhw7x+vVr1Go1JUqUoF27\ndvj4+LBhwwbGjh3Ltm3bPnzCr5S2d9INGzahQYPGycr7+j7k+fNnfPttC6ysrNIjRCGEEFmQVsm8\nevXqvH37FrVajZGREa1bt6ZDhw44OzsrZWJiYtixY0e6BZpVxcbG0rlzO5o3d6FLl+4plgsNDWXB\ngjkMGjQMIyOjZIn8xYvnfPddwlSuvXr1SdeYhRBCZC1aJfM3b95QsmRJ2rdvT/PmzTX2ZC9durQs\nr6nBmTOnOHbsyAfXEF+wYDazZk0ne3YT3N0HJ9kXFBSIq2trnj9/xujR46hRo1Z6hiyEECKL0SqZ\ne3h44OTk9N4ybdq0oU2bNmkS1Jdk167twId7sQ8e/CPGxib07ft9ku0RERF07erKnTu36dOnX7JE\nL4QQQmjVAc7R0ZEFCxYwbdo0ZVu/fv2YM2eOxkVBRIKYmBj27NmJtbUNlStX1VgmcarWbNmyMXDg\nkCRj0OPi4ujXz40LF87h4tKaCROmSg92IYQQyWiVzFesWMGCBQsICgpStgUHB7NkyRJWrFiRbsFl\ndadOnSAwMJAWLVzQ1dVNtj8gIIA6daqxf//eZPvUajUjRgxj37491KhRm/nzlyhzsAshhBD/plV2\n8PDwoGzZsgwdOlTZtmDBAsqUKcPWrVvTLbisLnG2thYtNDex37hxHV/fh9y5451s34wZU1m9eiWO\njs6sWrUWQ0PDdI1VCCFE1qXVM/OXL1/SuXPnJMOhcubMSePGjZk5c2a6BZfV1avXgOjoaCpVqqxx\nf+KUrf/tHPfXXyuZPn0KBQsWZsOGrcqkMUIIIYQmWt2Z29jYsGfPHl6+fKlse/z4Mdu3bydXrlzp\nFlxW4+ramlKlbJXXZcqU4+jRQ/zyy0/Ktvnz51C8eCHOnz8LQNGitkmaz/fu3cOIEUPJlSsXmzdv\nUxZNEUIIIVKiVTJv3bo1N27coG7dulSsWJHy5cvTuHFj7t69S8eOHdM7xs/W8uWLKVXKlhMnjgFg\naZmT3LnzAAmd33R1dcmdOw9mZmbKMSYmJuTOnUfjYivnz5+jb9+eZMtmxLp1HhQtapcxP4gQQogs\nTatm9r59+xIUFMT69euVOdj19fXp2rUrvXv3TtcAP2f6+gaYmZkp4+4XLlwGQGRkJOXLO9KyZStO\nnDif5JiePXvTs2fyOrt925uuXTsQFxfHX39tSDaVqxBCCJESrZK5jo4OI0eOZODAgTx8+BADAwMK\nFy5McHAwd+/epUSJEukd52epe/dedO/eK9n248eP4u//GgMD7TqtPXv2FFfX1gQHB/HHH0upW7d+\nWocqhBDiC5aqsU5xcXHkypWLHDly8ObNG5YtW0b37ilPUfq1Slzu1MXlw8udBga+xdW1NS9fvmDM\nmImygIoQQohU0+rO/OnTpwwaNIjbt28n2a5Wq7/qDnAnThxDX1+fb76prmyLiIjgwIF9FCpUmNKl\ny773+PDwcDp3bs+9e3fp2/cHvv/ePb1DFkII8QXS6s58ypQpeHt7Y2lpiVqtxtzcHB0dHRwcHFi4\ncGF6x/jZ+vHHwcriJ4mOHDlEWFgoLVu2fu9sbbGxsfTt25PLly/SunU7xo2bJLO7CSGE+ChaJfMr\nV67g5ubGzp07AZg+fTpHjx4lJiaGJ0+epGuAn7NBg4YxdOhPSbbt2pUwUUzLlq1SPE6tVvPjj4M5\ncGAfNWvWYd68RTK7mxBCiI+mVTN7fHw8OXPmVBJOSEgINjY2tG7dmrlz59KsWbN0DfJz1blzt2Tb\nRoz4hfLlK+Lo6KzhiATLly9m3brVODuXYdWqtRqHqQkhhBDa0iqZ29vbM3/+fKpVq4a+vj6LFi3C\nz8+P7du3ExAQkN4xZim2tvbY2tqnuP/hw/tMnDiWnDlzsm6dByYmphkWmxBCiC+TVm277u7uxMXF\nERUVRePGjbl37x7Tpk3j7t27VK6searSL93Dh/fp1q0j27dvUbbdv39PWQVNk7i4ONzd+xMREcHv\nv8+W2d2EEEKkCa3uzKtWrcq+ffswMTFh0qRJWFtbc/fuXezt7enbt296x/hZevLkCfv3/02ZMgk9\n1kNDQ6lXrzoVK1Zm69bdGo9ZuHA+ly9fpFWrNjRv7pKR4QohhPiCaZXM169fT5kyZciXLx8AP/74\nY7oGlRXUqlWHu3cfKUubHjy4j8jISCpVqqKx/J07t5k2bSLW1jZMmTIjI0MVQgjxhdOqmX3u3Llc\nuXIlvWPJUnR0dLCwsCRHjoR513fu3A6Ai0ubZGVjYmJwd+9HdHQ0M2fOw9IyZ4bGKoQQ4sumVTIf\nNWoU27dv5/z587x7947o6Ogk/32NQkLeERERofz76NFDlCxZiuLFk09tO2/eLDw9r9GhQycaNWqS\n0aEKIYT4wmnVzD5t2jRCQkLo2bNnsn0qlQpvb+80D+xzN2bML6xd+xfnzl3h6tUrREVF0aJF8rHl\nN2/eYObMaeTJk5eJE6dmQqRCCCG+dFol87dv36a4T61Wp1kwWUmxYsWpVasOuXJZceTIQQBatkw6\nF3t0dDTu7v2IjY1l9uwFmJmZZ0aoQgghvnBaJfMjR46kdxxZTr9+A+jXbwAACxYspWfP77CzSzq+\nfObMqXh736Jr1x6yEpoQQoh0o1UyT+zFLjTT09OjcuWkvdivXbvCvHmzKVCgIOPGTcqkyIQQQnwN\ntErm9erVS3GfSqXi8OHDaRZQVrF48QIKFSpCTEw0ZcqUo2DBQsq+yMhI3N37ERcXx9y5C2WWNyGE\nEOlKq2T+/PnzFPd9jSt9RUVF8dtvo6hS5RsuX75IqVKOHD58Utk/depE7t27i5vbd1SvXjMTIxVC\nCPE10CqZL1u2LMnr6OhoPD09OXDgABMnTkyXwD5nOjo6rF27icuXL3H+/NkkvdgvXDjPokXzKVKk\nKKNHj8vEKIUQQnwttErmNWrUSLatXr16mJiYsGLFCipWrJjmgX3O9PX1adiwCZ6e1wFwdi4NQFhY\nGAMH9gNg3rzFZM+ePdNiFEII8fX4pEW0IyMjuXDhQlrFkuW8fPkCgHz58gMwadJYfH196NdvQLIO\ncUIIIUR60erOfOTIkUleq9Vqnj9/zpUrV77Knu579+5hxoypSn+BPHnycvr0SZYvX4K9fTF+/nl0\nJkcohBDia6JVMt++fbvmg/X0GDBgQJoGlBUEBQXi6+uDubnZPxPBqBk8+Ad0dHSYP38xRkZGmR2i\nEEKIr4hWyXzKlCnJtpmamuLk5JSqNbknT56Mp6cnKpWKUaNG4ezsrOyrW7cuuXPnVlYhmzFjxme7\n3nenTl3p1KkrISEhvH37hjFjRvPkyWMGDx5OuXIVMjs8IYQQXxmtknmrVgm9tQMDA7GwsADg6dOn\nqUq2Fy9e5PHjx2zatImHDx8yatQoNm3alKTMsmXLslSnMVNTUy5dusCaNX9SsqQDw4aNyOyQhBBC\nfIW0SubBwcG4u7uTL18+5S59xIgRqFQqFi5ciJmZ2QfPce7cOerXT5jS1NbWluDgYEJDQzExMfmE\n8DPH3bt3iIyMQK1OaF7X09NjwYIlGBoaZnZoQgghvkJaJfOZM2dy8eJFunbtqmyztrZm//79zJo1\ni3HjPjyeOiAgAAcHB+W1paUl/v7+SZL5mDFjeP78OeXLl2fYsGHvnZDGwsIYPT1djfusrNJ3xrWW\nLQdx4cIF4uPjARg9ejR161ZL12umhfSul6xK6kUzqRfNpF40k3rRLKPqRatkfuLECVxcXPjll1+U\nbXPmzGHEiBGcPHnyPQR3D7oAACAASURBVEem7L+rrQ0cOJAaNWpgZmbGDz/8wIEDB2jcuHGKxwcG\nhmvcbmVlir9/yEfFpK0mTZqjr2/IyZPHAShfvmq6X/NTZUS9ZEVSL5pJvWgm9aKZ1Itm6VEvKX05\n0GqceWBgIMWKFUu23c7Ojjdv3mgVgLW1NQEBAcrr169fY2Vlpbx2cXEhZ86c6OnpUbNmTe7du6fV\neTNDv34DqFChkvI6T568mRiNEEKIr51WydzOzo6VK1eyY8cO7ty5g7e3Nx4eHqxYsYIiRYpodaFq\n1apx4MABALy8vLC2tlaa2ENCQnBzcyM6OhqAS5cuYW9vn+K5PgcvXvx/vnpJ5kIIITKTVs3s/fr1\nY+DAgRonj9E0bE2TcuXK4eDggKurKyqVijFjxrBt2zZMTU1p0KABNWvWpEOHDhgaGlKqVKn3NrFn\nprdv3zB16kSuX78GgLm5uYwrF0IIkalU6v8+vE7BkSNHWLZsGXfu3MHAwAB7e3u+++47atWqld4x\napTSc4j0fnZz8+YN6tWrjpmZGcHBwZQq5cjx42fT7XppRZ5paSb1opnUi2ZSL5pJvWiWkc/Mtboz\nh4SFVd63rvnXwt6+GCdOnOf69SsMGvQDefNKE7sQQojMpfVCKzt27GDp0qXK619++QUPD490Cepz\nli1bNkqWLEW5cgkrxeXJ8/XNTS+EEOLzolUy37p1KyNHjsTX11fZ5uPjw2+//cbWrVvTLbjPUeJT\nicQOcHny5MnMcIQQQgjtkvmqVauwtbWlZ8+eyrYxY8Zga2vLX3/9lW7BfY6mTZtIkSJ56N69IwB5\n88qduRBCiMylVTJ/8uQJHTp0SDLWvESJErRr144nT56kW3Cfoxw5zDExMSUyMhKQYWlCCCEyn1bJ\n3NzcnOPHjxMVFaVsCwsL4/Dhw1lybvVP8f337nTs2EV5LclcCCFEZtOqN3uTJk1YtWoVVapUoVCh\nQsTHx/PkyROioqLo1atXesf42Xn+/Jnyb+nNLoQQIrNplcyHDBnCs2fPOHz4MHfu3FG2N2rUiEGD\nBqVbcJ+jvXv3cPu2F/9r787joiz3Po5/hk0lcWEZ3MMtIJcMUzOtXNAjnqy0TPIoxyWXPJi5k4+G\nWVqadtRcjpZLLueIh0fLsic9ara6y6kk1FQ0WURAkkVABJ4/0El0oLFkZoDv+/Xy1cw1N3P/uLpf\n/ryu+7qvH4Cr6z24udWwcUQiIlLZWZTMq1SpwpIlSzh79iwxMTGmTWM8PDzIyMjAw8OjrOO0Gy+9\n9CLZ2VcwGAzUq1ev1MpuIiIi1mDxc+YAPj4+BAUF0b17dxo1asSaNWt46qmnyio2u1NYWEh4+Ov0\n6tWbwsJCPWMuIiJ2waKR+aVLlwgPD2ffvn1kZWWZ2gsLC6lRo/JMMxsMBgYPHkLnzo/x8ccf6X65\niIjYBYuS+Ztvvsl//vOf29qbN2/Oyy+/fNeDsneJiQmAVrKLiIh9sGia/dtvv+WZZ57h888/B2Dl\nypVERESQl5eHq6trmQZoT44ePUxQUDdeeulFQMlcRETsg0XJPDs7G39/f6pUqQLA1atXeeCBB3ju\nueeYM2dOmQZoT86ejeXIkcP8/PM5QLu/iYiIfbAomfv4+LB8+XLS0tJwdHRk3bp17Nq1i7179xIX\nF/fbX1BB9O37LCNHjjG9177sIiJiDyxK5i+88AKXLl0iKyuLzp07c/DgQcaOHcuhQ4e4//77yzpG\nu2EwGEhJuWh6r9XsIiJiDyxaANe7d2/q1q1L3bp1eeutt3jttdc4ceIEzZs3Z/LkyWUdo91ITU3l\n3LmiKXZnZ+dK9Xy9iIjYL4uSOcCDDz5oer1w4cIyCcbejR8fypEjhzAYDNStWw8Hhzt6TF9ERKRM\nKBvdgbZtH8LLy3h9wxitZBcREfugZH4Hxo2byH/+8wWgAisiImI/lMzvUEJCPAB16iiZi4iIfbDo\nnvmhQ4do3Lgxnp6exdrPnDlDUlISHTt2LJPg7EleXh7Tp08lJuZHQCNzERGxHxaNzENCQvjiiy9u\na9+zZw8TJky460HZo9TUFNaseZ/9+78FtGGMiIjYj1JH5iEhIUBRQZX333+fjz76yPRZQUEB0dHR\nFBYWlm2EdqJmzVo88cRTfPJJUR9oAZyIiNiLUpN5rVq1+PrrrzEYDMTGxhIbG3vbMU8++WSZBWdP\nqlWrhqOjo+m9krmIiNiLUpP54sWLyc3N5YEHHmDYsGF06dKl2Oc1a9bE19e3LOOzK/HxcRgMBgCM\nRm8bRyMiIlLkNxfAValShXXr1tGkSZPbFsBVJhs3ruO//z2KwWDAaPTG2dnZ1iGJiIgAFi6ACwgI\nYO3atcTFxZGfn88rr7zCgw8+yJAhQ0hNTS3rGO1Cevpl8vPzKSgoUIEVERGxKxYl84ULF7Jq1Sri\n4uL4+OOP2bp1KwAHDhzg73//e5kGaC9efHEs0dGnARVYERER+2JRMv/000/p1asXbdu2ZdeuXVSt\nWpXdu3cTEhLC119/XdYx2o3ExKINY/SMuYiI2BOLNo1JSUmhQ4cOODs7c+TIEVq1aoW7uztNmzat\nNNPsO3Z8yt69nwPa/U1EROyLRcm8du3anD59moMHD5KWlkZAQAAAiYmJVK9evUwDtBcvvxxKamoK\noJG5iIjYF4um2Tt37sz69ev561//isFgoFevXhw6dIjVq1fTtm3bso7RLjRr1sz0Wru/iYiIPbFo\nZD5lyhSys7OJjY3lmWeewd/fn++//x4PDw8mT55c1jHaBU9Po+l1nTpazS4iIvbDomRes2ZN3nnn\nnWJt999/Pzt37sTJyaKvKPcSEoo2jFEtcxERsTcWZ+L4+Hi2bt1KbGwsw4YNw9PTkzNnzlSKimnn\nzp0lJiYGBwcHatasSbVq1WwdkoiIiIlFyTwqKophw4aRnZ2NwWCgb9++ZGZm8sILL7Bs2TIef/zx\nso7Tpk6fPkVOTtHvrpXsIiJibyxaADd37lw8PDx4/fXXTVXS7r33Xnx8fFi0aFGZBmgPHn74Edas\n2UBhYaFWsouIiN2xKJnHxMQwePBgunbtamqrU6cO/fr146effiqz4OyFq6srzZrdB2j3NxERsT8W\nJXN3d3fOnz9vqhh2479RUVF4eHiUXXR24vLly8TGngHQvuwiImJ3LLpn/tBDD7Fx40aOHi2qGrZ4\n8WJmzpxJXFwcQUFBZR2jzQ0Y0JejRw8DesZcRETsj0XJfOrUqcTExPDjjz8C8N133wHQpEkTpk6d\nWnbR2Y1C0ys9liYiIvbGomTu6enJhx9+yFdffcWpU6cAaN68OZ07d64Uz5kbjXVMrzUyFxERe2NR\nJn7llVd45pln6Nq1a7FFcLt27eKrr77itddeK7MA7UFCQjwODg6qZS4iInap1GSekJAAwNatW2nW\nrFmxx7Ly8/P57LPP2LVrV4VP5mfOnMLBwYFq1Vxxc6th63BERESKKTWZd+vWzbRyff78+cyfP/+2\nY9zd3csmMjuRkZFBZmYmBoOBevXqmfpDRETEXpT6aNry5cvp168fULQ/e926dYv98ff359VXX7VK\noLZSWFjIgAF/obCwULu/iYiIXSp1ZH7jHvm+ffuYPHlypXgM7VY1atRgwoTJRERs1O5vIiJilyxa\nALdnz56yjsOuJSYWrR1QMhcREXtk0Q5wldmUKS8zYEBfAE2zi4iIXbJqMp8zZw4DBgwgODiY77//\n3uwxCxYsYPDgwdYMq1QxMcfJzc0F9Iy5iIjYJ6sl84MHD3Lu3DkiIiKYPXs2s2fPvu2YU6dOcejQ\nIWuFZJEaNdxMrzXNLiIi9shqyXzfvn0EBgYC0LRpUy5fvkxmZmaxY9566y3Gjx9vrZAsEh8fj6Oj\nI6BpdhERsU9W24s1JSWFFi1amN67u7uTnJxM9erVAdiyZQvt27enfn3LprJr13bFycnR7GdeXm5m\n23+P+PjzODk54eDggJ+fDw4O5XeZwd3sl4pE/WKe+sU89Yt56hfzrNUvNttYvbDw1+Ilv/zyC1u2\nbGHNmjUkJSVZ9PNpaVfMtnt5uZGcnHFXYszKyuLy5csANGx4L6mpWXfle23hbvZLRaJ+MU/9Yp76\nxTz1i3ll0S8l/ePAasNMo9FISkqK6f3Fixfx8vICYP/+/Vy6dIm//OUvhIaGEh0dzZw5c6wVWony\n8q7SunUbQPfLRUTEflktmXfq1IkdO3YAEB0djdFoNE2x9+rVi08//ZTNmzezZMkSWrRowbRp06wV\nWolq1arNunX/ApTMRUTEflltmj0gIIAWLVoQHByMwWAgPDycLVu24ObmRo8ePawVxh1LSIgHoG5d\nPZYmIiL2yar3zCdNmlTsvZ+f323HNGjQgPXr11srpFJt2PABixYtAFDpUxERsVvld2m2FezZs4tz\n584C2jBGRETsl5J5KdLTL5te162re+YiImKflMxLcfFiEs7OzoCSuYiI2C8l81LEx8fj5OSMg4MD\nRqO3rcMRERExy2abxti7jIx0MjLSMRgMuLt7mEboIiIi9kYj8xKkp6fj5WWksLAQo9Fo63BERERK\npGRegvr1G/DFF/sBaNy4qY2jERERKZmSeSkSE4s2jNHubyIiYs90z7wE3377Ne+/vwLQ7m8iImLf\nNDIvQUTEP/nkk48A7f4mIiL2Tcm8BPHx8abX2v1NRETsmZJ5CRIS4nBxqQJowxgREbFvSuZmFBYW\nkpCQYHq2vE4dTbOLiIj90gI4My5f/oUrV7JwcnLCzc2NatWq2TokERGREmlkbsaFCxcAuHbtGvfc\n42bjaEREREqnZG6Gn58/R48eA8DX19fG0YiIiJROybwEWVlXAGjUyMe2gYiIiPwGJXMzYmPPsH//\nN4B2fxMREfunBXBmLFgwl82b/wWAm1sNG0cjIiJSOo3MzUhI+HXDmKZNVWRFRETsm5K5GfHxcVSt\nWhWABg0a2TgaERGR0imZ36KwsJDExAScnV0A7csuIiL2T/fMb5GamkpOTg6FhVC1ajXdMxcREbun\nkfktEhLiAMjNzcHJyRGDwWDjiEREREqnZH6LJk2asnbtRgAaN9biNxERsX9K5reoXt0Nf/8WANx/\nfwsbRyMiIvLblMxvkZ+fT2JiAqANY0REpHzQArhb/O1vI/n4448AyM29auNoREREfptG5rdITEwg\nL68oidesWdPG0YiIiPw2JfNbxMfH4+rqCkDXrt1sHI2IiMhvUzK/SUFBAYmJ8bi4VAGgQYN7bRyR\niIjIb1Myv0lycjJ5eXnk51/D2dkZDw8PW4ckIiLym7QA7iaJiUUFVjIzMzEYDNowRkREygWNzG/i\n5WXklVdmUFhYiNHobetwRERELKJkfpP69RswYMBAADp2fMTG0YiIiFhGyfwWN2qZ161b38aRiIiI\nWEb3zG8ya9ar7Nr1GQDZ2VdsHI2IiIhlNDK/yYED+zhx4gQAKSkpNo5GRETEMkrmN0lIiMfV9R4A\nnn66n42jERERsYyS+XX5+flcuJBIlSpFG8a0bdvOxhGJiIhYRsn8uosXk8jPz8dgAAcHBz2aJiIi\n5YaS+XXx8XEApKdnAAbOn//ZtgGJiJRzR48eZvr0KcXaFi1aYHpq6IYzZ04RGjrytp+fPn0KR48e\nLrP4zMXyex09epiRI4fw4ovDmDPnNQoKCgBYvHgBo0YNZfToYcTERAOQlHSB0NCRjBnzAjNmhHH1\n6h+v0Klkfl2VKlXo2TOIa9fycHR0oHp1N1uHJCJS4YwbN5F69ezj0d+7Gcu8ebN54425LF++mitX\nrnDgwLccPHiQuLjzrFixhrCwGSxcOB+AVatW0K/fcyxb9j4NGjRk+/Ztf/j8ejTtulatHmDhwqXc\nf38TevTohZeXl61DEhG5K2bOnM7HH394V7+zT5+nmTnzjd887sqVbGbNmsGpUyfp2jWQI0cOMWHC\nFKpXd2PGjDCcnZ1p1uw+0/EbN37Arl07qFOnLllZWde/I4s5c14jIyOD/Px8Xn55Ms2aNWfAgKd5\n6ql+fPPNV1y9epVFi5aZFjHf6v/+7xO2bNmMk1PR+SZOnEpo6EgmTJjC55/vJirqCABnzpxm/PjJ\ndOr06G3nbNy4CePGvVjse7296zBjxixWrVrPPfdUB6BWrdpcvnyZ2NiTPPpoFwB8fBqTkZFOVlYm\nUVFHmDTpFQA6dXqUf/1rPX37Pntn/wNuoWR+kxt7s9erV8/GkYiIVAxnz57hn//8XwoKCnjuuSfx\n8WkCQGTkJrp378lzzz3Phg1rOXXqJBkZGWzdGsnGjZHk51/jueeeBmDz5n/RocMj9OnzNLGxZ1i0\naD4LFy4jPz+fRo18GDgwhPDwVzh8+BCPPdbFbBybNm1g3ryFeHvXYfv2beTm5pg+Gz58FAAnTx7n\nnXfm0aVLdzZu/MDsOZcsWWn2+28k8pSUFA4d2s+IEaP54IOVNGzYxHRMrVq1SU1NJTs7GxcXFwBq\n13YnNTX1j3UySuYmH3ywmv37vwHAYHC0cTQiInfPzJlvWDSKLgu+vn5UrVoVgMLCQlP72bOxdO0a\nCMCDDz7E/v3fEh9/nsaNm1x/qqgKvr7+APzww/f88ksaO3Z8ClAsET/wwIMAeHl5k5WVWWIcgYF/\nYtq0yfzpT0EEBv6JKlWqFvs8JyeHuXNnEx7+Bs7OzqWesyRpaZeYOnU8EyeGUbNmrds+v/n3L63t\n91Ayv27Tpg1ERR0FYO/eXTaORkSkYnB0ND84KiwsxGBwuP664La2m9udnZ0YP34yLVu2LvX7S0uM\ngwcPpUePIPbu3cVLL73I0qXFR9iLFs2nb99nadTo3hLPmZ+fX+I0e1ZWJhMnvsTIkWNo3/5hAIxG\nY7FRd0pKCp6enlSr5kpubg5VqlQlOfkinp6eJcZtKS2Auy4+Pt40TdK7dx8bRyMiUrE1anQvx4//\nCGBasV6/fgPOnYslLy+PrKxMTpyIAeD++1vy5Zd7AYiNPcOmTRvu6FwFBQWsWLEUT09PgoMH0bJl\nKy5cuGD6fO/e3WRlZfHEE0+Z2syd09HRkSVLVhb7M2PGLACWLFnIgAEDefjhX4t0derUib17dwNw\n4sRxPD09cXW9h4ceas/evXsA+OKLPXTo8McLe2lkDuTl5ZGUdAFPTy8yMtIZOHCwrUMSEanQ+vd/\nnhkzwvjyy89p2rQ5ADVq1CQo6AlGjRpKvXr18fNrAcCzzw5g9uyZjBnzAgUFBbz88qQ7OpeDgwOu\nrvcwatRQqlevTr169Wne/NdFdytWLKVaNVfT43Fdu3a/o3Pm5OTw2WfbOX/+Z9NCwx49evHCC3/F\n19ef0aOHYTAYmDBhKlB0j/6NN17lo4+2UKdOXYKCnrij38ccQ+HdmrC3suTkDLPtXl5uJX5WkvPn\nf6Zt25Z4eXmTnJzEzz9fNN3jqSh+T79UBuoX89Qv5qlfzFO/mFcW/eLlZf6xaauOzOfMmcN3332H\nwWBg2rRptG79672IzZs3ExkZiYODA35+foSHh2MwGKwSV3x80Sr27OwsXFxciIo6QseOnaxybhER\nuTsuXLjAG2+8elv7gw+2Na1Yr6islswPHjzIuXPniIiI4PTp00ybNo2IiAgAsrOz2b59Oxs3bsTZ\n2ZmQkBCioqIICAiwSmxXrmTi6elJWtov5OdfIynpwm//kIiI2JU6deqU+OhYRWe1BXD79u0jMLDo\nMYSmTZty+fJlMjOLHiOoVq0aH3zwAc7OzmRnZ5OZmWnVTVu6devBgQP/JT//Go8++jiBgT2tdm4R\nEZE/ymoj85SUFFq0aGF67+7uTnJyMtWrVze1rVy5knXr1hESEkLDhg1L/b7atV1xcjL/yENJ9xRK\nk5x8HgB/f18aN66Ym8b8nn6pDNQv5qlfzFO/mKd+Mc9a/WKz1ezm1t2NHDmSkJAQRowYQdu2bWnb\ntm2JP5+WdsVs++9dcHDs2EkAatb0qJALObRAxTz1i3nqF/PUL+apX8yz5gI4q02zG41GUlJSTO8v\nXrxomkr/5ZdfOHToEABVq1blscce4+jRo9YKDYALFxIBWLBgLteuXbPquUVERP4IqyXzTp06sWPH\nDgCio6MxGo2mKfZr164RFhZm2lT/hx9+oHHjxtYKDcBUBq916zY4OenxexGRP6qyl0A9cOAATzwR\nSGjoSEJDR/L3v88DyqYEqtWyVkBAAC1atCA4OBiDwUB4eDhbtmzBzc2NHj168Le//Y2QkBCcnJzw\n9fWle/fu1goNgISEBADeffcfVj2viEhlMm7cRFuHYHI3Y5k3bzaLF/8Do9Gb6dOncuDAt3h7u9Om\nTQBvvDGv2LE3SqB26xbIihVL2b59W/mqmjZpUvEddPz8/Eyv+/XrR79+/awZTjEXLhQlc1VME5GK\nqG3blmbbx4x5ieHDR15/PYIDB/aZ+dmHWLlyLQDr169l4cL5HDlyzKLzVuYSqN7e7mZjUQnUMnT+\n/HlcXFz48ccf6dDhYVuHIyJSIVTmEqipqQmcPRvL1KnjSU9PZ9iwEbRr97BKoJalhIQ4rl69SmRk\nhJK5iFQ4loykly177zePGTx4CIMHD7H4vJW5BKqbmwtDh46gW7ceJCTEM3bsKCIiPiz2MyqBehfl\n5OSQnp6Ov38LgoMH2jocEZEKozKXQPX29qZ796JNyOrXb4CHhwfJyRfLpASqkjmQmFh0v7x16wdo\n27adjaMREan4bpRA9fPzN1sC9erV3NtKoLZs2ZrY2DMcOPAtwcGDLD5XQUEB7723nOHDRxEcPIiz\nZ2MtLoF66zlLmmY3VwJ127ZtxMbGMXDgYFJTU7h06RJeXkZTCdQ//am3SqDeTTeSuRa/iYhYR2Uo\ngRoc/Axjx77M119/QV5eHpMmFS34UwnUm9zNEqgffvi/jBw5lHvv9WHt2n/SooX5VZ/lmXZoMk/9\nYp76xTz1i3nqF/MqbAlUe9WuXQd8ff04deonq5VdFRGRu0slUCu5+vUb8NVXBykoKLB1KCIi8jtV\n5hKoSuY3cXCw2u62IiIid42y13XHj8fctT16RURErEkj8+v69fsztWrV5ttvj9g6FBERkTuiZH5d\n//7PU6NGDVuHISIicsc0zX7da6/NZuLEqbYOQ0SkwqhMJVC3bdtqKoE6f/5bpt3oFi9ewKhRQxk9\nehgxMdFA2ZRAVTIXERGrGTduIvXq1bd1GMDdiyUnJ4fdu3eybNn7LF++mp9/PsuxY99z8OBB4uLO\ns2LFGsLCZrBw4Xzg1xKoy5a9T4MGDdm+fdsfjkHT7MDJkyfYuHEdQUF/LrYVn4hIRdG2bctipUw/\n+WQb4eHTmDHjNZ5++hng1xKo+/YdxcXFhdTUVHr2fJzAwJ7MnfsOoBKoJe3NvmjRcqAosWdmZuLu\n7sEXX+zk0Ue7AODj05iMjHSysjJVArWsHD/+I8uXv0vDhg2VzEVE7qLKUgIViv6hExn5L/r3f576\n9RuQkpJCw4ZNTJ/XqlWb1NRUlUAtK126dOOzz/bYzdSPiMjddutI+oknnuSJJ54s1nZrCVQPD4/b\nfk4lUEs2ePAQnnsumEmTxtG6dZvbPje3e7pKoN5FNWrUJCDgIVuHISJS4VSGEqjjxk3kzJnTtGkT\nQJUqVXn44Uf44YfvMBqNxUbdKSkpeHp6lkkJVC2AExERq7tRAhUwWwI1KyvzthKoALGxZ9i0acMd\nnaugoIAVK5bi6elJcPAgWrZsZXEJ1JvP6ejoyJIlK4v9mTFjFteuXWP27Ne4cuUKADEx0TRqdC+d\nOnVi797dAJw4cRxPT09cXe8xlUAFVAJVRETKr4pUAtXd3YOhQ1/gpZdG4+joSLNmzenc+XGMxhr4\n+vozevQwDAYDEyYUPf6sEqg3uZslUCsD9Yt56hfz1C/mqV/MU7+YpxKoIiIid0glUEVERMq5ylwC\nVQvgREREyjklcxERkXJOyVxERKScUzIXEREp55TMRUREyjklcxERkXJOyVxERKScK7c7wImIiEgR\njcxFRETKOSVzERGRck7JXEREpJxTMhcRESnnlMxFRETKOSVzERGRcq5ClUCdM2cO3333HQaDgWnT\nptG6dWtbh2RzBw4cYNy4cTRv3hyA++67jxkzZtg4Kts6efIkY8aMYciQIQwaNIjExESmTJlCfn4+\nXl5evP3227i4uNg6TKu7tV/CwsKIjo6mVq1aAAwfPpwuXbrYNkgrmzdvHkeOHOHatWuMGjWKVq1a\n6Vrh9n7Zs2dPpb9WsrOzCQsLIzU1ldzcXMaMGYOfn5/VrpcKk8wPHjzIuXPniIiI4PTp00ybNo2I\niAhbh2UX2rdvz+LFi20dhl24cuUKr7/+Oh07djS1LV68mIEDBxIUFMQ777xDZGQkAwcOtGGU1meu\nXwAmTJhA165dbRSVbe3fv5+ffvqJiIgI0tLS6Nu3Lx07dqz014q5fnn44Ycr9bUC8Pnnn9OyZUtG\njBhBfHw8w4YNIyAgwGrXS4WZZt+3bx+BgYEANG3alMuXL5OZmWnjqMTeuLi48N5772E0Gk1tBw4c\noHv37gB07dqVffv22So8mzHXL5Vdu3btWLRoEQA1atQgOztb1wrm+yU/P9/GUdle7969GTFiBACJ\niYl4e3tb9XqpMMk8JSWF2rVrm967u7uTnJxsw4jsx6lTpxg9ejTPP/8833zzja3DsSknJyeqVq1a\nrC07O9s09eXh4VEprxtz/QKwYcMGQkJCGD9+PJcuXbJBZLbj6OiIq6srAJGRkTz22GO6VjDfL46O\njpX6WrlZcHAwkyZNYtq0aVa9XirMNPuttEttER8fH0JDQwkKCuL8+fOEhISwc+fOSnmfzxK6bn71\n1FNPUatWLfz9/Vm5ciVLlizh1VdftXVYVrdr1y4iIyNZvXo1PXv2NLVX9mvl5n45duyYrpXrNm3a\nRExMDJMnTy52jZT19VJhRuZGo5GUlBTT+4sXL+Ll5WXDiOyDt7c3vXv3xmAw0KhRIzw9PUlKSrJ1\nWHbF1dWVnJwcFsncWgAABZtJREFUAJKSkjTVfF3Hjh3x9/cHoFu3bpw8edLGEVnfV199xT/+8Q/e\ne+893NzcdK1cd2u/6FqBY8eOkZiYCIC/vz/5+fncc889VrteKkwy79SpEzt27AAgOjoao9FI9erV\nbRyV7W3bto1Vq1YBkJycTGpqKt7e3jaOyr488sgjpmtn586dPProozaOyD6MHTuW8+fPA0XrCm48\nEVFZZGRkMG/ePFasWGFapa1rxXy/VPZrBeDw4cOsXr0aKLrte+XKFateLxWqatr8+fM5fPgwBoOB\n8PBw/Pz8bB2SzWVmZjJp0iTS09PJy8sjNDSUxx9/3NZh2cyxY8eYO3cu8fHxODk54e3tzfz58wkL\nCyM3N5d69erx5ptv4uzsbOtQrcpcvwwaNIiVK1dSrVo1XF1defPNN/Hw8LB1qFYTERHBu+++S+PG\njU1tb731FtOnT6/U14q5funXrx8bNmyotNcKQE5ODv/zP/9DYmIiOTk5hIaG0rJlS6ZOnWqV66VC\nJXMREZHKqMJMs4uIiFRWSuYiIiLlnJK5iIhIOadkLiIiUs4pmYuIiJRzSuYiYhXdunXD19e3Um4o\nIlLWlMxFRETKOSVzERGRck7JXKSCy8zMZNasWQQGBtKqVSuefPJJdu/eDcCUKVPw9fXl3//+N5Mm\nTSIgIID27duzbNmyYt/x/fffM3z4cAICAmjVqhV9+vRh8+bNxY6Ji4tj3LhxtGvXjoCAAAYNGsSR\nI0duiyctLY1Ro0bRpk0bevfuXekr+YncDUrmIhXcuHHj2LhxI61bt2by5Mk4ODgwduxYoqKicHAo\n+itgwYIF1KpVi2HDhnH16lUWLVrExx9/DMDx48cZNGgQ+/fvp3///owdO5a0tDRmzJjB2rVrgaJ/\nMAwePJjPPvuMoKAgRo0axfHjxxk+fDinTp0qFs/bb79Nq1atCAwM5PTp00yaNInc3Fyr9olIRVNh\nS6CKCJw4cYKvv/4ad3d3wsLCMBgM+Pj4MGLECDZt2oTBYACKKqRNnz7d9HPvvvsuH374IX369GHN\nmjXk5uYydOhQwsLCAPD19WXkyJGsWrWKIUOGsH37dhISEmjfvj2zZs0CoGHDhnz55ZfExsbSrFkz\n03f/+c9/ZujQoRQWFnLw4EGSkpKIjY1VLQWRP0DJXKQCO336NACXLl26rWJTbGwsTZo0AaBdu3am\n9pYtWwJF0+YAP/30EwBt2rQxHdOqVSugqNRwZmYmMTExQFGSv6F379707t37tphat24NgMFgoEGD\nBiQlJZGenv4HfksRUTIXqQTq16/PzJkzi7W5uroSGRkJQH5+vqn9Ru2lG6P2G/WYb67JdPPr3Nxc\nXFxcbmsvyY1jARwdHS3+OREpme6Zi1RgN6a309LSeOihh3jsscdo1aoVTk5OGI1G03HHjh0zvf7x\nxx8B8PHxAX4dqf/3v/81HRMVFQVAnTp18PDwMNWvjo6ONh2zZcsWnn/+edavX18Gv5mI3Ewjc5EK\n7L777qNjx47s27ePUaNG0bVrV3bu3ElUVBSzZ882Hbd7927mz59PjRo1eP/99wF49tlnAQgNDWXH\njh1s3LgRBwcHatasaVr4FhoaCkCfPn1YunQpUVFRTJs2DR8fH9577z1yc3MJDw+37i8tUglpZC5S\nwS1evJj+/fsTHx/PO++8Q1paGrNnzzYla4DRo0dz6tQp3n33XVxdXZk+fTqBgYEANGrUiMjISDp0\n6MCmTZtYunQpdevWZcGCBfTv3x+AqlWrsmnTJnr27MmOHTtYsWIFvr6+rF69WgvbRKzAUKibVSKV\nVlhYGFu3buXNN9+kX79+tg5HRH4njcxFRETKOSVzERGRck7T7CIiIuWcRuYiIiLlnJK5iIhIOadk\nLiIiUs4pmYuIiJRzSuYiIiLlnJK5iIhIOff/DjjPw8iq/xAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd195530b90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAFcCAYAAADLZ8e5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAer4Y6/LIqHBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd187768850>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl33snrqGY3E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1202
        },
        "outputId": "969ed34b-ade0-4336-fd4b-ef45a91941a7"
      },
      "source": [
        "#RNN_sent_model.py  for gru              ARTICLE LEVEL CASE\n",
        "\n",
        "\n",
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "\n",
        "import argparse\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import utils.file2dict as fdt\n",
        "import utils.read_minibatch as rmb\n",
        "import utils.data_util as data_util\n",
        "import utils.confusion_matrix as cm\n",
        "import utils.data_util as du\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from AttributionModel import AttributionModel\n",
        "from proj_rnn_cell import RNNCell\n",
        "from proj_gru_cell import GRUCell\n",
        "\n",
        "logger = logging.getLogger(\"RNN_Author_Attribution\")\n",
        "logger.setLevel(logging.DEBUG)\n",
        "logging.basicConfig(format='%(message)s', level=logging.DEBUG)\n",
        "\n",
        "tf.reset_default_graph()  #used so that variables gets reinitialized every time\n",
        "\n",
        "class Config:\n",
        "    cell_type=\"gru\" # either rnn, gru or lstm\n",
        "\n",
        "    window_size = 0\n",
        "\n",
        "    max_length = 24 # longest length of a sentence we will process\n",
        "    n_classes = 50 # in total, we have 50 classes\n",
        "    dropout = 0.8\n",
        "\n",
        "    embed_size = 50\n",
        "\n",
        "    hidden_size = 300\n",
        "    batch_size = 16\n",
        "\n",
        "    n_epochs = 3\n",
        "    regularization = 0.00001\n",
        "\n",
        "    max_grad_norm = 10.0 # max gradients norm for clipping\n",
        "    lr = 0.004 # learning rate\n",
        "    \n",
        "    def __init__(self, args):\n",
        "\n",
        "        #self.cell = args.cell\n",
        "\n",
        "        self.cell = GRUCell(Config.embed_size, Config.hidden_size)\n",
        "        if \"output_path\" in args:\n",
        "            # Where to save things.\n",
        "            self.output_path = args.output_path\n",
        "        else:\n",
        "            self.output_path = \"results/{}/{:%Y%m%d_%H%M%S}/\".format(\"RNN\", datetime.now())\n",
        "\n",
        "        self.model_output = self.output_path + \"model.weights\"\n",
        "        self.eval_output = self.output_path + \"results.txt\"\n",
        "\n",
        "        #self.conll_output = self.output_path + \"{}_predictions.conll\".format(self.cell)\n",
        "        self.log_output = self.output_path + \"log\"\n",
        "\n",
        "class RNNModel(AttributionModel):\n",
        "    def add_placeholders(self):\n",
        "        self.input_placeholder = tf.placeholder(tf.float32, [None, Config.max_length, Config.embed_size])\n",
        "        self.labels_placeholder = tf.placeholder(tf.int32, [None, Config.n_classes])\n",
        "        self.mask_placeholder = tf.placeholder(tf.float32, [None, Config.max_length])\n",
        "        self.dropout_placeholder = tf.placeholder(tf.float32)\n",
        "      \n",
        "    def create_feed_dict(self, inputs_batch, mask_batch, labels_batch=None, dropout=1):\n",
        "        feed_dict = {}\n",
        "        if labels_batch is not None:\n",
        "            feed_dict[self.labels_placeholder] = labels_batch\n",
        "        if inputs_batch is not None:\n",
        "            feed_dict[self.input_placeholder] = inputs_batch\n",
        "        if dropout is not None:\n",
        "            feed_dict[self.dropout_placeholder] = dropout\n",
        "        if mask_batch is not None:\n",
        "            feed_dict[self.mask_placeholder] = mask_batch\n",
        "\n",
        "        return feed_dict\n",
        "      \n",
        "    def add_embedding(self):\n",
        "       \n",
        "        embeddingTensor = tf.Variable(self.pretrained_embeddings,tf.float32)\n",
        "        embeddings = tf.nn.embedding_lookup(embeddingTensor, self.input_placeholder)\n",
        "\n",
        "        return embeddings\n",
        "      \n",
        "    def add_prediction_op(self):\n",
        "        #x = self.add_embedding()\n",
        "        x = self.input_placeholder\n",
        "        if Config.cell_type==\"lstm\":\n",
        "            print \"lstm\"\n",
        "            cell_state = tf.zeros([tf.shape(x)[0], Config.hidden_size])\n",
        "            hidden_state = tf.zeros([tf.shape(x)[0], Config.hidden_size])\n",
        "            init_state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)\n",
        "            cell = tf.nn.rnn_cell.BasicLSTMCell(Config.hidden_size, state_is_tuple=True)\n",
        "            inputs_series=tf.split(1,Config.max_length,x)\n",
        "            outputs, current_state = tf.nn.rnn(cell, inputs_series, init_state)\n",
        "\n",
        "\n",
        "            self.U = tf.get_variable('U',\n",
        "                                  [Config.hidden_size, Config.n_classes],\n",
        "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
        "            self.b2 = tf.get_variable('b2',\n",
        "                                  [Config.n_classes, ],\n",
        "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
        "            h = tf.zeros([tf.shape(x)[0], Config.hidden_size])\n",
        "\n",
        "            preds=[tf.matmul(o, self.U) + self.b2 for o in outputs]\n",
        "            preds=tf.stack(preds)\n",
        "            preds=tf.reshape(preds,[-1,Config.max_length,Config.n_classes])\n",
        "            return preds\n",
        "\n",
        "\n",
        "        else:\n",
        "            dropout_rate = self.dropout_placeholder\n",
        "\n",
        "            preds = [] # Predicted output at each timestep should go here!\n",
        "\n",
        "            if Config.cell_type==\"rnn\":\n",
        "                cell = RNNCell(Config.embed_size, Config.hidden_size)\n",
        "            elif Config.cell_type==\"gru\":\n",
        "                cell = GRUCell(Config.embed_size, Config.hidden_size)\n",
        "            else:\n",
        "                assert False, \"Cell type undefined\"\n",
        "          \n",
        "            self.U = tf.get_variable('U',\n",
        "                                  [Config.hidden_size, Config.n_classes],\n",
        "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
        "            self.b2 = tf.get_variable('b2',\n",
        "                                  [Config.n_classes, ],\n",
        "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
        "            h = tf.zeros([tf.shape(x)[0], Config.hidden_size])\n",
        "\n",
        "            with tf.variable_scope(\"RNN\"):\n",
        "\n",
        "                for time_step in range(config.max_length):\n",
        "                    if time_step >= 1:\n",
        "                        tf.get_variable_scope().reuse_variables()\n",
        "                    o, h = cell(x[:,time_step,:], h)\n",
        "\n",
        "                    o_drop = tf.nn.dropout(o, dropout_rate)\n",
        "                    preds.append(tf.matmul(o_drop, self.U) + self.b2)\n",
        "            preds=tf.stack(preds)\n",
        "            preds=tf.reshape(preds,[-1,Config.max_length,Config.n_classes])\n",
        "            return preds\n",
        "          \n",
        "    def add_loss_op(self, preds):\n",
        "        \n",
        "        self.pred_mask=tf.reshape(self.mask_placeholder,[-1,Config.max_length,1])\n",
        "        self.pred_mask=tf.tile(self.pred_mask,[1,1,Config.n_classes])\n",
        "\n",
        "        self.pred_masked=tf.multiply(preds,self.pred_mask)\n",
        "        self.pred_masked=tf.reduce_sum(self.pred_masked,axis=1)\n",
        "\n",
        "        loss = tf.nn.softmax_cross_entropy_with_logits(logits=self.pred_masked, labels=self.labels_placeholder)\n",
        "\n",
        "        loss = tf.reduce_mean(loss) + config.regularization * ( tf.nn.l2_loss(self.U) )\n",
        "\n",
        "        with tf.variable_scope(\"RNN/cell\", reuse= True):\n",
        "            # add regularization\n",
        "\n",
        "            if Config.cell_type=='gru':\n",
        "                loss += config.regularization * (tf.nn.l2_loss(tf.get_variable(\"W_r\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"U_r\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"W_z\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"U_z\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"W_o\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"U_o\")))\n",
        "        return loss\n",
        "          \n",
        "    def add_training_op(self, loss):\n",
        "        train_op = tf.train.AdamOptimizer(Config.lr).minimize(loss)\n",
        "        return train_op\n",
        "\n",
        "    def train_on_batch(self, sess, inputs_batch, labels_batch, mask_batch):\n",
        "\n",
        "        feed = self.create_feed_dict(inputs_batch, labels_batch=labels_batch, mask_batch=mask_batch,\n",
        "                                     dropout=Config.dropout)\n",
        "        _, loss, pred, pred_mask = sess.run([self.train_op, self.loss, self.pred, self.pred_mask], feed_dict=feed)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def predict_on_batch(self, sess, inputs_batch, mask_batch):\n",
        "        \n",
        "        feed = self.create_feed_dict(inputs_batch,mask_batch)\n",
        "        predictions = sess.run(tf.nn.softmax(self.pred), feed_dict=feed)\n",
        "        mask2=np.stack([mask_batch for i in range(Config.n_classes)] ,2)\n",
        "        pred2=np.sum(np.multiply(predictions,mask2),1)\n",
        "        return pred2\n",
        "\n",
        "\n",
        "    def record_history_init(self,f):\n",
        "        f.write(\"###\\n\")\n",
        "        f.write(\"training_model: \"+sys.argv[0]+\"\\n\")\n",
        "        f.write(\"starting_time: \"+str(datetime.now())+\"\\n\")\n",
        "        f.write(\"\\n\")\n",
        "        f.write(\"parameters:\\n\")\n",
        "        f.write(\"\\tcell_type: \"+Config.cell_type+\"\\n\")\n",
        "        f.write(\"\\tembed_size: {}\\n\".format(Config.embed_size))\n",
        "        f.write(\"\\thidden_size: {}\\n\".format(Config.hidden_size))\n",
        "        f.write(\"\\tlearning_rate: {0:.4f}\\n\".format(Config.lr))\n",
        "        f.write(\"\\tregularization: {0:.5f}\\n\".format(Config.regularization))\n",
        "        f.write(\"\\tdropout: {0:.5f}\\n\".format(Config.dropout))\n",
        "        f.write(\"\\tn_epochs: {0:.5f}\\n\".format(Config.n_epochs))\n",
        "        f.write(\"\\tbatch_size: {}\\n\".format(Config.batch_size))\n",
        "        f.write(\"\\n\")\n",
        "        f.write(\"training history:\\n\")\n",
        "        f.write(\"epoch \\t\\t loss \\t\\t train_accu \\t\\t test_accu\\n\")\n",
        "\n",
        "    def record_history_accu(self,f,n_epoch,average_train_loss,train_accu,test_accu):\n",
        "        f.write(\"{0:d} \\t\\t {1:.5f} \\t\\t {2:.5f} \\t\\t {3:.5f}\\n\".format(n_epoch,average_train_loss,train_accu,test_accu))\n",
        "\n",
        "    def record_history_finish(self,f):\n",
        "        f.write(\"END\\n\")\n",
        "        f.write(\"\\n\")\n",
        "        f.close()\n",
        "\n",
        "    def test_model(self, session, batch_list):\n",
        "        print \"Now, testing on the test set...\"\n",
        "        total = 0\n",
        "        accuCount = 0\n",
        "        for batch in batch_list:\n",
        "            batch_feat = np.array(batch[1], dtype = np.float32)\n",
        "            batch_mask = np.array(batch[2], dtype = np.float32)\n",
        "\n",
        "            pred = self.predict_on_batch(session, batch_feat, batch_mask)\n",
        "            accuCount += np.sum(np.argmax(pred,1) == batch[0])\n",
        "            total += len(batch[0])\n",
        "        accu = accuCount * 1.0 / total\n",
        "        logger.info( (\"Test accuracy %f\" %(accu)) )\n",
        "        return accu\n",
        "\n",
        "    def test_trainset_model(self, session, batch_list):\n",
        "        print \"Now, testing on the training set, notice this is only for debugging...\"\n",
        "        total = 0\n",
        "        accuCount = 0\n",
        "        for batch in batch_list:\n",
        "            batch_feat = np.array(batch[1], dtype = np.float32)\n",
        "            batch_mask = np.array(batch[2], dtype = np.float32)\n",
        "\n",
        "            pred = self.predict_on_batch(session, batch_feat, batch_mask)\n",
        "            accuCount += np.sum(np.argmax(pred,1) == batch[0])\n",
        "            total += len(batch[0])\n",
        "        accu = accuCount * 1.0 / total\n",
        "        logger.info( (\"Test accuracy on training set is: %f\" %(accu)) )\n",
        "        return accu\n",
        "      \n",
        "    def process_model_output(self):\n",
        "\n",
        "        pkl_file = open('/content/auth_id/data_sentence.pkl', 'rb') #changed filename from data_sentence_index_test to data_sentence to load train data\n",
        "        batch_list = pickle.load(pkl_file)\n",
        "        pkl_file.close()\n",
        "\n",
        "        test_size = int(len(batch_list) / 10)  #changed division by 10 to 1\n",
        "        training_batch = batch_list[0 : len(batch_list) - test_size]\n",
        "        print test_size, len(batch_list)\n",
        "        testing_batch = batch_list[len(batch_list) - test_size : len(batch_list)]\n",
        "\n",
        "        init = tf.global_variables_initializer()\n",
        "        saver = tf.train.Saver()\n",
        "        with tf.Session() as session:\n",
        "            session.run(init)\n",
        "            #load_path = \"results/RNN/20170318_221625/model.weights_10\"\n",
        "            saver.restore(session, \"./model_weights_glove\")\n",
        "\n",
        "            print \"Now, collecting the model outputs...\"\n",
        "            total = 0\n",
        "            accuCount = 0\n",
        "            pred_list = []\n",
        "            real_label_list = []\n",
        "            for batch in testing_batch:\n",
        "                  batch_feat = np.array(batch[1], dtype = np.float32)\n",
        "                  batch_mask = np.array(batch[2], dtype = np.float32)\n",
        "\n",
        "                  pred = self.predict_on_batch(session, batch_feat, batch_mask)\n",
        "                  accuCount += np.sum(np.argmax(pred,1) == batch[0])\n",
        "                  total += len(batch[0])\n",
        "                  \n",
        "            accu = accuCount * 1.0 / total\n",
        "            print( (\"Test accuracy %f\" %(accu)) )\n",
        "            \n",
        "            t_cm = cm.generate_cm(real_label_list,pred_list, Config.n_classes)    \n",
        "            x = t_cm.as_matrix().astype(np.uint8)\n",
        "            print x\n",
        "            du.visualize_cm(x, \"gutenberg_sentence\")\n",
        "            return accu        \n",
        "\n",
        "    def train_model(self):\n",
        "            level='word_level'\n",
        "            dataset='gutenberg'\n",
        "            date='0318'\n",
        "            training_history_txt_filename='/content/auth_id/results/training_history.txt'\n",
        "            training_history_file = open(training_history_txt_filename,'a+')\n",
        "            self.record_history_init(training_history_file)\n",
        "\n",
        "            if not os.path.exists(config.log_output):\n",
        "                os.makedirs(os.path.dirname(config.log_output))\n",
        "            handler = logging.FileHandler(config.log_output)\n",
        "            handler.setLevel(logging.DEBUG)\n",
        "            handler.setFormatter(logging.Formatter('%(message)s'))\n",
        "            logging.getLogger().addHandler(handler)\n",
        "\n",
        "            pkl_file = open('/content/auth_id/data_sentence.pkl', 'rb')\n",
        "\n",
        "            batch_list = pickle.load(pkl_file)\n",
        "            pkl_file.close()\n",
        "\n",
        "            test_size = int(len(batch_list) / 10)\n",
        "            training_batch = batch_list[0 : len(batch_list) - test_size]\n",
        "            print test_size, len(batch_list)\n",
        "            testing_train_batch = batch_list[test_size : 2 * test_size]\n",
        "            testing_batch = batch_list[len(batch_list) - test_size : len(batch_list)]\n",
        "\n",
        "            init = tf.global_variables_initializer()\n",
        "            saver = tf.train.Saver()\n",
        "            with tf.Session() as session:\n",
        "                session.run(init)\n",
        "                #load_path = \"results/RNN/20170310_1022/model.weights_20\"\n",
        "                #saver.restore(session, load_path)\n",
        "                for iterTime in range(Config.n_epochs):\n",
        "                    loss_list = []\n",
        "                    smallIter = 0\n",
        "\n",
        "                    for batch in training_batch:\n",
        "                        batch_label = rmb.convertOnehotLabel(batch[0],  Config.n_classes)\n",
        "                        batch_feat = np.array(batch[1], dtype = np.float32)\n",
        "                        batch_mask = np.array(batch[2], dtype = np.float32)\n",
        "                      #  print batch_mask\n",
        "                        loss = self.train_on_batch(session, batch_feat, batch_label, batch_mask)\n",
        "                        loss_list.append(loss)\n",
        "                        smallIter += 1\n",
        "\n",
        "                        if(smallIter % 20 == 0):\n",
        "\n",
        "                            #self.test_trainset_model(session, testing_train_batch)\n",
        "                            #self.test_model(session, testing_batch)\n",
        "                            logger.info((\"Intermediate epoch %d Total Iteration %d: loss : %f\" %(iterTime, smallIter, np.mean(np.mean(np.array(loss)))) ))\n",
        "\n",
        "                    average_train_loss=np.mean(np.array(loss_list))\n",
        "                    train_accu=self.test_trainset_model(session, testing_train_batch)\n",
        "                    test_accu=self.test_model(session, testing_batch)\n",
        "                    self.record_history_accu(training_history_file,iterTime,average_train_loss,train_accu,test_accu)\n",
        "                    if(iterTime % 10 == 0):\n",
        "                        logger.info((\"epoch %d : loss : %f\" %(iterTime, np.mean(np.mean(np.array(loss)))) ))\n",
        "                        saver.save(session, \"./model_weights_glove\") #changed path name to model_weights\n",
        "\n",
        "                        #if(smallIter % 200 == 0):\n",
        "                        print (\"Intermediate epoch %d : loss : %f\" %(iterTime, np.mean(np.mean(np.array(loss)))) )\n",
        "\n",
        "\n",
        "                print (\"epoch %d : loss : %f\" %(iterTime, np.mean(np.mean(np.array(loss)))) )\n",
        "                self.record_history_finish(training_history_file)\n",
        "\n",
        "\n",
        "    def __init__(self, config, pretrained_embeddings, report=None):\n",
        "\n",
        "        super(RNNModel, self).__init__(config)\n",
        "        self.pretrained_embeddings = pretrained_embeddings\n",
        "        self.raw_preds=None\n",
        "        self.input_placeholder = None\n",
        "        self.labels_placeholder = None\n",
        "        self.batch_mask_placeholder = None\n",
        "        self.mask_placeholder = None\n",
        "        self.dropout_placeholder = None\n",
        "\n",
        "        self.build()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = \"gru\"\n",
        "    config = Config(args)\n",
        "    glove_path = \"/content/glove.6B.50d.txt\"\n",
        "    glove_vector = data_util.load_embeddings(glove_path, config.embed_size)\n",
        "    model = RNNModel(config, glove_vector.astype(np.float32))\n",
        "\n",
        "    model.train_model()\n",
        "    model.process_model_output()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15 157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Intermediate epoch 0 Total Iteration 20: loss : 4.344902\n",
            "INFO:Intermediate epoch 0 Total Iteration 40: loss : 4.026558\n",
            "INFO:Intermediate epoch 0 Total Iteration 60: loss : 3.938172\n",
            "INFO:Intermediate epoch 0 Total Iteration 80: loss : 3.827962\n",
            "INFO:Intermediate epoch 0 Total Iteration 100: loss : 3.971529\n",
            "INFO:Intermediate epoch 0 Total Iteration 120: loss : 3.876811\n",
            "INFO:Intermediate epoch 0 Total Iteration 140: loss : 4.090477\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 0.041667\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.026316\n",
            "INFO:epoch 0 : loss : 3.942413\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Intermediate epoch 0 : loss : 3.942413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Intermediate epoch 1 Total Iteration 20: loss : 4.031553\n",
            "INFO:Intermediate epoch 1 Total Iteration 40: loss : 3.926654\n",
            "INFO:Intermediate epoch 1 Total Iteration 60: loss : 3.922607\n",
            "INFO:Intermediate epoch 1 Total Iteration 80: loss : 3.812349\n",
            "INFO:Intermediate epoch 1 Total Iteration 100: loss : 3.932571\n",
            "INFO:Intermediate epoch 1 Total Iteration 120: loss : 3.863362\n",
            "INFO:Intermediate epoch 1 Total Iteration 140: loss : 4.042767\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 0.045833\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.035088\n",
            "INFO:Intermediate epoch 2 Total Iteration 20: loss : 3.959415\n",
            "INFO:Intermediate epoch 2 Total Iteration 40: loss : 3.876372\n",
            "INFO:Intermediate epoch 2 Total Iteration 60: loss : 4.015905\n",
            "INFO:Intermediate epoch 2 Total Iteration 80: loss : 3.764166\n",
            "INFO:Intermediate epoch 2 Total Iteration 100: loss : 3.905041\n",
            "INFO:Intermediate epoch 2 Total Iteration 120: loss : 3.855807\n",
            "INFO:Intermediate epoch 2 Total Iteration 140: loss : 4.031605\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 0.033333\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.026316\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 : loss : 3.884176\n",
            "15 157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Restoring parameters from ./model_weights_glove\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, collecting the model outputs...\n",
            "Test accuracy 0.026316\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "./results/fig/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAFOCAYAAABKV1DqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nI1wAAJb7fyWhQFSn/H2RAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f307d641490>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSgq6fswxfle",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3473
        },
        "outputId": "5523e139-6994-42a8-9055-3c471183224e"
      },
      "source": [
        "%cd /content/auth_id/results/\n",
        "!cat training_history.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/auth_id/results\n",
            "###\n",
            "training_model: RNN_sent_model_embed.py\n",
            "starting_time: 2017-03-16 21:55:01.472013\n",
            "\n",
            "parameters:\n",
            "\tcell_type: gru\n",
            "\tembed_size: 50\n",
            "\thidden_size: 100\n",
            "\tlearning_rate: 0.0005\n",
            "\tregularization: 0.00000\n",
            "\tbatch_size: 16\n",
            "\n",
            "training history:\n",
            "epoch \t\t loss \t\t train_accu \t\t test_accu\n",
            "0 \t\t 3.31822 \t\t 0.27083 \t\t 0.25946\n",
            "1 \t\t 2.42042 \t\t 0.42742 \t\t 0.38716\n",
            "2 \t\t 1.84739 \t\t 0.53293 \t\t 0.48649\n",
            "3 \t\t 1.39370 \t\t 0.65121 \t\t 0.58041\n",
            "4 \t\t 1.03385 \t\t 0.72849 \t\t 0.64392\n",
            "5 \t\t 0.75409 \t\t 0.80847 \t\t 0.71014\n",
            "6 \t\t 0.54105 \t\t 0.86223 \t\t 0.72973\n",
            "7 \t\t 0.39351 \t\t 0.90793 \t\t 0.77905\n",
            "8 \t\t 0.27987 \t\t 0.93347 \t\t 0.79932\n",
            "9 \t\t 0.20876 \t\t 0.95833 \t\t 0.82027\n",
            "END\n",
            "\n",
            "###\n",
            "training model: siamese_network.py\n",
            "starting time: 2017-03-17 00:04:27.437097\n",
            "\n",
            "parameters:\n",
            "\tcell_type: gru\n",
            "\tembed_size: 50\n",
            "\thidden_size: 100\n",
            "\tlearning_rate: 0.0010\n",
            "\tregularization: 0.00000\n",
            "\tbatch_size: 16\n",
            "\n",
            "training history:\n",
            "epoch \t\t loss \t\t train_accu \t\t test_accu\n",
            "0 \t\t 6.35964 \t\t 0.24219 \t\t 0.23197\n",
            "1 \t\t 5.05598 \t\t 0.24279 \t\t 0.22837\n",
            "2 \t\t 4.66568 \t\t 0.24079 \t\t 0.22796\n",
            "###\n",
            "training model: siamese_network.py\n",
            "starting time: 2017-03-17 00:40:45.100162\n",
            "\n",
            "parameters:\n",
            "\tcell_type: gru\n",
            "\tembed_size: 50\n",
            "\thidden_size: 100\n",
            "\tlearning_rate: 0.0010\n",
            "\tregularization: 0.00000\n",
            "\tbatch_size: 16\n",
            "\n",
            "training history:\n",
            "epoch \t\t loss \t\t train_accu \t\t test_accu\n",
            "0 \t\t 2.60000 \t\t 0.92768 \t\t 0.93249\n",
            "1 \t\t 0.16800 \t\t 0.94832 \t\t 0.95633\n",
            "###\n",
            "training model: siamese_network.py\n",
            "starting time: 2017-03-18 05:39:38.159956\n",
            "\n",
            "parameters:\n",
            "\tcell_type: gru\n",
            "\tembed_size: 50\n",
            "\thidden_size: 100\n",
            "\tlearning_rate: 0.0010\n",
            "\tregularization: 0.00500\n",
            "\tbatch_size: 16\n",
            "\n",
            "training history:\n",
            "epoch \t\t loss \t\t train_accu \t\t test_accu\n",
            "0 \t\t 2.28918 \t\t 0.92288 \t\t 0.92468\n",
            "1 \t\t 0.75771 \t\t 0.94030 \t\t 0.93890\n",
            "2 \t\t 0.61900 \t\t 0.93490 \t\t 0.93950\n",
            "3 \t\t 0.53327 \t\t 0.96534 \t\t 0.96615\n",
            "4 \t\t 0.49153 \t\t 0.97496 \t\t 0.97576\n",
            "5 \t\t 0.46604 \t\t 0.98057 \t\t 0.98097\n",
            "6 \t\t 0.40643 \t\t 0.98598 \t\t 0.98838\n",
            "7 \t\t 0.40816 \t\t 0.99139 \t\t 0.99099\n",
            "8 \t\t 0.39715 \t\t 0.99239 \t\t 0.99139\n",
            "9 \t\t 0.36072 \t\t 0.99339 \t\t 0.99239\n",
            "10 \t\t 0.36206 \t\t 0.99419 \t\t 0.99439\n",
            "11 \t\t 0.35416 \t\t 0.99499 \t\t 0.99579\n",
            "12 \t\t 0.33678 \t\t 0.99399 \t\t 0.99419\n",
            "###\n",
            "training_model: RNN_sent_model.py\n",
            "starting_time: 2017-03-19 01:48:18.496763\n",
            "\n",
            "parameters:\n",
            "\tcell_type: gru\n",
            "\tembed_size: 50\n",
            "\thidden_size: 100\n",
            "\tlearning_rate: 0.0010\n",
            "\tregularization: 0.0000000\n",
            "\tbatch_size: 16\n",
            "\n",
            "training history:\n",
            "epoch \t\t loss \t\t train_accu \t\t test_accu\n",
            "###\n",
            "training_model: RNN_average_model.py\n",
            "starting_time: 2017-03-19 02:14:06.685723\n",
            "\n",
            "parameters:\n",
            "\tcell_type: gru\n",
            "\tembed_size: 50\n",
            "\thidden_size: 150\n",
            "\tlearning_rate: 0.0010\n",
            "\tregularization: 0.0000000\n",
            "\tbatch_size: 64\n",
            "\n",
            "training history:\n",
            "epoch \t\t loss \t\t train_accu \t\t test_accu\n",
            "0 \t\t 2.63045 \t\t 0.45877 \t\t 0.35880\n",
            "1 \t\t 1.54173 \t\t 0.61692 \t\t 0.42786\n",
            "2 \t\t 1.09828 \t\t 0.71829 \t\t 0.44877\n",
            "3 \t\t 0.78750 \t\t 0.80528 \t\t 0.45385\n",
            "4 \t\t 0.55673 \t\t 0.85826 \t\t 0.44942\n",
            "5 \t\t 0.38587 \t\t 0.89673 \t\t 0.44493\n",
            "6 \t\t 0.27420 \t\t 0.92765 \t\t 0.44132\n",
            "7 \t\t 0.19650 \t\t 0.94682 \t\t 0.43679\n",
            "8 \t\t 0.13688 \t\t 0.95949 \t\t 0.43603\n",
            "9 \t\t 0.10071 \t\t 0.96475 \t\t 0.42517\n",
            "###\n",
            "training_model: RNN_average_model.py\n",
            "starting_time: 2017-03-19 02:31:28.713025\n",
            "\n",
            "parameters:\n",
            "\tcell_type: gru\n",
            "\tembed_size: 50\n",
            "\thidden_size: 150\n",
            "\tlearning_rate: 0.0010\n",
            "\tregularization: 0.0000000\n",
            "\tbatch_size: 64\n",
            "\n",
            "training history:\n",
            "epoch \t\t loss \t\t train_accu \t\t test_accu\n",
            "0 \t\t 2.59948 \t\t 0.46264 \t\t 0.36507\n",
            "1 \t\t 1.51047 \t\t 0.61541 \t\t 0.42523\n",
            "2 \t\t 1.07480 \t\t 0.71580 \t\t 0.44243\n",
            "3 \t\t 0.77285 \t\t 0.79793 \t\t 0.44417\n",
            "4 \t\t 0.55095 \t\t 0.85478 \t\t 0.44233\n",
            "5 \t\t 0.39299 \t\t 0.90106 \t\t 0.44161\n",
            "6 \t\t 0.27617 \t\t 0.92732 \t\t 0.43981\n",
            "7 \t\t 0.19611 \t\t 0.94347 \t\t 0.43567\n",
            "8 \t\t 0.13905 \t\t 0.94525 \t\t 0.43249\n",
            "9 \t\t 0.10450 \t\t 0.95674 \t\t 0.42120\n",
            "END\n",
            "\n",
            "###\n",
            "training_model: /usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\n",
            "starting_time: 2018-12-18 15:19:10.106790\n",
            "\n",
            "parameters:\n",
            "\tcell_type: gru\n",
            "\tembed_size: 50\n",
            "\thidden_size: 300\n",
            "\tlearning_rate: 0.0040\n",
            "\tregularization: 0.00001\n",
            "\tdropout: 0.80000\n",
            "\tn_epochs: 30.00000\n",
            "\tbatch_size: 16\n",
            "\n",
            "training history:\n",
            "epoch \t\t loss \t\t train_accu \t\t test_accu\n",
            "0 \t\t 4.00243 \t\t 0.00833 \t\t 0.01754\n",
            "1 \t\t 3.93835 \t\t 0.01667 \t\t 0.03070\n",
            "2 \t\t 3.91902 \t\t 0.02083 \t\t 0.03070\n",
            "3 \t\t 3.89389 \t\t 0.02500 \t\t 0.03070\n",
            "4 \t\t 3.87379 \t\t 0.02500 \t\t 0.02632\n",
            "5 \t\t 3.85378 \t\t 0.05417 \t\t 0.02193\n",
            "6 \t\t 3.84058 \t\t 0.03333 \t\t 0.01754\n",
            "7 \t\t 3.85971 \t\t 0.05417 \t\t 0.01316\n",
            "8 \t\t 3.80204 \t\t 0.04583 \t\t 0.01754\n",
            "9 \t\t 3.81405 \t\t 0.04583 \t\t 0.02193\n",
            "10 \t\t 3.80699 \t\t 0.04167 \t\t 0.02193\n",
            "11 \t\t 4.05223 \t\t 0.02083 \t\t 0.03070\n",
            "12 \t\t 4.31854 \t\t 0.01667 \t\t 0.02632\n",
            "13 \t\t 4.22374 \t\t 0.02500 \t\t 0.02193\n",
            "14 \t\t 4.17811 \t\t 0.02500 \t\t 0.02193\n",
            "15 \t\t 4.21213 \t\t 0.04583 \t\t 0.01754\n",
            "16 \t\t 4.16534 \t\t 0.03333 \t\t 0.01316\n",
            "17 \t\t 4.12002 \t\t 0.03750 \t\t 0.03509\n",
            "18 \t\t 4.25126 \t\t 0.02917 \t\t 0.02193\n",
            "19 \t\t 4.26603 \t\t 0.02083 \t\t 0.01754\n",
            "20 \t\t 4.25278 \t\t 0.03333 \t\t 0.01316\n",
            "21 \t\t 4.16444 \t\t 0.02917 \t\t 0.02632\n",
            "22 \t\t 4.18512 \t\t 0.02500 \t\t 0.01754\n",
            "23 \t\t 4.30362 \t\t 0.02917 \t\t 0.02632\n",
            "24 \t\t 4.36463 \t\t 0.04583 \t\t 0.02193\n",
            "25 \t\t 4.39972 \t\t 0.02083 \t\t 0.02632\n",
            "26 \t\t 4.30825 \t\t 0.02083 \t\t 0.01754\n",
            "27 \t\t 4.37870 \t\t 0.02083 \t\t 0.02632\n",
            "28 \t\t 4.51667 \t\t 0.03750 \t\t 0.01754\n",
            "29 \t\t 4.34430 \t\t 0.03333 \t\t 0.01754\n",
            "END\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LntZgOMGCsuw"
      },
      "source": [
        "SENTENCE LEVEL CASE START FROM HERE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXKaKJzhZ-iA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "03a04ff1-5f66-4348-98a4-5a4fbd6e08a3"
      },
      "source": [
        "# RNN average model                             SENTENCE LEVEL CASE\n",
        "\n",
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "\n",
        "import argparse\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import utils.file2dict as fdt\n",
        "import utils.read_minibatch as rmb\n",
        "import utils.data_util as data_util\n",
        "import utils.confusion_matrix as cm\n",
        "import utils.data_util as du\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from AttributionModel import AttributionModel\n",
        "from proj_rnn_cell import RNNCell\n",
        "from proj_gru_cell import GRUCell\n",
        "\n",
        "logger = logging.getLogger(\"RNN_Author_Attribution\")\n",
        "logger.setLevel(logging.DEBUG)\n",
        "logging.basicConfig(format='%(message)s', level=logging.DEBUG)\n",
        "\n",
        "tf.reset_default_graph()  #used so that variables gets reinitialized every time\n",
        "\n",
        "class Config:\n",
        "    cell_type=\"gru\" # either rnn, gru or lstm\n",
        "\n",
        "    window_size = 0\n",
        "\n",
        "    max_length = 70 # longest length of a sentence we will process\n",
        "    n_classes = 50 # in total, we have 50 classes\n",
        "    dropout = 0.9\n",
        "\n",
        "    embed_size = 50\n",
        "\n",
        "    hidden_size = 300\n",
        "    batch_size = 64\n",
        "\n",
        "    n_epochs = 10\n",
        "    regularization = 0\n",
        "\n",
        "    max_grad_norm = 10.0 # max gradients norm for clipping\n",
        "    lr = 0.004 # learning rate\n",
        "\n",
        "    def __init__(self, args):\n",
        "\n",
        "        #self.cell = args.cell\n",
        "\n",
        "        self.cell = GRUCell(Config.embed_size, Config.hidden_size)\n",
        "        if \"output_path\" in args:\n",
        "            # Where to save things.\n",
        "            self.output_path = args.output_path\n",
        "        else:\n",
        "            self.output_path = \"results/{}/{:%Y%m%d_%H%M%S}/\".format(\"RNN\", datetime.now())\n",
        "\n",
        "        self.model_output = self.output_path + \"model.weights\"\n",
        "        self.eval_output = self.output_path + \"results.txt\"\n",
        "\n",
        "        #self.conll_output = self.output_path + \"{}_predictions.conll\".format(self.cell)\n",
        "        self.log_output = self.output_path + \"log\"\n",
        "\n",
        "class RNNModel(AttributionModel):\n",
        "    \n",
        "    def add_placeholders(self):\n",
        "        self.input_placeholder = tf.placeholder(tf.int32, [None, Config.max_length])\n",
        "        self.labels_placeholder = tf.placeholder(tf.int32, [None, Config.n_classes])\n",
        "        self.mask_placeholder = tf.placeholder(tf.float32, [None, Config.max_length])\n",
        "        self.dropout_placeholder = tf.placeholder(tf.float32)\n",
        "\n",
        "    def create_feed_dict(self, inputs_batch, mask_batch, labels_batch=None, dropout=1):\n",
        "\n",
        "        feed_dict = {}\n",
        "        if labels_batch is not None:\n",
        "            feed_dict[self.labels_placeholder] = labels_batch\n",
        "        if inputs_batch is not None:\n",
        "            feed_dict[self.input_placeholder] = inputs_batch\n",
        "        if dropout is not None:\n",
        "            feed_dict[self.dropout_placeholder] = dropout\n",
        "        if mask_batch is not None:\n",
        "            feed_dict[self.mask_placeholder] = mask_batch\n",
        "        return feed_dict\n",
        "\n",
        "    def add_embedding(self):     \n",
        "        embeddingTensor = tf.Variable(self.pretrained_embeddings,tf.float32)\n",
        "        embeddings = tf.nn.embedding_lookup(embeddingTensor, self.input_placeholder)\n",
        "        return embeddings\n",
        "\n",
        "    def add_prediction_op(self):\n",
        "      \n",
        "        x = self.add_embedding()\n",
        "\n",
        "        dropout_rate = self.dropout_placeholder\n",
        "        preds = [] # Predicted output at each timestep should go here!\n",
        "\n",
        "        if Config.cell_type==\"rnn\":\n",
        "            cell = RNNCell(Config.embed_size, Config.hidden_size)\n",
        "        elif Config.cell_type==\"gru\":\n",
        "            cell = GRUCell(Config.embed_size, Config.hidden_size)\n",
        "        else:\n",
        "            assert False, \"Cell type undefined\"\n",
        "\n",
        "        self.U = tf.get_variable('U',\n",
        "                              [Config.hidden_size, Config.n_classes],\n",
        "                              initializer = tf.contrib.layers.xavier_initializer())\n",
        "        self.b2 = tf.get_variable('b2',\n",
        "                              [Config.n_classes, ],\n",
        "                              initializer = tf.contrib.layers.xavier_initializer())\n",
        "        h = tf.zeros([tf.shape(x)[0], Config.hidden_size])\n",
        "\n",
        "        with tf.variable_scope(\"RNN\"):\n",
        "\n",
        "            for time_step in range(Config.max_length):\n",
        "                if time_step >= 1:\n",
        "                    tf.get_variable_scope().reuse_variables()\n",
        "                o, h = cell(x[:,time_step,:], h)\n",
        "\n",
        "                o_drop = tf.nn.dropout(o, dropout_rate)\n",
        "                preds.append(tf.matmul(o_drop, self.U) + self.b2)\n",
        "\n",
        "        self.raw_preds=tf.stack(preds)\n",
        "        preds=tf.reshape(tf.transpose(self.raw_preds, [1, 0, 2]),[-1,Config.max_length,Config.n_classes])\n",
        "        return preds\n",
        "\n",
        "    def add_loss_op(self, preds):\n",
        "\n",
        "        pred_mask=tf.reshape(self.mask_placeholder,[-1,Config.max_length,1])\n",
        "        pred_mask=tf.tile(pred_mask,[1,1,Config.n_classes])\n",
        "        pred_masked= preds * pred_mask\n",
        "        pred_masked=tf.reduce_sum(pred_masked,axis=1)\n",
        "        loss = tf.nn.softmax_cross_entropy_with_logits(logits=pred_masked, labels=self.labels_placeholder)\n",
        "\n",
        "        loss = tf.reduce_mean(loss) + config.regularization * ( tf.nn.l2_loss(self.U) )\n",
        "        with tf.variable_scope(\"RNN/cell\", reuse= True):\n",
        "            # add regularization\n",
        "\n",
        "            loss += config.regularization * (tf.nn.l2_loss(tf.get_variable(\"W_r\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"U_r\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"W_z\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"U_z\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"W_o\"))\n",
        "                                             + tf.nn.l2_loss(tf.get_variable(\"U_o\")))\n",
        "        return loss\n",
        "\n",
        "    def add_training_op(self, loss):        \n",
        "        train_op = tf.train.AdamOptimizer(Config.lr).minimize(loss)\n",
        "        return train_op\n",
        "\n",
        "    def train_on_batch(self, sess, inputs_batch, labels_batch, mask_batch):\n",
        "\n",
        "        feed = self.create_feed_dict(inputs_batch, labels_batch=labels_batch, mask_batch=mask_batch,\n",
        "                                     dropout=Config.dropout)\n",
        "        _, loss, pred = sess.run([self.train_op, self.loss, self.pred], feed_dict=feed)\n",
        "        return loss\n",
        "\n",
        "    def predict_on_batch(self, sess, inputs_batch, mask_batch):\n",
        "    \n",
        "        feed = self.create_feed_dict(inputs_batch,mask_batch)\n",
        "        predictions = sess.run(self.pred, feed_dict=feed)\n",
        "        pred_mask=sess.run(self.mask_placeholder,feed_dict=feed)\n",
        "        pred_mask=np.reshape(pred_mask,(-1,Config.max_length,1))\n",
        "        pred_mask=np.tile(pred_mask,(1,1,Config.n_classes))\n",
        "        pred_masked=predictions*pred_mask\n",
        "        pred_masked=np.sum(pred_masked,axis=1)\n",
        "        return pred_masked\n",
        "\n",
        "    def record_history_init(self,f):\n",
        "        f.write(\"###\\n\")\n",
        "        f.write(\"training_model: \"+sys.argv[0]+\"\\n\")\n",
        "        f.write(\"starting_time: \"+str(datetime.now())+\"\\n\")\n",
        "        f.write(\"\\n\")\n",
        "        f.write(\"parameters:\\n\")\n",
        "        f.write(\"\\tcell_type: \"+Config.cell_type+\"\\n\")\n",
        "        f.write(\"\\tembed_size: {}\\n\".format(Config.embed_size))\n",
        "        f.write(\"\\thidden_size: {}\\n\".format(Config.hidden_size))\n",
        "        f.write(\"\\tlearning_rate: {0:.4f}\\n\".format(Config.lr))\n",
        "        f.write(\"\\tregularization: {0:.7f}\\n\".format(Config.regularization))\n",
        "        f.write(\"\\tdropout: {0:.5f}\\n\".format(Config.dropout))\n",
        "        f.write(\"\\tn_epochs: {0:.5f}\\n\".format(Config.n_epochs))\n",
        "        f.write(\"\\tbatch_size: {}\\n\".format(Config.batch_size))\n",
        "        f.write(\"\\n\")\n",
        "        f.write(\"training history:\\n\")\n",
        "        f.write(\"epoch \\t\\t loss \\t\\t train_accu \\t\\t test_accu\\n\")\n",
        "\n",
        "    def record_history_accu(self,f,n_epoch,average_train_loss,train_accu,test_accu):\n",
        "        f.write(\"{0:d} \\t\\t {1:.5f} \\t\\t {2:.5f} \\t\\t {3:.5f}\\n\".format(n_epoch,average_train_loss,train_accu,test_accu))\n",
        "\n",
        "    def record_history_finish(self,f):\n",
        "        f.write(\"END\\n\")\n",
        "        f.write(\"\\n\")\n",
        "        f.close()\n",
        "\n",
        "    def test_model(self, session, batch_list):\n",
        "        print \"Now, testing on the test set...\"\n",
        "        total = 0\n",
        "        accuCount = 0\n",
        "        for batch in batch_list:\n",
        "            batch_feat = np.array(batch[0], dtype = np.int32)\n",
        "            batch_mask = np.array(batch[1], dtype = np.float32)\n",
        "            pred = self.predict_on_batch(session, batch_feat, batch_mask)\n",
        "            accuCount += np.sum(np.argmax(pred,1) == batch[2])\n",
        "            total += len(batch[2])\n",
        "        accu = accuCount * 1.0 / total\n",
        "        logger.info( (\"Test accuracy %f\" %(accu)) )\n",
        "        return accu\n",
        "\n",
        "    def test_trainset_model(self, session, batch_list):\n",
        "        print \"Now, testing on the training set, notice this is only for debugging...\"\n",
        "        total = 0\n",
        "        accuCount = 0\n",
        "        for batch in batch_list:\n",
        "            batch_feat = np.array(batch[0], dtype = np.int32)\n",
        "            batch_mask = np.array(batch[1], dtype = np.float32)\n",
        "            pred = self.predict_on_batch(session, batch_feat, batch_mask)\n",
        "            accuCount += np.sum(np.argmax(pred,1) == batch[2])\n",
        "            total += len(batch[2])\n",
        "        accu = accuCount * 1.0 / total\n",
        "        logger.info( (\"Test accuracy on training set is: %f\" %(accu)) )\n",
        "        return accu     \n",
        "      \n",
        "    def process_model_output(self):\n",
        "        pkl_file = open('/content/auth_id/data_article_test.pkl', 'rb')\n",
        "        batch_list = pickle.load(pkl_file)\n",
        "        pkl_file.close()\n",
        "\n",
        "        test_size = int(len(batch_list) /1)   \n",
        "        training_batch = batch_list[0 : len(batch_list) - test_size]\n",
        "        print test_size, len(batch_list)\n",
        "        testing_batch = batch_list[len(batch_list) - test_size : len(batch_list)]\n",
        "\n",
        "        init = tf.global_variables_initializer()   #added initialization\n",
        "        saver = tf.train.Saver()\n",
        "        with tf.Session() as session:\n",
        "            session.run(init)\n",
        "            #load_path = \"./model_weights_article\"\n",
        "            saver.restore(session, \"./model_weights_article\")\n",
        "\n",
        "            print \"Now, collecting the model outputs...\"\n",
        "            total = 0\n",
        "            accuCount = 0\n",
        "\n",
        "            for batch in testing_batch:\n",
        "                batch_feat = np.array(batch[1], dtype = np.int32)\n",
        "                batch_mask = np.array(batch[2], dtype = np.float32)\n",
        "\n",
        "                preds = self.predict_on_batch(session, batch_feat, batch_mask)\n",
        "                #print len(preds)\n",
        "                author_find = data_util.find_author(preds)\n",
        "                if author_find == batch[0]:\n",
        "                    accuCount += 1\n",
        "                total += 1\n",
        "            accuracy = accuCount / total\n",
        "            print( (\"Test accuracy %f\" %(accuracy)) )\n",
        "            return accuracy\n",
        "\n",
        "    def process_model_confusion_matrix(self):\n",
        "        pkl_file = open('/content/auth_id/data_test_bundle_seq.pkl', 'rb')\n",
        "        batch_list = pickle.load(pkl_file)\n",
        "        pkl_file.close()\n",
        "\n",
        "        test_size = int(len(batch_list) / 1)\n",
        "        training_batch = batch_list[0 : len(batch_list) - test_size]\n",
        "        print test_size, len(batch_list)\n",
        "        testing_batch = batch_list[len(batch_list) - test_size : len(batch_list)]\n",
        "\n",
        "        init = tf.global_variables_initializer()   #added initialization\n",
        "        saver = tf.train.Saver()\n",
        "        with tf.Session() as session:\n",
        "            session.run(init)\n",
        "            #load_path = \"./model_weights_article\"\n",
        "            saver.restore(session, \"./model_weights_article\")\n",
        "            \n",
        "            print \"Now, collecting the model outputs...\"\n",
        "            pred_list = []\n",
        "            real_label_list = []\n",
        "            total = 0\n",
        "            accuCount = 0\n",
        "            for batch in testing_batch:\n",
        "                batch_feat = np.array(batch[0], dtype = np.int32)\n",
        "                batch_mask = np.array(batch[1], dtype = np.float32)\n",
        "\n",
        "                pred = self.predict_on_batch(session, batch_feat, batch_mask)\n",
        "                accuCount += np.sum(np.argmax(pred,1) == batch[2])\n",
        "                pred_list.extend(np.argmax(pred,1).tolist())\n",
        "                real_label_list.extend(batch[2])                  #changed from batch[0] to batch[2]\n",
        "                total += len(batch[2])\n",
        "\n",
        "            accu = accuCount * 1.0 / total\n",
        "            print( (\"Test accuracy %f\" %(accu)) )\n",
        "            t_cm = cm.generate_cm(real_label_list,pred_list, 50)\n",
        "            x = t_cm.as_matrix().astype(np.uint8)\n",
        "            du.visualize_cm(x, \"C50_word\")\n",
        "            return accu\n",
        "\n",
        "    def train_model(self):\n",
        "        level='word' # 'word' or ''\n",
        "        dataset='c50'\n",
        "        parameter='hs'\n",
        "        date='0319'\n",
        "        training_history_txt_filename='/content/auth_id/results/training_history'+level+'_'+parameter+'_'+dataset+'_'+date  +'.txt'\n",
        "        # write training_history\n",
        "        training_history_file = open(training_history_txt_filename,'a+')\n",
        "        self.record_history_init(training_history_file)\n",
        "\n",
        "        if not os.path.exists(config.log_output):\n",
        "            os.makedirs(os.path.dirname(config.log_output))\n",
        "        handler = logging.FileHandler(config.log_output)\n",
        "        handler.setLevel(logging.DEBUG)\n",
        "        handler.setFormatter(logging.Formatter('%(message)s'))\n",
        "        logging.getLogger().addHandler(handler)\n",
        "        '''\n",
        "        pkl_file = open('../data/batch_data/C50/data_bundle_seq.pkl', 'rb')\n",
        "        batch_list = pickle.load(pkl_file)\n",
        "        pkl_file.close()\n",
        "        test_size = int(len(batch_list) / 10)\n",
        "        training_batch = batch_list[0 : len(batch_list) - test_size]\n",
        "        print test_size\n",
        "        testing_train_batch = batch_list[test_size : 2 * test_size]\n",
        "        testing_batch = batch_list[len(batch_list) - test_size : len(batch_list)]\n",
        "        '''\n",
        "\n",
        "        train_file = open('/content/auth_id/data_train_bundle_seq.pkl', 'rb')\n",
        "        training_batch = pickle.load(train_file)\n",
        "        train_file.close()\n",
        "\n",
        "\n",
        "        test_file = open('/content/auth_id/data_test_bundle_seq.pkl', 'rb')\n",
        "        testing_batch = pickle.load(test_file)\n",
        "        test_file.close()\n",
        "\n",
        "        testing_train_batch = training_batch[0 : int(len(training_batch) / 2)]\n",
        "\n",
        "        init = tf.global_variables_initializer()\n",
        "        saver = tf.train.Saver()\n",
        "        with tf.Session() as session:\n",
        "            session.run(init)\n",
        "            #load_path = \"results/RNN/20170310_1022/model.weights_20\"\n",
        "            #saver.restore(session, load_path)\n",
        "\n",
        "            #the following is a test for what in tensor\n",
        "            batch = training_batch[0]\n",
        "            batch_label = rmb.convertOnehotLabel(batch[2],  Config.n_classes)\n",
        "            batch_feat = np.array(batch[0], dtype = np.int32)\n",
        "            batch_mask = np.array(batch[1], dtype = np.float32)\n",
        "            feed = self.create_feed_dict(batch_feat, labels_batch=batch_label, mask_batch=batch_mask,\n",
        "                                     dropout=Config.dropout)\n",
        "            _, loss, raw_pred, pred = session.run([self.train_op, self.loss, self.raw_preds, self.pred], feed_dict=feed)\n",
        "            ##############\n",
        "\n",
        "            for iterTime in range(Config.n_epochs):\n",
        "                loss_list = []\n",
        "                smallIter = 0\n",
        "\n",
        "                for batch in training_batch:\n",
        "                    batch_label = rmb.convertOnehotLabel(batch[2],  Config.n_classes)\n",
        "                    batch_feat = np.array(batch[0], dtype = np.int32)\n",
        "                    batch_mask = np.array(batch[1], dtype = np.float32)\n",
        "                    loss = self.train_on_batch(session, batch_feat, batch_label, batch_mask)\n",
        "                    loss_list.append(loss)\n",
        "                    smallIter += 1\n",
        "\n",
        "                    if(smallIter % 40 == 0):\n",
        "                        #self.test_trainset_model(session, testing_train_batch)\n",
        "                        #self.test_model(session, testing_batch)\n",
        "                        logger.info((\"Intermediate epoch %d Total Iteration %d: loss : %f\" %(iterTime, smallIter, np.mean(np.mean(np.array(loss)))) ))\n",
        "                # record training history on this epoch\n",
        "                train_accu=self.test_trainset_model(session, testing_train_batch)\n",
        "                test_accu=self.test_model(session, testing_batch)\n",
        "                average_train_loss=np.mean(np.array(loss_list))\n",
        "                self.record_history_accu(training_history_file,iterTime,average_train_loss,train_accu,test_accu)\n",
        "\n",
        "                if(iterTime % 20 == 0):\n",
        "                    logger.info((\"epoch %d : loss : %f\" %(iterTime, np.mean(np.mean(np.array(loss)))) ))\n",
        "                    saver.save(session,\"./model_weights_article\")\n",
        "\n",
        "                    #if(smallIter % 200 == 0):\n",
        "                    print (\"Intermediate epoch %d : loss : %f\" %(iterTime, np.mean(np.mean(np.array(loss)))) )\n",
        "\n",
        "            print (\"epoch %d : loss : %f\" %(iterTime, np.mean(np.mean(np.array(loss)))) )\n",
        "            self.record_history_finish(training_history_file)\n",
        "\n",
        "           \n",
        "    def __init__(self, config, pretrained_embeddings, report=None):\n",
        "        super(RNNModel, self).__init__(config)\n",
        "        self.pretrained_embeddings = pretrained_embeddings\n",
        "        self.input_placeholder = None\n",
        "        self.labels_placeholder = None\n",
        "        self.mask_placeholder = None\n",
        "        self.dropout_placeholder = None\n",
        "        self.raw_preds = None\n",
        "        self.build()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = \"gru\"\n",
        "    config = Config(args)\n",
        "    glove_path = \"/content/glove.6B.50d.txt\"\n",
        "    glove_vector = data_util.load_embeddings(glove_path, config.embed_size)\n",
        "    model = RNNModel(config, glove_vector.astype(np.float32))\n",
        "    model.train_model()\n",
        "    model.process_model_output()\n",
        "    #model.process_model_confusion_matrix()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:Intermediate epoch 0 Total Iteration 40: loss : 3.046538\n",
            "INFO:Intermediate epoch 0 Total Iteration 80: loss : 2.358649\n",
            "INFO:Intermediate epoch 0 Total Iteration 120: loss : 1.639385\n",
            "INFO:Intermediate epoch 0 Total Iteration 160: loss : 1.715694\n",
            "INFO:Intermediate epoch 0 Total Iteration 200: loss : 1.421646\n",
            "INFO:Intermediate epoch 0 Total Iteration 240: loss : 1.322795\n",
            "INFO:Intermediate epoch 0 Total Iteration 280: loss : 1.299574\n",
            "INFO:Intermediate epoch 0 Total Iteration 320: loss : 1.480430\n",
            "INFO:Intermediate epoch 0 Total Iteration 360: loss : 1.310145\n",
            "INFO:Intermediate epoch 0 Total Iteration 400: loss : 1.244930\n",
            "INFO:Intermediate epoch 0 Total Iteration 440: loss : 0.934993\n",
            "INFO:Intermediate epoch 0 Total Iteration 480: loss : 1.052158\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the training set, notice this is only for debugging...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy on training set is: 0.736904\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, testing on the test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Test accuracy 0.465215\n",
            "INFO:epoch 0 : loss : 1.296263\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Intermediate epoch 0 : loss : 1.296263\n",
            "epoch 0 : loss : 1.296263\n",
            "2500 2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:Restoring parameters from ./model_weights_article\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Now, collecting the model outputs...\n",
            "Test accuracy 0.602800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FFFmXr9fKXm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "d763e43a-b039-4b6c-e3af-45f5e32e3221"
      },
      "source": [
        "%cd /content/auth_id/results/\n",
        "!cat training_historyword_hs_c50_0319.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/auth_id/results\n",
            "\n",
            "###\n",
            "training_model: /usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\n",
            "starting_time: 2018-11-04 08:17:14.532747\n",
            "\n",
            "parameters:\n",
            "\tcell_type: gru\n",
            "\tembed_size: 50\n",
            "\thidden_size: 150\n",
            "\tlearning_rate: 0.0040\n",
            "\tregularization: 0.0000000\n",
            "\tdropout: 0.90000\n",
            "\tn_epochs: 1.00000\n",
            "\tbatch_size: 64\n",
            "\n",
            "training history:\n",
            "epoch \t\t loss \t\t train_accu \t\t test_accu\n",
            "0 \t\t 1.81801 \t\t 0.70987 \t\t 0.46440\n",
            "END\n",
            "\n",
            "###\n",
            "training_model: /usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\n",
            "starting_time: 2018-11-04 08:28:24.565365\n",
            "\n",
            "parameters:\n",
            "\tcell_type: gru\n",
            "\tembed_size: 50\n",
            "\thidden_size: 150\n",
            "\tlearning_rate: 0.0040\n",
            "\tregularization: 0.0000000\n",
            "\tdropout: 0.90000\n",
            "\tn_epochs: 1.00000\n",
            "\tbatch_size: 64\n",
            "\n",
            "training history:\n",
            "epoch \t\t loss \t\t train_accu \t\t test_accu\n",
            "0 \t\t 1.81439 \t\t 0.70604 \t\t 0.45712\n",
            "END\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}