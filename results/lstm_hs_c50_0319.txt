###
training_model: RNN_sent_model_embed.py
starting_time: 2017-03-19 19:37:52.546750

parameters:
	cell_type: lstm
	embed_size: 50
	hidden_size: 50
	learning_rate: 0.0010
	regularization: 0.00000
	batch_size: 16

training history:
epoch 		 loss 		 train_accu 		 test_accu
0 		 3.83091 		 0.15833 		 0.08772
1 		 3.12171 		 0.26667 		 0.19298
2 		 2.45397 		 0.44167 		 0.26754
3 		 2.05589 		 0.49583 		 0.28947
4 		 1.76922 		 0.57917 		 0.36404
5 		 1.53718 		 0.57917 		 0.39035
6 		 1.36439 		 0.60417 		 0.38596
7 		 1.22070 		 0.65000 		 0.44737
8 		 1.07055 		 0.72083 		 0.50000
9 		 0.94631 		 0.75833 		 0.53070
10 		 0.90267 		 0.78750 		 0.55263
11 		 0.76733 		 0.79583 		 0.50877
12 		 0.68129 		 0.83750 		 0.54386
13 		 0.60993 		 0.82917 		 0.56140
14 		 0.53399 		 0.85417 		 0.58333
15 		 0.47378 		 0.81250 		 0.56140
16 		 0.43659 		 0.89167 		 0.57895
17 		 0.37039 		 0.91667 		 0.59649
18 		 0.34059 		 0.90833 		 0.61404
19 		 0.29141 		 0.91250 		 0.60088
20 		 0.27011 		 0.92500 		 0.63596
21 		 0.27590 		 0.93333 		 0.59211
22 		 0.26007 		 0.94583 		 0.62719
23 		 0.19647 		 0.95417 		 0.59649
24 		 0.16397 		 0.95417 		 0.60965
END

###
training_model: RNN_sent_model_embed.py
starting_time: 2017-03-19 19:53:40.002695

parameters:
	cell_type: lstm
	embed_size: 50
	hidden_size: 100
	learning_rate: 0.0010
	regularization: 0.00000
	batch_size: 16

training history:
epoch 		 loss 		 train_accu 		 test_accu
0 		 3.61079 		 0.19167 		 0.12719
1 		 2.63636 		 0.39167 		 0.27632
2 		 2.04596 		 0.45000 		 0.33333
3 		 1.72493 		 0.51667 		 0.35965
4 		 1.51654 		 0.57917 		 0.44298
5 		 1.29395 		 0.57500 		 0.44737
6 		 1.09339 		 0.60417 		 0.49123
7 		 0.93107 		 0.70833 		 0.48246
8 		 0.80081 		 0.78333 		 0.55263
9 		 0.70344 		 0.72500 		 0.53947
10 		 0.65137 		 0.80000 		 0.51754
11 		 0.55701 		 0.85833 		 0.56579
12 		 0.46964 		 0.89167 		 0.55702
13 		 0.41479 		 0.90000 		 0.54386
14 		 0.35921 		 0.89583 		 0.55702
15 		 0.29909 		 0.90833 		 0.56140
16 		 0.28384 		 0.94167 		 0.60088
17 		 0.23139 		 0.93333 		 0.60965
18 		 0.20118 		 0.95000 		 0.58772
19 		 0.29132 		 0.89167 		 0.52193
20 		 0.24612 		 0.95000 		 0.60088
21 		 0.15946 		 0.95833 		 0.60965
22 		 0.15329 		 0.95833 		 0.61842
23 		 0.12177 		 0.94583 		 0.58333
24 		 0.11601 		 0.97500 		 0.60526
END

###
training_model: RNN_sent_model_embed.py
starting_time: 2017-03-19 21:19:07.973477

parameters:
	cell_type: lstm
	embed_size: 50
	hidden_size: 150
	learning_rate: 0.0010
	regularization: 0.00000
	batch_size: 16

training history:
epoch 		 loss 		 train_accu 		 test_accu
0 		 3.54064 		 0.20417 		 0.14035
1 		 2.50944 		 0.35833 		 0.25877
2 		 1.90679 		 0.50000 		 0.39474
3 		 1.58492 		 0.55833 		 0.43860
4 		 1.34774 		 0.57917 		 0.42544
5 		 1.18065 		 0.62500 		 0.47807
6 		 1.00551 		 0.70833 		 0.50000
7 		 0.81797 		 0.77083 		 0.50877
8 		 0.75941 		 0.76250 		 0.53509
9 		 0.66020 		 0.81250 		 0.56579
10 		 0.53358 		 0.85417 		 0.52193
11 		 0.45034 		 0.88333 		 0.56140
12 		 0.43623 		 0.84167 		 0.53070
13 		 0.37194 		 0.90000 		 0.54386
14 		 0.34588 		 0.82917 		 0.48246
15 		 0.29931 		 0.90417 		 0.57018
16 		 0.24183 		 0.94583 		 0.54386
17 		 0.19246 		 0.91250 		 0.56140
18 		 0.17041 		 0.96667 		 0.57456
19 		 0.14834 		 0.93333 		 0.57456
20 		 0.16087 		 0.95833 		 0.59211
21 		 0.18330 		 0.85833 		 0.53947
22 		 0.25780 		 0.91667 		 0.53947
23 		 0.15193 		 0.97083 		 0.57456
24 		 0.16487 		 0.99167 		 0.58333
END

###
training_model: RNN_sent_model_embed.py
starting_time: 2017-03-19 22:11:15.257127

parameters:
	cell_type: lstm
	embed_size: 50
	hidden_size: 300
	learning_rate: 0.0010
	regularization: 0.00000
	batch_size: 16

training history:
epoch 		 loss 		 train_accu 		 test_accu
0 		 3.33209 		 0.21250 		 0.14912
1 		 2.39743 		 0.37500 		 0.25877
2 		 1.91128 		 0.45000 		 0.32895
3 		 1.64285 		 0.52500 		 0.37281
4 		 1.40324 		 0.56667 		 0.42105
5 		 1.20141 		 0.64167 		 0.44737
6 		 1.07879 		 0.70000 		 0.53509
7 		 0.89576 		 0.73333 		 0.50000
8 		 0.74051 		 0.80417 		 0.58772
9 		 0.66858 		 0.79583 		 0.55263
10 		 0.52775 		 0.86250 		 0.54825
11 		 0.46810 		 0.80833 		 0.54386
12 		 0.47741 		 0.85000 		 0.56140
13 		 0.35080 		 0.86667 		 0.56140
14 		 0.25601 		 0.94583 		 0.58772
15 		 0.18686 		 0.95000 		 0.57895
16 		 0.18950 		 0.91250 		 0.53509
17 		 0.18898 		 0.95417 		 0.58772
18 		 0.20130 		 0.94583 		 0.61404
19 		 0.13390 		 0.95833 		 0.59649
20 		 0.10812 		 0.96250 		 0.59211
21 		 0.09114 		 0.94583 		 0.56579
22 		 0.12296 		 0.92917 		 0.53509
23 		 0.26033 		 0.98333 		 0.59211
24 		 0.13088 		 0.97500 		 0.58772
END

