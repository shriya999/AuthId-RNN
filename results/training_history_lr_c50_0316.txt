###
training_model: RNN_sent_model_embed.py
starting_time: 2017-03-17 05:14:49.614350

parameters:
	cell_type: gru
	embed_size: 50
	hidden_size: 100
	learning_rate: 0.0005
	regularization: 0.00000
	batch_size: 16

training history:
epoch 		 loss 		 train_accu 		 test_accu
0 		 3.88058 		 0.12917 		 0.05263
1 		 3.40913 		 0.16667 		 0.11404
2 		 2.78715 		 0.27500 		 0.17544
3 		 2.32826 		 0.37917 		 0.26754
4 		 2.01251 		 0.44583 		 0.28070
5 		 1.79369 		 0.53333 		 0.32895
6 		 1.60527 		 0.59167 		 0.38596
7 		 1.44484 		 0.62500 		 0.41228
8 		 1.31952 		 0.65833 		 0.40351
9 		 1.19613 		 0.69583 		 0.43860
10 		 1.09304 		 0.68750 		 0.47368
11 		 0.97324 		 0.70417 		 0.48684
12 		 0.87579 		 0.72083 		 0.45614
13 		 0.79101 		 0.80833 		 0.49123
14 		 0.71517 		 0.79167 		 0.53070
15 		 0.62763 		 0.80417 		 0.54386
16 		 0.58716 		 0.82917 		 0.52632
17 		 0.52851 		 0.82500 		 0.53070
18 		 0.48696 		 0.82917 		 0.57456
19 		 0.42317 		 0.82500 		 0.55263
20 		 0.39121 		 0.86667 		 0.56579
21 		 0.36029 		 0.87083 		 0.55702
22 		 0.31191 		 0.95417 		 0.57456
23 		 0.27397 		 0.95417 		 0.54386
24 		 0.22587 		 0.95833 		 0.55263
25 		 0.23248 		 0.93750 		 0.56140
26 		 0.20982 		 0.97500 		 0.58772
27 		 0.17373 		 0.95000 		 0.57018
28 		 0.14304 		 0.99167 		 0.58333
29 		 0.21515 		 0.97917 		 0.57018
30 		 0.14694 		 0.98333 		 0.58333
31 		 0.11902 		 1.00000 		 0.58333
32 		 0.09839 		 0.97917 		 0.59649
33 		 0.08745 		 0.99583 		 0.58772
34 		 0.07635 		 0.99583 		 0.61404
35 		 0.17777 		 0.96667 		 0.60526
36 		 0.10774 		 0.97917 		 0.58333
37 		 0.06458 		 1.00000 		 0.60088
38 		 0.04606 		 1.00000 		 0.60088
39 		 0.04235 		 0.99583 		 0.61404
END

###
training_model: RNN_sent_model_embed.py
starting_time: 2017-03-17 05:39:50.624501

parameters:
	cell_type: gru
	embed_size: 50
	hidden_size: 100
	learning_rate: 0.0010
	regularization: 0.00000
	batch_size: 16

training history:
epoch 		 loss 		 train_accu 		 test_accu
0 		 3.67853 		 0.11667 		 0.09211
1 		 2.86862 		 0.26250 		 0.18860
2 		 2.21912 		 0.41250 		 0.31140
3 		 1.74540 		 0.53750 		 0.38596
4 		 1.40822 		 0.65000 		 0.38158
5 		 1.19326 		 0.56250 		 0.36842
6 		 1.04841 		 0.72500 		 0.47368
7 		 0.84011 		 0.76250 		 0.51754
8 		 0.67271 		 0.80000 		 0.53509
9 		 0.55947 		 0.81667 		 0.55263
10 		 0.47648 		 0.85833 		 0.58333
11 		 0.39655 		 0.88333 		 0.57895
12 		 0.35020 		 0.88333 		 0.57456
13 		 0.35170 		 0.85000 		 0.55263
14 		 0.24181 		 0.92917 		 0.58333
15 		 0.19169 		 0.95833 		 0.60965
16 		 0.16998 		 0.97917 		 0.60965
17 		 0.12863 		 0.98333 		 0.61842
18 		 0.12254 		 0.98750 		 0.61842
19 		 0.08536 		 0.99167 		 0.61842
20 		 0.06954 		 0.99583 		 0.61404
21 		 0.08915 		 0.99583 		 0.61404
22 		 0.07789 		 0.98333 		 0.58333
23 		 0.09985 		 0.99583 		 0.59649
24 		 0.08070 		 0.97500 		 0.60965
25 		 0.13413 		 0.98750 		 0.61842
26 		 0.08074 		 0.99167 		 0.62281
27 		 0.04729 		 0.99583 		 0.61842
28 		 0.02797 		 1.00000 		 0.62281
29 		 0.02109 		 1.00000 		 0.64474
30 		 0.03226 		 0.99583 		 0.62719
31 		 0.02921 		 0.98750 		 0.61404
32 		 0.02778 		 0.99583 		 0.60965
33 		 0.01349 		 1.00000 		 0.61842
34 		 0.00951 		 1.00000 		 0.62281
35 		 0.00763 		 1.00000 		 0.61842
36 		 0.00680 		 1.00000 		 0.61404
37 		 0.00626 		 1.00000 		 0.61404
38 		 0.00575 		 1.00000 		 0.61404
39 		 0.00540 		 1.00000 		 0.61404
END

###
training_model: RNN_sent_model_embed.py
starting_time: 2017-03-17 05:55:34.352058

parameters:
	cell_type: gru
	embed_size: 50
	hidden_size: 100
	learning_rate: 0.0020
	regularization: 0.00000
	batch_size: 16

training history:
epoch 		 loss 		 train_accu 		 test_accu
0 		 3.40502 		 0.27500 		 0.13596
1 		 2.21418 		 0.50417 		 0.33772
2 		 1.51123 		 0.65000 		 0.41667
3 		 1.08375 		 0.68750 		 0.52632
4 		 0.77991 		 0.77500 		 0.51316
5 		 0.57236 		 0.91250 		 0.62719
6 		 0.39895 		 0.92917 		 0.59649
7 		 0.31944 		 0.95417 		 0.58333
8 		 0.24957 		 0.97917 		 0.60526
9 		 0.20816 		 0.95833 		 0.64474
10 		 0.14586 		 0.95833 		 0.64035
11 		 0.09866 		 0.94583 		 0.64035
12 		 0.09766 		 0.97083 		 0.62281
13 		 0.07318 		 0.97500 		 0.63158
14 		 0.05895 		 0.97917 		 0.64035
15 		 0.04058 		 1.00000 		 0.63596
16 		 0.03157 		 1.00000 		 0.65351
17 		 0.08032 		 0.97917 		 0.58333
18 		 0.06916 		 0.99167 		 0.61404
19 		 0.05071 		 1.00000 		 0.62719
20 		 0.01971 		 1.00000 		 0.64474
21 		 0.01011 		 1.00000 		 0.64474
22 		 0.00587 		 1.00000 		 0.64474
23 		 0.00584 		 1.00000 		 0.64912
24 		 0.00496 		 1.00000 		 0.64912
25 		 0.00425 		 1.00000 		 0.64912
26 		 0.00342 		 1.00000 		 0.65351
27 		 0.00284 		 1.00000 		 0.64474
28 		 0.00247 		 1.00000 		 0.64912
29 		 0.00202 		 1.00000 		 0.64912
30 		 0.00164 		 1.00000 		 0.64912
31 		 0.00144 		 1.00000 		 0.64912
32 		 0.00132 		 1.00000 		 0.64912
33 		 0.00121 		 1.00000 		 0.64474
34 		 0.00110 		 1.00000 		 0.64912
35 		 0.00097 		 1.00000 		 0.64474
36 		 0.00089 		 1.00000 		 0.64474
37 		 0.00082 		 1.00000 		 0.64912
38 		 0.00076 		 1.00000 		 0.64912
39 		 0.00069 		 1.00000 		 0.64912
END

###
training_model: RNN_sent_model_embed.py
starting_time: 2017-03-17 06:13:07.661546

parameters:
	cell_type: gru
	embed_size: 50
	hidden_size: 100
	learning_rate: 0.0040
	regularization: 0.00000
	batch_size: 16

training history:
epoch 		 loss 		 train_accu 		 test_accu
0 		 3.10334 		 0.34167 		 0.24561
1 		 1.65015 		 0.67917 		 0.49561
2 		 0.98307 		 0.80417 		 0.62719
3 		 0.57285 		 0.87083 		 0.63596
4 		 0.34334 		 0.92917 		 0.67982
5 		 0.20989 		 0.96250 		 0.71930
6 		 0.11840 		 1.00000 		 0.69737
7 		 0.06070 		 0.97500 		 0.67105
8 		 0.04331 		 0.99167 		 0.71053
9 		 0.01393 		 1.00000 		 0.68860
10 		 0.00842 		 1.00000 		 0.68421
11 		 0.00587 		 1.00000 		 0.68860
12 		 0.00512 		 1.00000 		 0.67105
13 		 0.00410 		 1.00000 		 0.67982
14 		 0.00347 		 1.00000 		 0.68421
15 		 0.00263 		 1.00000 		 0.68421
16 		 0.00165 		 1.00000 		 0.68421
17 		 0.00127 		 1.00000 		 0.68860
18 		 0.00110 		 1.00000 		 0.68860
19 		 0.00097 		 1.00000 		 0.68421
20 		 0.00083 		 1.00000 		 0.68860
21 		 0.00074 		 1.00000 		 0.68860
22 		 0.00065 		 1.00000 		 0.68860
23 		 0.00059 		 1.00000 		 0.68421
24 		 0.00053 		 1.00000 		 0.67982
25 		 0.00047 		 1.00000 		 0.68421
26 		 0.00042 		 1.00000 		 0.68860
27 		 0.00038 		 1.00000 		 0.67982
28 		 0.00035 		 1.00000 		 0.68421
29 		 0.00032 		 1.00000 		 0.68421
30 		 0.00029 		 1.00000 		 0.68421
31 		 0.00027 		 1.00000 		 0.68421
32 		 0.00024 		 1.00000 		 0.68421
33 		 0.00022 		 1.00000 		 0.69298
34 		 0.00020 		 1.00000 		 0.69298
35 		 0.00018 		 1.00000 		 0.68860
36 		 0.00017 		 1.00000 		 0.68860
37 		 0.00016 		 1.00000 		 0.68860
38 		 0.00014 		 1.00000 		 0.68860
39 		 0.00013 		 1.00000 		 0.68860
END

