

###
training_model: RNN_sent_model_embed.py
starting_time: 2017-03-19 05:11:05.361807

parameters:
	cell_type: lstm
	embed_size: 50
	hidden_size: 50
	learning_rate: 0.0010
	regularization: 0.00000
	batch_size: 16

training history:
epoch 		 loss 		 train_accu 		 test_accu
0 		 3.77806 		 0.08750 		 0.10526
1 		 3.06089 		 0.31250 		 0.17105
2 		 2.42035 		 0.47500 		 0.28509
3 		 1.97207 		 0.55000 		 0.35088
4 		 1.63417 		 0.65000 		 0.42544
5 		 1.45358 		 0.71250 		 0.45614
6 		 1.22456 		 0.72500 		 0.47368
7 		 1.05806 		 0.73750 		 0.50000
8 		 0.90662 		 0.80000 		 0.51754
9 		 0.79169 		 0.79167 		 0.53070
10 		 0.71768 		 0.86250 		 0.57018
11 		 0.61641 		 0.81250 		 0.52193
12 		 0.56057 		 0.87500 		 0.56140
13 		 0.47668 		 0.90000 		 0.57456
14 		 0.42623 		 0.87917 		 0.54386
15 		 0.38818 		 0.92500 		 0.55263
16 		 0.34787 		 0.89583 		 0.54386
17 		 0.34305 		 0.93750 		 0.55702
18 		 0.28286 		 0.94167 		 0.57895
19 		 0.23681 		 0.94167 		 0.60088
20 		 0.24932 		 0.92500 		 0.59211
21 		 0.19128 		 0.96667 		 0.58772
22 		 0.15227 		 0.96250 		 0.59649
23 		 0.18666 		 0.95417 		 0.59649
24 		 0.14603 		 0.98333 		 0.57895
END

###
training_model: RNN_sent_model_embed.py
starting_time: 2017-03-19 05:19:18.912240

parameters:
	cell_type: lstm
	embed_size: 50
	hidden_size: 100
	learning_rate: 0.0010
	regularization: 0.00000
	batch_size: 16

training history:
epoch 		 loss 		 train_accu 		 test_accu
0 		 3.56932 		 0.17083 		 0.10526
1 		 2.60973 		 0.32917 		 0.26316
2 		 2.06943 		 0.47083 		 0.34649
3 		 1.74777 		 0.52500 		 0.34649
4 		 1.52146 		 0.58750 		 0.41228
5 		 1.27783 		 0.61667 		 0.44737
6 		 1.09632 		 0.65417 		 0.45175
7 		 0.96533 		 0.70417 		 0.50439
8 		 0.84974 		 0.71250 		 0.51316
9 		 0.74604 		 0.79583 		 0.55702
10 		 0.62227 		 0.79583 		 0.56579
11 		 0.56465 		 0.85000 		 0.56140
12 		 0.46750 		 0.87500 		 0.58333
13 		 0.40570 		 0.89583 		 0.51316
14 		 0.40726 		 0.85417 		 0.52632
15 		 0.38074 		 0.85000 		 0.53070
16 		 0.31049 		 0.89583 		 0.53070
17 		 0.34525 		 0.90000 		 0.53509
18 		 0.24885 		 0.94583 		 0.57018
19 		 0.19548 		 0.95833 		 0.58772
20 		 0.16507 		 0.95000 		 0.60088
21 		 0.14230 		 0.96250 		 0.58772
22 		 0.12991 		 0.96250 		 0.54825
23 		 0.15979 		 0.97917 		 0.57018
24 		 0.11788 		 0.97083 		 0.56140
END

###
training_model: RNN_sent_model_embed.py
starting_time: 2017-03-19 05:27:45.692334

parameters:
	cell_type: lstm
	embed_size: 50
	hidden_size: 150
	learning_rate: 0.0010
	regularization: 0.00000
	batch_size: 16

training history:
epoch 		 loss 		 train_accu 		 test_accu
0 		 3.42367 		 0.22917 		 0.17105
1 		 2.36878 		 0.40417 		 0.28070
2 		 1.99296 		 0.42917 		 0.34211
3 		 1.59773 		 0.53333 		 0.43421
4 		 1.33202 		 0.53750 		 0.46930
5 		 1.20793 		 0.65000 		 0.49561
6 		 1.04255 		 0.68750 		 0.51754
7 		 0.89722 		 0.69583 		 0.54386
8 		 0.80152 		 0.76667 		 0.52193
9 		 0.66504 		 0.76250 		 0.54825
10 		 0.58020 		 0.85000 		 0.54386
11 		 0.49496 		 0.84167 		 0.57018
12 		 0.42311 		 0.86250 		 0.58333
13 		 0.38895 		 0.88750 		 0.57456
14 		 0.39170 		 0.88750 		 0.57018
15 		 0.28814 		 0.90833 		 0.60088
16 		 0.30363 		 0.88333 		 0.55702
17 		 0.29543 		 0.92917 		 0.56579
18 		 0.21859 		 0.93333 		 0.60088
19 		 0.17837 		 0.95833 		 0.60088
20 		 0.14850 		 0.97083 		 0.61404
21 		 0.13056 		 0.95833 		 0.60965
22 		 0.12230 		 0.96667 		 0.60965
23 		 0.17868 		 0.94583 		 0.60526
24 		 0.10484 		 0.98333 		 0.64474
END

###
training_model: RNN_sent_model_embed.py
starting_time: 2017-03-19 05:49:54.197078

parameters:
	cell_type: lstm
	embed_size: 50
	hidden_size: 300
	learning_rate: 0.0010
	regularization: 0.00000
	batch_size: 16

training history:
epoch 		 loss 		 train_accu 		 test_accu
0 		 3.41284 		 0.19583 		 0.15351
1 		 2.44065 		 0.38333 		 0.22807
2 		 1.96372 		 0.47917 		 0.30702
3 		 1.61080 		 0.54167 		 0.37719
4 		 1.41673 		 0.55000 		 0.40351
5 		 1.24873 		 0.61667 		 0.44298
6 		 1.07465 		 0.66667 		 0.46053
7 		 0.91223 		 0.71250 		 0.54825
8 		 0.77189 		 0.77500 		 0.53509
9 		 0.68405 		 0.80417 		 0.55702
10 		 0.58768 		 0.80833 		 0.57456
11 		 0.48777 		 0.83750 		 0.56140
12 		 0.39777 		 0.87917 		 0.55702
13 		 0.33799 		 0.84583 		 0.54386
14 		 0.32490 		 0.89167 		 0.55702
15 		 0.34888 		 0.93333 		 0.53947
16 		 0.23746 		 0.88333 		 0.54825
17 		 0.23975 		 0.94167 		 0.58772
18 		 0.21367 		 0.93750 		 0.57018
19 		 0.15347 		 0.89167 		 0.54386
20 		 0.13609 		 0.93750 		 0.56140
21 		 0.09553 		 0.97500 		 0.57018
22 		 0.07559 		 0.99167 		 0.58772
23 		 0.06136 		 0.99167 		 0.58772
24 		 0.04532 		 0.99167 		 0.58772
END

